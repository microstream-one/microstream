Clustering Grundsatzüberlegungen
TM, 2019-06-06

Grundregel für parallel ausgeführte Logiken:

Für jede veränderbare, zusammenhängende Dateneinheit darf zu jedem Zeitpunkt nur ein Akteur zuständig sein. Schreibend UND lesend. Alle anderen Akteure müssen eine potenziell veraltete Kopie verwenden oder warten, bis sie die Zuständigkeit bekommen.

Eine "Zusammenhängende Dateneinheit" kann von einem einzelnen Datensatz/Objekt/Entity bishin zu einem thematisch zusammengehörenden Subgraphen alles sein.
Ein "Akteur" ist irgendetwas, das aktiv Programmlogik ausführt. Ein Thread, ein Prozess oder ein "Node" (physische oder virtuelle Hardware) in einem Cluster.
Warum Schreibend UND lesen? Weil eine Veränderung der Daten (Schreiben) während einem nicht-trivialen Lesevorgang (mehr als technisch atomarer Wert) für diesen inkonsistente Daten erzeugen kann: Ein Teil wird aus dem alten Zustand gelesen, ein Teil von dem neuen.

Unveränderbare Dateneinheiten ("immutable") können jederzeit von mehreren Akteuren gleichzeitig gelesen werden. Sie werden (können) sich nie mehr ändern und können daher auch nicht durch nebenläufige Zugriffe inkonsistent werden.
Für Entwicklung von Logik mit Nebenläufigkeit wird von je her empfohlen, so viele Daten wie möglich unveränderbar zu machen. Objekte oder gar ganze Graphen bei jeder Änderung komplett neu erzeugen mag im ersten Moment nach unwirtschaftlich hohem Aufwand aussehen, doch die Erleichterung (geradezu Trivialisierung) des Nebenläufigkeitshandlings ist den Aufwand meistens wert.

Beispiel Threads in Java:
Daten Thread-local machen (z.B. neue Instanz, die noch nicht von anderen Threads erreichBar ist), dann muss sich um Nebenläufigkeit nicht gekümmert werden.
Zu jedem Zeitpunkt ALLE Daten immer nur von einem Thread bearbeiten lassen, dann muss sich um Nebenläufigkeit nicht gekümmert werden.
Ansonsten:
Konkurrierende Zugriffe müssen mit einem "Lock" ("synchronized") koordiniert werden, an dem alle Akteuere mit Bedarf warten, bis sie an der Reihe sind. Im einfachsten Fall auf das gelockte Objekt selbst, ansonsten mit einem Lock auf ein Stellvertreterobjekt, das für einen komplexen Subgraphen steht. Z.B. "Kopfinstanz".

Beispiel Nodes in einem Cluster:
Für eine bestimmte Dateneinheit müssen alle Änderungen immer an denselben, für sie zuständigen Node in Form einer Anfrage weitergeleitet werden. Dieser validiert die Anfrage dann und führt sie aus oder verwirft sie. Alle anderen Nodes halten sich bei Bedarf nur eine Kopie dieser Dateneinheit. Die Kopie ist potenziell veraltet und muss bei Bedarf nach Aktualität erst entsprechend aktualisiert werden, bevor die Logik mit dem Aktualitätsbedarf anfangen kann, zu arbeiten.

Zuständigkeiten können zwischen Nodes wechseln, doch das ist als ein komplexer Restrukturierungsaufwand anzusehen, während dem keine Anfragen verarbeitet werden können. ("Stop the world"-Effekt, ähnlich JVM Full GC)

Es ist hier natürlich ein Mechanismus vorstellbar, der Zuständigkeiten und die entsprechenden Daten "vorab" neu verteilt, während Anfragen noch auf den alten Zuständigkeiten abgearbeitet werden. Sobald die Neuverteilung abgeschlossen ist, wechselt die Zuständigkeit diskret von einem Node zum anderen (gesteuert von einer zentralen Management-Instanz). Ggf. müssen dann noch Updates als den letzten Anfrage-Verarbeitungen verarbeitet werden, dann kann der neu zuständige Node mit kaum merklicher Pause weiterarbeiten. Damite wären die Zuständigkeiten "on the Fly" neu verteilt.
Klingt als Beschreibung in so einem Absatz sehr einfach, wäre aber bestimmt eine Arbeit von mehreren Mannjahren bis zu einer praxistauglich fehlerfrei funktionierenden Lösung.



Aktualitätsbedarf

Anwendungslogik grundsätzlich in zwei Arten unterscheiden (ähnlich synchronized und nicht synchronized auf JVM-Level):

Ohne Aktualitätsbedarf:
Kann ungheprüft auf vorhandenen, poteziell veralteten Daten arbeiten. Effektive Änderungen werden erst später in Form einer Änderungsanfrage durch den zuständigen Node vorgenommen, welcher vorher die Daten erst validiert und bei Problemen durch veraltete Daten die Anfrage verwirft.
Mit Aktualitätsbedarf:
Die Logik muss warten, bis der interne Daten-Update-Mechanismus des Nodes alle Updates bis zum Aufrufzeitpunkt der Logik verarbeitet hat und damit die Daten auf dem aktuellsten Stand (vom Aufrufzeitpunkt her gesehen) sind.

Es wäre zu kompliziert und selbst bei technisch korrekter Ausführung anfällig für Inkonsistenzen auf fachlicher Ebene, wenn man einen Aktualitätsbedarf je Dateneinheit definieren könnte. Stattdessen gibt es Aktualitätsbedarf nur als "Alles oder nichts"-Zustand für den ganzen Node: Eine Logik kann grundsätzlich Aktualitätsbedarf haben, dann muss sie warten, bis ALLE Updates bis zu ihrem Aufrufzeitpunkt verarbeitet worden sind. Umgekehrt kann der Update-Mechanismus niemals weiter voranschreiten, als der jüngste Aufrufzeitpunkt einer Logik mit angemeldetem Aktualitätsbedarf ist. Ansonsten würde sie verwendete Daten "in die Zukunft" verändern und damit aus Sicht der Aktualität potenziell inkonsistent machen.
Logik ohne Aktualitätsbedarf kann unbehelligt davon arbeiten, so wie Logik ohne "synchronized" auch einfach an Locks vorbei arbeiten kann.


Kann dadurch ein System vor lauter Anfragen von Außen mit Aktualitätsbedarf-Logik lahmgelegt werden, weil der Update-Mechanismus vor lauter Geblocktsein nicht mehr hinterherkommt?
Antwort:
Jain.
Zunächst ist das bei "normalen" Anfragen und Locks in einer einzelnen JVM auch schon so: Wenn sich eine Request-Queue schneller füllt, als sie abgearbeitet werden kann, wird das immer in einem überlasteten System enden.
Darum ja, prinzipiell kann das auch hier der Fall sein.
Allerdings: Je länger ein System mit der Abarbeitung der aktuellen Requests beschäftigt ist, umso weiter nach hinten verschieben sich ja auch die Aufrufzeitpunkte der Aktualitätsbedarf-Logiken, d.h. je mehr sich aufstaut, umso mehr holt der Update-Mechanismus auf einmal auf, sobald er wieder "darf", bevor er wieder geblockt wird. Das ist keine vollständige Lösung (die kann es nie geben, wenn Arbeit einfach schneller reinkommt, als sie abgearbeitet wird), aber es hat einen gewissen "heilenden" oder "entspannenden" Effekt.


Was ist, wenn Logik ohne Aktualitätsbedarf vor sich hinarbeitet und der Update-Mechanismus währenddessen den Zustand von Entities verändert? Das kann zu Problemen nicht nur der Datenaktualität führen (die wäre per Definition ja egal), sondern auch zu fatalen Inkonsistenzen führen.
Beispiel:
Eine Klasse hat zwei Felder. Eins der beiden muss zu jedem Zeitpunkt bei jeder Instanz der Klasse nicht null sein. Konzeptionell ist das auch so, doch durch eine Race Condition zwischen Logik ohne Aktualitätsbedarf und Update-Mechanismus kann folgendes passieren:
- Die Logik liest das erste Feld einer Instanzen aus. Das ist null, was okay ist.
- Der Update-Mechanismus aktualisiert die Instanz. In der aktuellsten Version ist das erste Feld nicht-null und dafür das zweite null.
- Die Logik liest das zweite Feld einer Instanzen aus. Das ist (inzwischen) auch null. Für den aktuellen Zustand ist das korrekt. Aus Sicht der Logik ist es nun aber eine Inkonsistenz, mit der diese nicht rechnet, weil sie konzeptionell nicht vorkommen darf und "eigentlich" auch nicht tut.

Heißt das nun, dass alle Logik eines Nodes strikt mit Aktualitätsbedarf arbeiten muss?
Oder ist es ähnlich wie bei nicht-synchronized Logik in Java: Das Problem wird einfach gar nicht abgefangen, sondern muss durch entsprechend maßgeschneiderter Anwendungslogik kompensiert bzw. verhindert werden.
Wahrscheinlich ist zweiteres die günstigere Lösung, mit folgender Begründung:
- Man kann ja trotzdem, wenn man will, einfach alles mit Aktualitätsbedarf programmieren. Problem gelöst (wenn auch sehr teuer).
- Es gibt viele Situationen, sogar die allermeisten, wo so ein Spezialfall gar nicht vorkommt und die einwandfrei ohne erzwungener Dauer-Aktualität arbeiten können. Immerhin soll ein Cluster ja paralleles Arbeiten ermöglichen und wenn dauerhaft alle Nodes auf alle Update warten müssten, würde das sehr schnell effektiv auf einen Single-Node-Cluster mit viel unnötigem Overhead hinauslaufen. Eine Lösung können hier auch unveränderbare Daten sein: Es gäbe dann im Beispiel zwei unterschiedliche Instanzen eine "alte" mit null/non-null und eine "neue" mit non-null/null. Eine Logik, die bvis zu ihrem Ende immer nur eine Instanz verarbeitet, wird hier niemals auf einen Konsistenzfehler stoßen, sondern nur noch die neue Version "nicht mitbekommen".