MicroStream Dokumentation Gliederung
TM, 2019-04-16

01.) Konfiguration
- Interfacebasierte Architektur: Viele "Rädchen" ergeben die Maschine, jedes mitgelieferte Rädchen ist nur ein Default und kann ersetzt werden.
- Foundation Typen Konzept und Verwendung
- StorageConfiguration
- Backup
- LockFile
(Jeweils Links nach unten.)

02.) Betriebskontrolle
- Shutdown: möglich aber nicht nötig. Siehe Safety.
- Sicherung durch LockFile. Siehe unten.
- Beliebiges starten und stoppen in der Anwendung möglich
- Beliebig viele Datenbankinstanzen in einer Anwendung möglich

03.) Anwendungsarchitektonische Schichten
- Anwendungsebene (Swizzling, Storer, Loader, Lazy References. )
- Storageebene (Channels, Threads, Dateien, Caching, Housekeeping.)
- Fileebene (channel, dat-Dateien, transactions Datei, TypeDictionary, Backup Dateien.)
(Jeweils Links nach unten.)

04.) Codearchitektonische Schichten
- Persistence (Persistierung allgemein, auch für Serialisierung. Beliebiges Format, theoretisch auch CSV, XML, JSON)
- Binary Persistence (Binary Implementierung für Persistence Schicht)
- Storage (Datenbanklösung mit Binary Persistence, theoretisch auch standalone Prozess)
- EmbeddedStorage (Schnittstelle für Anwendung zu Storage)

05.) Rootinstanz
- Bedeutung und Möglichkeiten zur Registrierung
[Evtl. noch ein kurzfristiges TODO für Entwicklung: Das Reference<...> außem rum wegmachen, das ist unnötig verwirrend.]

06.) Swizzling Konzept
- Eineindeutige ObjectIds. Rechenbeispiel für ausreichenden Vorrat.
- SwizzlingRegistry Konzept (z.B. WeakReference), Bedeutung, Speicherbedarf (Hauptschuldiger ist JDK), Management-Methoden. 

07.) Speichern
- Convenience-Methoden und expliziter Storer (quasi "Transaction")
- Defaultverhalten "lazy" und Alternativen "eager" und "full".

08.) Laden
- Lazy References: touched Timestamp, null-safe Variante
- LazyReferenceManager. Plus Erklärung, warum nicht defaultmäßig an 

09.) Konstanten und Enums
- Konstanten explizit registrieren (implizit via qualifier oder explizit via Name, Vor- und Nachteile, RootResolver)
- Enums: sind nichts anderes als Konstanten, aber Instanzen (Daten) verändern den Typ (Struktur). Eigentlich nur syntaktischer Zucker für Logik, in persistenten Daten sowieso deplatziert. Sind bisher durch Probleme und Verkomplizierung keine Unterstützung wert gewesen.

10.) TypeDictionary
- Konzept: Typbeschreibung für interne Validierung, Reference Traversal (z.B. für GC), Kovnertierung
- Syntax und deren Bedeutung
- Niemals per Hand editieren bzw. nur, wenn man genau weiß, was man tut und die Verantwortung übernimmt.
- Namen darin sind schall und rauch, nur für Zuordnung zu Runtime Klassen. Intern zählen nur TypeIds.

11.) TypeHandler
- Oft nötig für Effizienz (Beispiel LinkedList)
- Defaults für gängige Implementierungen
- Leicht erweiter- und ersatzbar.
- Z.B. hocheffizient maßgeschneidertes Handling für Massendaten (hunderttausende Umsätze, Messdaten, o.Ä. als 1 Entity)

12.) Backup
- On the fly Charakter: Verzögerung je nach Last und Hardware wenige µs)
- Mit Validierung
- Bei Bedarf auch explizit volles Backup (Link zu export)

13.) Legacy Type Mapping
- Konzept und Funktionsweise: kein Refactoring, kein Umkopieren, sondern on-the-fly "konvertieren". Immutable Typen für Abwärtskompatibilität
- Nötige Mappings und Heuristik

14.) Housekeeping: Storage Cache Management
- Jedes Entity in Datenbank hat einen Eintrag. Nötig für GC. Belegt aber kleine Menge RAM (ca. 100 Bytes). Konzept für zukünftige Optimierung.
- Daten der Entities auch im RAM, "Cache" (das hier ist das "in-memory" buzzword), aber Cache wird bei Nichtbedarf geleert.
- Evaluator Konzept und Funktionsweise
- Defaultverhalten
- Expliziter Aufruf

15.) Housekeeping: File Cleanup
- Motivation, Konzept
- Expliziter Aufruf

16.) Housekeeping: Garbage Collector
- Motivation, Konzept
- Expliziter Aufruf

17.) Dateien im Detail
- Storage Dateien: brutal einfach
- ByteOrder: aktuell "native", Wechsel erfordert aktuell einmalige explizite Konvertierung der Daten.
- Transactions Log: Einträge für Validierung von Writes / Erkennung von Crashes. "Optional": Löschbar, falls Dateien sicher konsistent sind.
- Zukünftig: Transactions Log Einträge als "Kommentar" in Storage Dateien embeddet. Transactions Log Dateien entfallen dann.

18.) Sicherheit (Safety)
- FileLocks via System (zweifelhafte Verlässlichkeit und deckt nicht alles ab) und LockFile (deckt konkurrierenden zweitprozess ab)
- crash safety: unvollständige Writes werden beim nächsten start erkannt und abgeschnitten (transactions log)
- immer, wenn eine store Methode zurückkehrt, garantie, dass Daten wirklich an Filesystem übergeben (und "geflusht") worden sind
- Keine Garantie für Verlässlichkeit oder Korrektheit des FileSystems (Erfahrung: FileSystem einer Cloudplattform hatte Bugs: Datenverlust, nicht verhinderbar durch MS)
- Nebenläufigkeit bei Speichern: reiner Anwendungsconcern, genau wie ohne Datenspeicherlösung. Nur Business Logik weiß, was wann wie lange gelockt werden muss. Ohne Nebenläufigskeitsmanagement: inkonsistente Datenstrukturen zur Laufzeit, darum kann nur Storer nur noch inkonsistente Daten produzieren. Ist kein Bug, sondern Folgefehler. Unvermeidbare Entwicklerverantwortung.

19.) Sicherheit (security)
- keine Verschlüsselung, denn: Datenbank ist internes Teil. Zugang dazu muss sowieso auf Systemebene gesichert sein.
  Wenn dort eh gesichert, dann kein Grund, Rad neu zu erfinden und speichern und laden unnötig langsam zu machen.
- Wer doch Datenbank live verschlüsseln will: Beispiel für customizing.

20.) Export und Import
- Daten per Typ in Datei exportieren
- Dateien mit passendem Format (siehe oben) importierbar. Aber Vorsicht: Graphstruktur, referenzielle Integrität ist eigene Verantwortung
- Konvertierung: Binary <-> CSV. CSV ist vollwertiges (anders als XML, JSON) und dazu noch effizientestes und lesbarstes Textformat. Nur richtiger Editor mit richtigen Settings nötig.

21.) Performance
- Wichtig, was und wie gemessen wird (JVM warmup usw.), viele Artikel dazu im Internet
- SwizzleRegistry resetten, Cache resetten, evtl. sogar geleerten Festplattencache sicherstellen.
- Aber: Ist Lese-Performance wirklich relevant, bzw. wann? Wenn, dann ist eher RAM für wichtige Anwendung zu klein.
- Speicherperformance ist das entscheidende: Anwendung läuft dahin und Daten sichern soll möglichst wenig aufhalten. Siehe Best Practice.
- Channels erhöhen Performance für Laden und Speichern. Theoretisch (viele Channels, jeder mit eigener SSD) beliebig viele Daten beliebig schnell. Bzw. nur interner Bus ist begrenzender Faktor. Allerdings: Abstrahierte Dateispeicher ("Cloud" usw.) vereiteln das.

22.) Best Practice "Speichern"
- Die geänderte Instanz muss gespeichert werden
- Um Kapselung nicht zu verletzen eager storing verwenden
- Datenmodell sollte aus Vielzahl von Gründen möglichst viel immutable sein. Dann: immutable sub-graph mit thread-local Storer storen, nebenläufig nur noch "einhängen" ("ultraschnell")

23.) Best Practice "Laden" (d.h. Lazy References)
- Datenmodell mit Collections ohnehin möglichst gut strukturieren (nicht einfach giga-collection "Orders", sondern Graph: Client -> BusinessYear -> Customer -> Order)
- Dadurch entstehende Subgraphen an geeigneten Stellen mit wenigen Lazy References in "Kopfdaten" Entity sehr leicht und effizient segmentierbar.
- Ordentliches Anwendungsdesign eliminiert auch das Bedürdnis einer "LazySegmentCollection": Daten gleich geschickt segmentieren, z.B. BusinessYear -> BusinessMonth, vereinfacht auch Business Logic, Concurrency Handling, usw.

24.) Logging?
- Erklärung: Crosscutting concern, jeder will anderes Framework, usw.
- Lösung: Interfacebasierte Architektur. Mit Typ und Creator/Provider "Rädchen" mit Logging nach eigenen Vorstellungen wrappen

25.) Ausblick
- Zugriff per Webserver für Debugging, Administrationsoberfläche, usw.
- effizienteres Fileformat: kleinere Datenbank, kleinere Backups, Zurückgehen auf jeden beliebigen Stand der Datenbank auf Knopfdurck, keine transaction logs mehr.
- Abstraktion von IO-Schicht (beliebige Speicherschicht anstatt FileSystem: z.B. "Cloud Storage", sogar speichern in RDBMS möglich, falls nötig)