{\rtf1\ansi\ansicpg1252\deff0\nouicompat\deflang1031{\fonttbl{\f0\fnil\fcharset0 Calibri;}}
{\colortbl ;\red0\green0\blue255;\red165\green165\blue165;}
{\*\generator Riched20 10.0.17763}\viewkind4\uc1 
\pard\sl276\slmult1\f0\fs28\lang7 2019-09-30\par
\par
Erst mal Brain Storming, was alles beteiligt ist:\par
\par
1.) Direkte Memory Allocation, z.B. um Entitydaten im Storage-Layer zu cachen.\par
-> k\'f6nnte gel\'f6st werden \'fcber ein simples byte[] bzw. evtl #3\par
ABER: wie gemeinsamen Nenner f\'fcr API?\par
\par
2.) ByteBuffer bef\'fcllen. (Wenn's kein DirectByteBuffer ist, wird intern vor dem Schreiben erst noch in einen DBB umkopiert. Kein Witz)\par
-> k\'f6nnte gel\'f6st werden, indem die ByteBuffer API aufgerufen wird, ggf. mit ByteOrder immer auf die System-Byteorder gesetzt, damit da nicht sinnlos rumgedreht wird und beim auslesen wieder zur\'fcck.\par
\par
3.) Direkte Memory-Zugriffe auf eine blanke Speicheradresse \par
-> byte[][] mit simulierter absoluter speicheradresse (siehe Issue Beschreibung)\par
? Oder evtl. einem gro\'dfen DirectByteBuffer unterteilt in mehrere Abschnitte? hm ...\par
\par
4.) Direkte Memory-Zugriffe auf eine Instanz mit offset\par
-> K\'f6nnte gel\'f6st werden mit ValueHandler Interface mit unterschiedlicher Implementierung intern (siehe Issue Beschreibung)\par
\par
5.) ValueSetter und ValueStorer Signaturen haben direkte Speicheradresse\par
-> k\'f6nnte gel\'f6st werden mit #4: \'dcbergeordnete Architekturschicht, die diese Typen gar nicht erst n\'f6tig macht.\par
ABER: wie sollen dann ValueTranslator und die ganzen um-map-Legacy-Handler geschrieben werden? Auch noch weiter abstrahieren?\par
\par
\par
\par
Ich denke, das einfachste w\'e4re erst mal, #4 und #5 umzusetzen und dann zu schauen, wie der performance Unterschied von Unsafe zu Reflection und von Unsafe zu direkten DirectByteBuffer methodenaufrufen w\'e4re.\par
\par
\par
\par
2019-10-01\par
\par
Mal im eclipse suchen, wo \'fcberall Unsafe vorkommt.\par
Kommt (immer noch) nur in der Klasse XMemory vor, das hab ich ja schon mal konsolidiert.\par
Sehr sch\'f6n.\par
Das WIP Projekt z\'e4hlt ja nicht, das wird nicht deployt.\par
\par
Also ist die Frage, wo XMemory \'fcberall vorkommt.\par
\par
Insgesamt 890 Vorkommen, die ersetzt werden m\'fcssen.\par
30 Vorkommen im JDK8Internals Projekt. Die z\'e4hlen nicht, denn die k\'f6nnen so bleiben, weil das JDK8 garantiert eine zug\'e4ngliche Unsafe Klasse hat und immer haben wird.\par
50 Vorkommen im WIP. Die sind komplett egal.\par
\par
Der Rest muss ersetzt werden:\par
\par
Ca. 130 Vorkommen im Base Projekt. Die sind erst mal nicht wichtig, m\'fcssten letztendlich aber auch ersetzt/modularisiert werden. Hm...\par
\par
6 Vorkommen im Communication Projekt. Ignorier ich erst mal. Sp\'e4ter ...\par
\par
1 ganzes Vorkommen im Persistence Projekt, n\'e4mlich f\'fcr den Instantiator.\par
Das l\'e4sst sich nat\'fcrlich irgendwie verschieben/ersetzen, wobei das schon eine interessante Frage aufwirft:\par
Ohne low-level Instantierung braucht man die "Es muss einen default Konstruktor ohne logik drin geben"-Seuche als Einschr\'e4nkung f\'fcr die Verwendung des Frameworks.\par
Oder nat\'fcrlich einen expliziten Instantiator.\par
\par
Ca. 100 Vorkommen im Storage Projekt.\par
Manche davon sind trivial, z.B. DefaultBufferSize. Oder primtive Byte sizes. Bzw. diese Aufrufe k\'f6nnen sogar bleiben. Oder man trennt die irgendwie raus, ist ja egal.\par
Der Rest sind lauter Operationen mit absoluter Speicheradresse.\par
\par
Ca. 650 Vorkommen im PersistenceBinary Projekt.\par
Lustig lustig: Davon ca. 400 in der BinaryValueTranslators Monsterklasse. Bzw. das sind alles nur Funktionsimplementierungen f\'fcr das BinaryValueSetter interface, das einen Wert von einer absoluten Adresse zu einer relativen oder absoluten Adresse setzt.\par
\par
Und dann noch 250 "sonstige" Vorkommen. In BinaryHandler Implementierungen usw.\par
\par
Puh ...\par
Da w\'e4re es fast sinnvoller, erst mal ein paar damit \'fcberschneidende Issues vorzuziehen, weil die auf saubere Art eine ansonsten eher provisorische L\'f6sung bringen w\'fcrden.\par
Z.B. Die gescheite Abstraktion von BinaryFields. Evtl. sogar das ValueAccessor Konzept.\par
\par
Diese 890 Vorkommen erzeugen unterschiedlichen Aufwand:\par
Ein paar davon (sagen wir pauschal 89) sind unproblematisch, weil sie einfach Konstanten sind (default buffer size, binary length von primitives, usw.)\par
Der eine Instantiator ist trivial ersetzbar, aber erzeugt damit ein riesen Problem: Ohne das braucht man in jeder Entityklasse einen "passenden" Konstruktor oder einen vom Entity Designer manuell zu bauenden Instantiator.\par
Die 400 f\'fcr die BinaryValueTranslators lassen sich alle nach Schema F ersetzen, sobald es ein passendes Ersatzkonzept gibt. Das ist dann nur eine Flei\'dfarbeit.\par
Die restlichen 400 m\'fcssen je nach Fall analysiert und passend ersetzt/abstrahiert werden. Das werden nat\'fcrlich keine 400 Einzelf\'e4lle, sondern vielleicht 10 oder so Kategorien an Modularisierung/Abstraktion und dann m\'fcssen alle 400 F\'e4lle auf die passende L\'f6sung umgebaut werden.\par
\par
Au\'dferdem knifflig:\par
Was immer an Modularisierung/Abstraktion gemacht wird, sollte ja m\'f6glichst so sein, dass der Normalfall keine oder kaum Performance oder gar Funktionalit\'e4t verliert.\par
Da muss ich viel analysieren, \'fcberlegen, rumprobieren.\par
\par
Mal Issue updaten ...\par
\par
\par
Jetzt mal \'fcberlegen zu BinaryValueSetter Abstraktion.\par
Gibt eigentlich nur zwei Stellen: in Binary f\'fcr #updateFixedSize und in BinaryLegacyTypeHandlerRerouting zum binary values translaten.\par
Das zweite verschieb ich mal in eine Binary#copyMemory Methode.\par
\par
\par
Hm... interessante Idee:\par
Das byte[][] w\'e4re wahrscheinlich gar nicht n\'f6tig. DirectByteBuffer gibt es \'fcberall (z.B. in Android hier: {{\field{\*\fldinst{HYPERLINK https://android.googlesource.com/platform/libcore/+/jb-mr2-release/luni/src/main/java/java/nio/DirectByteBuffer.java }}{\fldrslt{https://android.googlesource.com/platform/libcore/+/jb-mr2-release/luni/src/main/java/java/nio/DirectByteBuffer.java\ul0\cf0}}}}\f0\fs28 ). Muss es wahrscheinlich sogar geben, weil ja die JDK public API eine entsprechende Methode (ByteBuffer#allocateDirect) besitzt.\par
\par
Es k\'f6nnte also reichen, an den entsprechenden Stellen anstatt einer blanken Adresse ein Paar von DBB+Offset Werten zu \'fcbergeben. Die normale Implementierung kann sich daraus ihre absolut Adresse errechnen und gl\'fccklich arbeiten, wie bisher. Implementierungen ohne Unsafe m\'fcssen halt jedes mal einen Lookup \'fcber den Offset machen.\par
\par
Ich muss mal schauen, ob das irgendwo API-technisch Probleme macht.\par
\par
Mal daf\'fcr bissl umbauen:\par
BinaryEntityDataReader#readBinaryEntityData(long)\par
umbauen zu\par
BinaryEntityDataReader#readBinaryEntities(DirectByteBuffer)\par
Macht intern dann das gleiche wie bisher, aber evtl. kann man dann nach ein paar solcher Umformungen die LoadItemErstellung abstrahieren und modularisieren.\par
Aaach, da kommt wieder das byteOrderSwitching rein. Aber das macht nix. Da muss nur einmal ein boolean gecheckt werden f\'fcr mehrere Entities auf einmal.\par
Oh, dann f\'e4llt sogar der Check auf die ByteOrder bei jedem einzelnen LoadItem weg. Das ist super!\par
\par
Oh, beim refactoren aufgefallen:\par
Der ChunksBuffer (speichern) hat bisher die DBBs bis limit ausgelesen.\par
Der ChunksWrapper (laden) hat bisher die DBBs bis position ausgelesen.\par
\par
Dann kann ich das nicht so abstrahieren, dass beide Varianten immer bis limit auslesen.\par
Es sei denn, dass im zweiten Fall position immer gleich limit ist.\par
Muss ich recherchieren ...\par
- Also der ChunksWrapper wrapt einfach nur ein Array an ByteBuffers. Darum hei\'dft er ja wrapper.\par
- Der wird nur verwendet in der BinaryFileSource. Dort l\'e4uft das ganze sehr simpel: limit wird auf die File L\'e4nge gesetzt und es wird solange eingelesen, bis position gleich limit ist. Also kann auch limit verwendet werden.\par
- Bei der eigentlichen Storage werden zum lesen ChunkBuffers verwendet. Dort wird mit position gearbeitet und am ende geflipt (limit = position, position = 0). Darum wird dort limit verwendet.\par
Fazit: in beiden F\'e4llen passt limit als grenze. Sollte das mal ein Problem machen, muss eben das limit entsprechend gesetzt werden.\par
\par
So. Umgebaut. Testen. Passt.\par
\par
Mal weiter schauen wegen Abstraktion...\par
Also man k\'f6nnte eine zweite BinaryLoadItem Implementierung machen, die die address als Position im DBB interpretiert und sich den entsprechenden DBB dazu merkt.\par
\par
Was das ganze letztendlich ziemlich kompliziert bis unm\'f6glich macht, ist, dass Binary halt kein Interface, sondern eine Klasse ist.\par
Dadurch st\'f6ren ein paar Methoden und Modularisierung w\'fcrde bedeuten, dort interface-ierte Logikinstanzen reinzuh\'e4ngen. Dann kann man gleich das ganze Ding zu einem Interface machen und sich mit einem Provider f\'fcr eine plattform das passende geben lassen.\par
\par
Hei\'dft: Der Auftrag f\'fcr morgen ist, das Ding durch ein interface zu ersetzen und zu checken, wie sich die performance ver\'e4ndert.\par
\par
Davon unabh\'e4ngig muss die API mal aufger\'e4umt werden, damit die ganzen direkten Addressen als implementierungsdetails verschwinden. Mit 2-3 Methoden hab ich das schon gemacht. Geht ganz gut.\par
Da kommt dann auch wieder das BinaryField Konzept ins Spiel ...\par
\par
\par
\par
 2019-10-02\par
\par
Binary zu interface umbauen.\par
\par
Puh... das wird ... viel Arbeit. Die Klasse ist 2000 Zeilen lang. Darin befinden sich viele statische, private und public Methoden. Jeweils unterteilt in welche mit absolutem Memory-Address, die m\'fcssen intern implementierungsspezifisch bleiben. Und welche, die "schon" oder von Haus aus Memory-Address-unabh\'e4ngig sind, die m\'fcssen ins Interface rein.\par
Dazu muss ich erst mal Methode f\'fcr Methode durchk\'e4mmen, was wo dazugeh\'f6rt. Dann f\'fcr die eine Gruppe zu interface Methoden erstellen. Und dann Aufruferklassen entsprechend umbauen.\par
\par
Die updateFixedSize h\'e4tte noch MemoryOffsets in Instanzen rein, was f\'fcr eine Unabh\'e4ngigkeit von Unsafe nicht sein darf. Aber die m\'fcsst ich erst mal mitziehen und dann sp\'e4ter das Konzept \'e4ndern (ValueSetters, die intern den Offset halten - oder dann eben das Field direkt f\'fcr eine reflection Operation).\par
\par
Au\'dferdem stellt sich wieder mal die Frage, ob "Binary" wirklich ein unsauber typisierter Kombityp sein muss, weil die API Bestandteile wirklich nicht auf "BinaryStoring", "BinaryReading" und "? extends Binary" typisiert werden k\'f6nnen...\par
\par
... Mehrere Besprechungen, Support f\'fcr CK und FH sp\'e4ter ist der Tag irgendwie um. Kaum was am Issue gearbeitet ...\par
\par
Hm... Die \'c4nderungen commit ich mal nicht, sondern stash sie nur oder so.\par
\par
\par
2019-10-03\par
\par
Feiertag\par
\par
\par
2019-10-04\par
\par
Binary Umwandlung zu interface weitermachen.\par
\par
Public Methods in interface hochziehen.\par
Sind immer noch 200 Compilerfehler.\par
Es h\'e4ngt halt einfach noch so wahnsinnig viel von direkten Speicheradressen ab.\par
Eigentlich m\'fcsste ich dann jetzt erst das alles in das interface hochziehen, auch wenn es da nicht hingeh\'f6rt und ich es sp\'e4ter wieder rausschmeissen muss, damit ich \'fcberhaupt erst mal checken kann, wie es performancem\'e4\'dfig ist, aus der abstrakten Klasse ein interface zu machen ...\par
Und wenn das passt, dann m\'fcsste ich alle Methoden mit direkter Adresse umstellen auf entweder offset relativ zu internem address state oder DBB+Offset Parameter, z.B. im Fall von modifyLoadItem.\par
\par
\par
Bevor ein Refactoring in diese Richtung gemacht werden kann, m\'fcssen erst mal alle Methoden umgebaut werden, die absolute Speicheradressen verwenden. Da gibt es sogar unabh\'e4ngig von diesem Issue hier schon ein TODO im Code: besser w\'e4re es, in einem ChunksBuffer (Ableitung von Binary zum Speichern von Daten) die contennt Adresse des aktuellen Entities intern zu halten und dann nur noch mit Offsets drauf zuzugreifen. Der Performance Aufwand daf\'fcr sollte nahe 0 sein, denn:\par
- Aktuell muss die ermittelte contentAddress ja zur\'fcckgegeben und im Aufruferkontext in einer lokalen Variable gespeichert werden. Das ist auch nicht gratis und das w\'fcrde mit einem internen Feld wegfallen.\par
- Auch jetzt muss auf diese contentAddress schon der offset draufaddiert werden, also keine Einsparung hier. Vielleicht ist das lesen der lokalen Variable etwas schneller als das lesen des Felds, aber mit CPU caches usw. bin ich mir da gar nicht mal so sicher. Muss getestet werden.\par
- Algorithmen, die n Elemente hintereinander speichern (f\'fcr collections, arrays, usw.), k\'f6nnen in Binary intern gemacht werden bzw. sind sie inzwischen eh schon gr\'f6\'dftenteils wenn nicht alle. Sollte noch irgendwas fehlen, verschieb ich das einfach zu den anderen. Dort ist dann die contentAddress wieder eine lokale Variable in der Methode, also performancem\'e4\'dfig kein unterschied zu der externen Variante, nur API-m\'e4\'dfig sauberer und dann eben, endlich, auch abstrahierbar.\par
\par
Also bau ich jetzt zuerst das um und dann schau ich mir wieder den aktuell versuchten Schritt an.\par
\par
Issue updaten.\par
\par
\par
\par
2019-10-07\par
\par
Schnell einen Test zum Swappen von DirectByteBuffer Inhalt machen f\'fcr eine Idee/Frage vom Wochenende.\par
Schnell fertig. Laufen lassen. JVM Crash.\par
Warum des?\par
Untersuchen ...\par
Ich kann keinen Fehler finden.\par
Weitere Tests daf\'fcr bauen.\par
Ergebnis:\par
Mein Code ist korrekt. Nur ab einer gewissen Gr\'f6\'dfe, evtl. irgendwie kurz vor der out of heap exception (die da eigentlich gekommen w\'e4re), crasht eine Methode im StringBuilder (!!! Nicht in meinem Code!) die JVM.\par
Liegt wahrscheinlich an dem @HotSpotIntrinsic Zeug.\par
Mit umgangenem Crash den eigentlich test machen. Gro\'dfe DBB Datenmengen brauchen eine extra JVM -XX:MaxDirectMemorySize Angabe. Aha, hab ich auch noch nicht gewusst. Sehr gute neue Erkenntnis.\par
\par
Jetzt API refactoring weitermachen ...\par
\par
Achja, die storeStringsAsList Methode.\par
Die so zu refactoren, wie ich mir das zuerst gedacht hatte, wird schwierig ...\par
Genau: Weil da n variable-length Listen gespeichert werden und jede gibt den variablen end-offset wert zur\'fcck.\par
Einfachste L\'f6sung: Ich lass die auf absoluter Adresse, aber mach sie intern.\par
Bzw. anders rum: die beiden aufgerufenen methoden bekommen interne, absolut arbeitende Varianten und die \'e4u\'dfere, public Methode wird relativ mit this.address + offset Aufruf der anderen.\par
\par
\par
\par
2019-10-08\par
\par
Halber Tag Besprechungen, u.A. Clustering Design, aber sehr produktiv.\par
\par
Sonderfallmethoden fertig bauen.\par
Alle "_Direct" und "_Offset" Marker wegrefactoren.\par
Alle internen methoden sauber auf "internal~" umbenennen.\par
\par
Jetzt m\'fcssen dann noch die "static methods using absolut an memory address that should actually not be here" Methoden aufger\'e4umt werden.\par
Mal versuchen mit der ersten ...\par
\par
Hm. Das sieht jetzt erst mal unm\'f6glich aus, weil die BinaryReferenceTraversers n\'e4mlich auch f\'fcr gecachte Entitydaten direkt im Speicher (allocateMemory) verwendet werden.\par
Wieder l\'f6schen.\par
Aber ich muss mal schauen. Evtl. kann ich die Methode anderweitig verstecken oder einfach in die Call site verschieben, dann ist sie im binary weg.\par
Wobei das eigentliche Problem ja ist: wie kriegt man den direkten Speicherzugriff auf direkt gecachte Entities weg?\par
Oder muss da jetzt doch die Trickserei mit eigener Logik hinter allocateMemory rein? F\'fcr so "blank" allokierten Speicher ist das wahrscheinlich der einzig gangbare weg ...\par
\par
\par
\par
2019-10-09\par
\par
Aktuell gepflegte Version ausgelagert in "Speicherverwaltungskonzept.rtf" im pers\'f6nlichen Verzeichnis \\MicroStream\\Planung\\priv#111 Unsafe Modularisierung\\.\par
\cf2 Super Idee von Zuhause und Arbeitsweg:\par
\par
Manuelle Off-Heap Memory Allokierung sollte/muss eigentlich auch mit Off-Heap Memory realisiert werden.\par
Das hei\'dft zwangsweise: DirectByteBuffer. Unsafe#allocate gibt es ja eben auf manchen Systemen (Android) nicht und es gibt nur diese beiden M\'f6glichkeiten.\par
Sollte ein DBB mal intern so implementiert sein, dass er gar keinen Off-Heap Memory allokiert, dann k\'f6nnen wir das eh nicht \'e4ndern.\par
DBBs sind der beste Versuch bzw. die einzige M\'f6glichkeit, auf eine Java-Standard-API-Weise Off-Heap Memory zu allokieren. Also die.\par
\par
Nun folgendes Problem:\par
Man k\'f6nnte f\'fcr jeden allokate Aufruf einfach einen eigenen, neuen DBB instanzieren.\par
F\'fcr gro\'dfe Speicherbereiche ist das absolut okay. Aber f\'fcr kleine (z.B. 24 Byte f\'fcr ein stateless Entity, das nur aus Header besteht), w\'e4re der Overhead gigantisch.\par
\par
Darum folgende Idee:\par
"Kleine" Speicherbereiche werden zu mehreren in einem DBB zusammengefasst.\par
"Gr\'f6\'dfere" Speicherbereiche bekommen jeweils einen exklusiven DBB.\par
Cooler Nebeneffekt: ChunksBuffers zum Storen bekommen immer einen eigenen DBB. Der Lese-Fall (Entities laden und GC) ist performancem\'e4\'dfig nicht so kritisch in einer Anwendungskonzept, wo der In-Memory Objektgraph die Prim\'e4re Datenquelle darstellt.\par
\par
Die Idee ist nur, den DBB-Overhead je Item gegen 0 gegen zu lassen. Es muss nicht super-duper-intelligent die Zahl der DBBs auf einem absolut n\'f6tigen Minum gehalten werden oder sowas.\par
\par
Konkret zum Algorithmus:\par
\par
Rahmenbedingungen:\par
Man kann per DBB nur maximal Integer.MAX_VALUE an Speicherbereich reservieren. Total hinrissige Beschr\'e4nkung einfach nur, weil der ByteBuffer eine toArray Methode hat, aber in diesem Fall ist es ganz n\'fctzlich.\par
Also die maximal auf einmal reservierbare Speichergr\'f6\'dfe ist MAX_INT.\par
\par
Speicherbereiche werden aber als long addressiert. Also hat man 4 Byte "frei", um dort eine frei ausgedachte Verwaltung abzubilden.\par
Und zwar folgenderma\'dfen:\par
\par
Die unteren 4 byte werden als signed integer als index in den DBB (i) interpretiert.\par
Die oberen 4 byte werden als signed integer als Verwaltungsindex (v) interpretiert.\par
\par
Das Sign-Bit von v wird f\'fcr eine Fallunterscheidung verwendet:\par
Positiv bedeutet:\par
Der Wert identifiziert einen gro\'dfen Einzel-DBB Speicherbereich.\par
Eigentlich reicht daf\'fcr eine fortlaufende ID beginnend bei 1, die in ein BigEntry[] zeigt. Wobei beim Allokieren von index 1 an das array nach leeren Eintr\'e4gen durchsucht wird.\par
Das Array wird dynamisch gewachsen, wobei jede Gr\'f6\'dfen\'e4nderung einen upperThreshold und einen lowerThreshold wert cacht, gegen den beim allokieren und deallokieren mit dem bisher h\'f6chsten Wert getestet und ggf. rebuildet wird.\par
\par
So ein BigEntryenth\'e4lt die Referenz auf den DBB und Metadaten f\'fcr die Verwaltung. ... Hm... Was eigentlich bei einem Einzel-DBB?. Evtl. ist der Entry \'fcberfl\'fcssig.\par
D.h. man kann maximal 2,1~ Milliarden "gro\'dfe" DBBs allokieren. Das sollte reichen.\par
\par
Warum beginnend bei index 1? Weil eine generische Adresse von 0 nat\'fcrlich weiterhin "wie normal" ein nullpointer sein muss, der einen Fehler wird und nicht einfach ein generischer Indexwert, der auf den DBB mit index 0 zeigt.\par
Dieser eine Platz ist dann einfach immer leer ("da wohnt null"), aber das ist ja platzm\'e4\'dfig egal.\par
\par
\par
Negativ bedeutet:\par
Der Wert (mal *1) identifiziert einen einzelnen "kleinen" Eintrag in einem Multi-Eintrag-DBB Speicherbereich.\par
Die untersten 12 Bit definieren die L\'e4nge des allokierten Speicherbereichs und damit den Index in der Lookup Table (siehe unten).\par
Die n\'e4chsten 12 Bit definieren den Index der zweiten Dimension in der Lookup-Table (siehe unten).\par
Die obersten 7 bit identifiziert als unsigned int die Position im DBB. Nicht index, sondern index = position * L\'e4nge.\par
\par
Lookup-Table:\par
Ein Entry[][], das in der ersten Dimension immer die fest L\'e4nge 4096 (2^12) hat.\par
Der Index entspricht der L\'e4nge der allokierten Speicherbereiche. Also z.B. alle Speicherbereiche der L\'e4nge 197 werden verwaltet im Index 197.\par
Die zweite Dimension (nested Entry[] Array) ist ein ArrayList-artig wachsendes Array an Entry Instanzen.\par
\par
Ein Entry besteht aus:\par
- Referenz auf den DBB\par
- boolean[], das aussagt, ob der Eintrag an Position i gerade allokiert ist oder nicht.\par
Wobei dieses Array als header im DBB stehen k\'f6nnte. Mit einem initialen int, wie viele Eintr\'e4ge der DBB hat, d.h. wie lang das boolean-array ist.\par
Und einen size counter, um das deallokieren zu erleichtern.\par
Dann br\'e4uchte man gar keine Entry Zwischenklasse und das ganze w\'e4re etwas performanter.\par
\par
Allokieren und deallokieren liegt dann nat\'fcrlich auf der Hand:\par
usage-array checken (und ggf. exception).\par
\'fcbergebene Addresse in einen Offset in den DBB \'fcbersetzen und Bounds checken.\par
Wenn der size counter auf 0 ist, dann den ganzen DBB deallokieren und im nested array ausnullen.\par
\par
\par
Das w\'e4re ein off-heap-m\'e4\'dfig korrektes mittel, mit nur java public API (-> Android) eine absolute Speicheradressierung in manuell allokiertem Speicher zu machen.\par
Auf Entities zugreifen (base + offset) kann man damit nat\'fcrlich nicht, das braucht eine Umformung zu Reflection.\par
Auch auf explizite DBBs kann man damit nicht zugreifen. Die brauchen auch eine Umformung (DBB Referenz + Offset)\par
\cf0\par
\par
Das muss ich dann mal so implementieren, wenn ich alle kleineren Details refactort hab.\par
\par
\par
Jetzt wieder zur\'fcck zu den Methoden mit absoluter Speicheradressierung, die es eigentlich nicht geben darf.\par
\par
\par
Geht voran, aber das wird alles knifflig ...\par
\par
Und:\par
\par
Ich sollte mal ein konsistentes Benamungskonzept \'fcberlegen, wie man public API (mit relativem offset) von interner API (mit absolutem offset) unterscheiden kann.\par
\par
z.B:\par
get vs read\par
set vs store\par
\par
Ich w\'fcrd eigentlich sagen: read und store public, get und set intern.\par
Aber es gibt noch viele andere Methoden, die get~ anstatt read~ hei\'dfen. Die dann auch alle auf read~ umbenennen?\par
Aber eigentlich schon, weil der Binary Typ deutlich aussagen soll: Hier wird bin\'e4r gelesen und gestoret. Auf welche "magische" oder triviale Weise das intern dann auch immer stattfinden mag.\par
\par
F\'fcr arrays dann eher sowas wie:\par
update vs copy\par
build\par
\par
\par
\par
\par
2019-10-10\par
\par
Achja, die Benamungssache ist noch.\par
\par
Und noch die letzten paar Methoden mit absoluter Adresse rauswerfen.\par
Das geht eigentlich nicht, aber mit folgender einfacher Idee evtl doch:\par
Die Methoden zu simplen Arithmetik-Methoden reduzieren und den eigentlichen get_long Aufruf direkt in die Aufruferstelle schreiben. In diesen Klassen sind eh schon X-fach solche Aufrufe drin, da kommt es auf die paar mehr auch nicht mehr an.\par
Daf\'fcr w\'e4re dann die Binary Klasse sauber.\par
Das mach ich mal so.\par
\par
Das modifyLoadItem ist auch noch. Hm. Das \'e4nder ich auf einen \'fcbergebenen ByteBuffer und Offset. Dann passt das.\par
Die copyMemory Methode benutzt auch noch eine absolute Adresse. Umbauen.\par
\par
Bei den drei verbleibenden Methoden, den getEntity~ f\'fcr OID, TID, LEN ist das aber problematisch:\par
Das sind insgesamt 12-19 Stellen, insgesamt ca. 50. Die alle durch einen expliziten get_long Aufruf zu ersetzen ist strukturell widersinnig. Danach m\'fcssten diese 50 Stellen sofort wieder konsolidiert werden in eine statische Util-Klasse.\par
Also m\'fcsste das eine andere sein, eine "AbsoluteEntityAddressing". Aber das verschiebt das Problem ja nur, weil letztendlich auch die modularisiert werden m\'fcsste.\par
\par
Das Problem ist: Wie kann man alle Verwendungen der Unsafe Klasse modularisieren? Insbesondere die von statischen Methoden (XMemory...).\par
Man kann nat\'fcrlich einfach eine andere XMemory Klasse verwenden, die intern ihr eigenes Speichermanagement macht f\'fcr absolute Zugriffe. Das geht.\par
1.) Das geht aber nur f\'fcr die Logik, die sich so eine absolute Speicheradresse von einem kontextlosen/direkten "allocateMemory" Aufruf geholt hat.\par
2.) Logik, die per Adresse direkt auf einen DBB zugreift, muss so umgebaut werden, dass sie DBB + offset \'fcbergibt. So wie ich das bei modifyLoadItem und copyMemory gerade gemacht hab.\par
3.) Und Logik, die per reference + offset direkt auf instanzen zugreift, muss komplett eigenst\'e4ndig abstrahiert und modularisiert werden, damit man eine Alternative bauen kann, die Reflection anstatt DMA verwendet.\par
\par
Die Frage ist auch, ob man wirklich die Klasse tauschen muss, oder ob man den Memory-Zugriff \'fcber ein interface in eine instanz modularisieren kann.\par
Unsafe selbst ist witzigerweise ja auch eine Instanz, obwohl sie nur statische Funktionalit\'e4t bietet. Evtl. optimiert die JVM unbenutzte "this" argumente raus, dann w\'fcrde es keine rolle spielen.\par
Muss ich testen ...\par
\par
\par
\par
2019-10-11\par
\par
Also ich mach jetzt, einfach mal um Erfahrungs- bzw. Messwerte zu bekommen, folgendes:\line - Messen, wie lang so ein \'fcblicher Durchlauf an store und load jetzt braucht\line - Einfach mal hardgecodet in XMemory die Speicherzugriffsmethoden intern mit einer interface instanz modularisieren und schauen, was der Unterschied ist.\par
\par
Alle m\'f6glichen Besprechungen zwischendrin ...\par
\par
Testen ...\par
Oh. Erst mal JVM Crash. Debuggen. Ah, absoluten statt relativen Offset \'fcbergeben. Fixen. Testen. Passt.\par
Jetzt zu performance rumprobieren ...\par
\par
Hm. Also das variiert phasenweise. Mal ist die hardgecodete Variante meist 500 ms, manchmal bis zu 750, dann \'e4nder ich auch die dynamische und hab meist 750, dann \'e4nder ich auf die hardgecodete zur\'fcck und hab auch meist 750.\par
\par
So wird das nix. Evtl. wegen zu viel "noise" im System.\par
Muss ich doch eine main-methode mit spezifisch diesem Test bauen.\par
\par
\par
\par
Also das kann eigentlich nicht sein, aber ich kann es so reproduzieren mit ansonsten identischem Code:\par
\par
1 Million longs in einer for Schleife direkt in den Memory setzen.\par
10K warmup runs\par
10K hot runs\par
\par
Ergebnisse (SEHR konstant, mit Varianz von 0 bis -5\'b5s) :\par
\par
\par
hardcoded Aufruf von XMemory.VM.putLong()\par
average: 425\'b5s\par
minimum: 380\'b5s\par
\par
static final MemoryAccessor mit XMemory.VM.putLong() Aufruf in MemoryAccessor$Sun\par
average: 425\'b5s\par
minimum: 380\'b5s\par
\par
static MemoryAccessor mit XMemory.VM.putLong() Aufruf in MemoryAccessor$Sun gesetzt zur Laufzeit\par
average: 366\'b5s\par
minimum: 315\'b5s\par
\par
Also das flexibelste, am wenigsten eingeschr\'e4nkteste und damit am wenigsten voraussehbar optimierbar, das eigentlich einfach nur ein Umweg ist, ist SCHNELLER der als der direkte aufruf.\par
WTF?!\par
\par
Also das hei\'dft dann eigentlich eins:\par
Man kann einfach direkt in der XMemory Klasse die Unsafe Verwendung rausmodularisieren.\par
Krass\par
\par
\par
Wenn ich die Schleife in eine "hot" Methode verpack, dann sind alle drei Varianten so schnell wie die schnellste.\par
Scheinbar greift in dem oberen Beispiel eine JVM Optimierung in den ersten beiden F\'e4llen nicht richtig.\par
\par
Witzig auch:\par
Im Idealfall braucht ein long setzen 0,3 ns.\par
Auf dem 4,20 GHz Rechner also so grob 1 CPU cycle pro Aufruf.\par
Das kann doch eigentlich nicht sein: man kann doch nicht mit 1 Cycle 2 Werte verarbeiten, einen Sprung machen und den Wert dort hin schreiben. Selbst wenn's Level1 Cache ist...\par
Oder liegt das an Pipelining im CPU oder so?\par
\par
\par
\par
2019-10-14\par
\par
Noch ein paar weitere Tests.\par
Z.B., ob es einen unterschied macht, wenn die MemoryAccessor Instanz stack-escaping ist.\par
Offensichtlich nicht.\par
\par
Mal wieder ein paar Tests mit dem StorageExample machen. Das ist ja komplexer als die simple Loop.\par
Immer gleich schnell. Macht keinen Unterschied.\par
\par
Dann ist noch ein kniffliger Punkt:\par
\par
Wie soll das byte reversing zeug gehandelt werden?\par
Idealerweise gleich \'fcber eine Instanz und nicht wieder ein Flag, wie bisher.\par
Aber wo holt man sich die Instanz?\par
Von der XMemory? Oder holt man sich von der den MemoryAccessor und von dem ein toReversing() oder so?\par
Oder von einem Provider?\par
\par
Hm, mal \'fcberlegen ...\par
\par
Im Moment w\'fcrd ich sagen, dass man auf die MemoryAccessor Klasse direkt zugreifen kann und die dann eine toReversing Methode hat, wo sie eine nestete "reversing" Instanz raus gibt. Die wiederum gibt als reversing die originale zur\'fcck.\par
\par
Da f\'e4llt mir ein:\par
Ich muss noch testen, ob es einen Performance Unterschied macht, wenn die MemoryAccessor Instanz state hat ...\par
\par
\par
Und dann zerteil ich die XMemory Klasse jetzt mal in MemoryAccessor und einen allgemeinen teil ...\par
\par
\par
\par
2019-10-15\par
\par
Schnell noch den Test mit dem State auf dem vorherigen Branch commit. State im loop ver\'e4ndern und ausgeben, damit er auch wirklich verwendet wird.\par
Kein Performance Unterschied.\par
\par
Dann jetzt den Umbau weitermachen ...\par
>100 Compilerfehler/Methoden.\par
\par
Update 2019-10-16:\par
Zwischendrin alle m\'f6glichen Besprechungen, u.A. Oracle Clustering Consulting Meeting.\par
F\'fcrs Committen war abends um 19 Uhr auch keine Zeit mehr ...\par
\par
\par
2019-10-16\par
\par
XMemory Methoden zerlegen weitermachen.\par
\par
Hm. Alle Methoden, die ein Object mit memory offset akzeptieren, m\'fcssen gewrappt werden, wie beschrieben.\par
Bevor ich es noch 10 mal beschreib, mach ich das gleich mal:\par
\par
Logiktypen\par
MemoryObjectValuesCopier\par
MemoryObjectValuesSetter\par
MemoryObjectValuesHandler\par
definieren.\par
\par
Ne, das passt so nicht. Es muss ja auch noch den PersistenceStoreHandler geben. Mit Generics rumwursteln, nur um die eigentlich spezifischen Handling Typen mit Gewalt im allgemeinen memory package zu lassen, ist Quatsch.\par
Das m\'fcssen Peristence~ Varianten werden mit entsprechenden Creator Typen und deren Instanzen kennen dann intern einen MemoryAccessor.\par
\par
2019-10-17\par
\par
PersistenceMemoryObjectValuesSetter usw. weiterbauen.\par
\par
Hm. Verschiedene neue Designerkenntnisse w\'e4hrend dem bauen:\par
- Das hat auf der Persistence Ebene nix verloren, weil ja alles nur auf der Binary Ebene stattfindet. Muss ich verschieben.\par
- Ein Medium M angebeben bringt nix, sondern es gibt umgekehrt eine updateInstance Methode in der Binary Klasse, die ihren aktuellen Offset raussucht und \'fcbergibt.\par
- D.h. der BinaryMemoryObjectValuesSetter Typ br\'e4uchte doch wieder einen long offset anstatt M Medium.\par
- Aber eigentlich w\'e4re es noch besser, einen DBB + offset zu \'fcbergeben. Denn ein absoluter offset hei\'dft ohne Unsafe immer die selbstgebaute Speicherstruktur. Ein DBB ist ... \'e4h ... direkter. Und die 2 parameter statt 1 tun keinem weh.\par
\par
Und damit, Achtung lustig, kann es wieder ins Base package wandern, weil es keine Abh\'e4ngigkeiten mehr zu Typen der spezifischeren Packages hat.\par
Ach ne, fast: der PersistenceStoreHandler ist ja immer noch. Okay.\par
\par
Ach, so ein Mist: Binary kennt ja senien DBB gar nicht.\par
\par
Und das ist nicht so einfach:\par
- Ein ChunksBuffer kennt seinen eigenen DBB und arbeitet mit einem offset darauf. Ok. Das ist einfach.\par
- Ein LoadItem arbeitet aber zusammen mit vielen anderen auf demselben DBB, nur in jeweils segmentierten Bereichen.\par
\par
Jedem LoatItem eine R\'fcckreferenz auf den DBB zu geben w\'e4re teuer.\par
Immerhin gibt es f\'fcr jedes einzelne zu ladende Entity ein LoadItem.\par
\par
Jetzt k\'f6nnte man nat\'fcrlich sagen: okay, dann DBB raus und gleich explizit allokierter Speicher.\par
Dann ist aber das Problem: Wann wird der wieder freigegeben? Das sch\'f6ne am DBB ist halt, dass der implizit wieder freigibt, sobald er collectet wird.\par
Das w\'fcrde damit verloren gehen. Bl\'f6d.\par
\par
Mal \'fcberlegen.\par
\par
Also es gibt 2 M\'f6glichkeiten:\par
\par
1.)\par
Man kann beim MemoryAccessor einen DBB registrieren und kriegt eine absolute adresse zur\'fcck, auf der dann "normal" gearbeitet werden kann. Auch hier wieder intern nur mit WeakReference, damit der auch wirklich collectet wird.\par
Bzw. in der sun Implementierung w\'fcrde gar nichts passieren, sondern nur die allokierte MemoryAddress zur\'fcckgegeben.\par
\par
2.)\line Ich mach eine direkte Allkokierung im ChunksBuffer und Deallokier die explizit, wenn er nicht mehr ben\'f6tigt wird, d.h. am Ende eines Ladeprozesses.\par
Wobei das halt gef\'e4hrlich ist: momentan ist es so, dass der DBB valide ist, solang die ChunksBuffer Instanz existiert. Die h\'e4ngen automatisch lifecyclem\'e4\'dfig zusammen. Da kann nix schief gehen.\par
Wenn man so ein explizites Allokieren einbaut und irgendwann mal wird code so ge\'e4ndert, dass der danach noch auf die chunksbuffer daten zugreifen w\'fcrde, dann kracht die JVM.\par
Um sich mit genau solcher Komplexit\'e4t nicht rumschlagen zu m\'fcssen, gibt's ja das automatische Objekt-Lifecycle-Management der JVM und Referenzen auf DBBs sind eine wunderbare Art, direkte Speicheradressen dort reinzubinden.\par
\par
Genauer gesagt sollte #1 wohl implementiert werden mit einer speziellen HashTable int -> WeakReference<DirectByteBufferOwner>\par
Die Entries leiten direkt von WeakReference ab.\par
Und den Owner registrieren anstatt den DBB selbst, damit der lifecycle Zusammenhang garantiert gewahrt bleibt.\par
\par
Muss ich mal im Konzept updaten ...\par
\par
\par
2019-10-18\par
\par
Konzeptideen vom Nachhauseweg gestern aufschreiben: Ein zusammengesetzter Wert w\'fcrde bei einem \'dcberlauf des unteren eigentlich fatal verf\'e4lscht werden. ABER: das sign bit ist die Rettung.\par
Au\'dferdem Array statt int hashtable. Paar \'dcberlegungen zu effizienter Verwaltung von Leerstellen, rebuild, usw.\par
Das ist u.A. wieder das EfficientArrayChanges, an dem ich schon mal gebaut hab.\par
Das noch bissl verbessern.\par
\par
Dann also jetzt ValueCopier usw. wieder umstellen auf absolute Adresse.\par
\par
Aber saubbl\'f6d bei der Umstellerei ist echt:\par
Damit m\'fcsste es die komplette BinaryValueTranslators, die mit 2000 Zeilen bisher erst den allerwichtigsten Kern abdeckt, doppelt gemacht werden:\par
Einmal mit object base und einmal ohne.\par
Bisher wird die mit objeft base einfach f\'fcr beide F\'e4lle verwendet und im absoluten Fall einfach als object null gesetzt.\par
Evtl. sollte das auch so bleiben.\par
Man k\'f6nnte ja zumindest je nach plattform eine Exception werfen, wenn object nicht null ist.\par
Oder es k\'f6nnte sogar einfach eine interne ID f\'fcr ein Field sein und das Field wird dann benutzt, um die eigentliche operation zu machen.\par
Das w\'fcrde dann also hei\'dfen:\par
Es ist f\'fcr den Reflection Fall ein bisschen umst\'e4ndlicher Umweg, damit der Low-Level-Memory Fall performant l\'e4uft.\par
\par
Die BinaryObjectValue Dinger Kapselung w\'e4re immer noch sinnvoll daf\'fcr, diesen Umweg umgehen zu k\'f6nnen, sondern direkt Reflection per Field zu machen.\par
Gef\'e4llt mir. So mach ich das. Besser als zig tausend Zeilen code zu verdoppeln und tagelang das Legacy Type Mapping Value Translating umzureissen...\par
\par
\par
\par
2019-10-21\par
\par
Die beiden System-Info-methoden\par
- byteSizeInstance\par
- byteSizeObjectHeader\par
mach ich doch in die public API rein. Wenn die bei einer JVM nicht passen, kann man immer noch 0 zur\'fcckgeben oder eine Exception werfen oder so, aber solche Werte sind sinnvoll und sie allgemein rauszunehmen w\'fcrde die\par
Debug-Utility-Klasse unheimlich verkomplizieren.\par
\par
SunMemoryObjectValuesSetter\par
Creator daf\'fcr.\par
\par
Dabei aufgefallen:\par
- XMemory#objectFieldOffset gibts ja immer noch. Auch im Interface. Das soll eigentlich raus, eben hier rein. FIXME hinmachen.\par
- Hm. Dazu m\'fcsste auch die BinaryValueFunctions Klasser zerlegt bzw. in JVM-spezifische Implementierungen verschoben werden.\par
Dann k\'f6nnte man auch gleich das l\'e4stige switchByteOrder Flag wegbringen, indem viel fr\'fcher die passende MemoryAccessor Instanz \'fcbergeben wird.\par
Hm... w\'e4re das so dann eigentlich "sauberer", weil mehr objektorientierungskommunikationsm\'e4\'dfig oder unsauberer, weil implizierter und schwerer verst\'e4ndlich bei ansonsten irrelevanten Vorteilen (marginal weniger Code und irrelevant bessere Performance)...? Hm...\par
Ich mach jetzt mal den OOP Weg und schau, dass es sich in der Konsequenz mehr und mehr vereinfacht, dieses bl\'f6de Flag nicht immer rumschleppen zu m\'fcssen.\par
\par
\par
\par
2019-10-22\par
\par
Also beim SunMemoryObjectValuesSetter Implementieren kommen mir jetzt doch die zu vielen Baustellen in die Quere.\par
Ich zieh jetzt erst mal die 100 Compilerfehler im XMemory glatt, damit mal die Trennung zwischen dem und dem MemoryAccessor fertig ist, dann mach ich die architektonischen Sachen.\par
Evtl. ersetz ich dann gleich das nervige switchByteOrder Flag, das \'fcberall durchgezogen ist.\par
\par
\par
2019-10-23\par
\par
Weitermachen, die ~100 Compilerfehler glattzuziehen, indem die Methoden entsprechend in das Interface verschoben und verlinkt werden.\par
Dazwischen die \'fcblichen Ablenkungen und Fragen, Mails, usw.\par
\par
\par
2019-10-24\par
\par
Endlich XMemory fertig zerlegen und bissl aufr\'e4umen.\par
\par
XMemoryJDK8 anpassen bzw. Code umziehen.\par
\par
MemoryAccessor interface bissl kommentieren und aufr\'e4umen.\par
OMG da sind ja sogar bugs drin. Der setter f\'fcr byte-werte erwartet einen short. Der f\'fcr booleans einen char. Lololo. Fixen.\par
\par
MemoryAccessorReversing bauen.\par
\par
\par
2019-10-25\par
\par
MemoryAccessorReversing fertigstellen.\par
Die Methoden f\'fcr Arrays m\'fcssen mit einer Schleife extra programmiert werden. Wobei die float und double F\'e4lle wieder mal knifflig sind. Entsprechend kommentieren.\par
\par
Dabei aufgefallen:\par
so wie ein setObject(address) keinen Sinn macht, macht auch der Getter keinen Sinn. Und tats\'e4chlich wird der ja auch nie aufgerufen.\par
Darum gibt es diese Variante auch nicht in der Unsafe Klasse selbst.\par
Wieder was glernt. Also rausl\'f6schen und entsprechend kommentieren.\par
\par
Hm. Die CompareAndSwap Logik ist mit der generischen L\'f6sung nicht nachbildbar. Und MicroStream braucht die auch \'fcberhaupt nicht. Das hab ich einfach noch als \'dcberbleibsel aus meinem fr\'fcheren Unsafe Wrapping drin.\par
Ich lass das static im MemoryAccessorSun drin, aber l\'f6sch es aus dem Interface raus.\par
\par
Noch bissl aufr\'e4umen usw. Umbennenungs-TODO machen.\par
\par
\par
2019-10-28\par
\par
MemoryAccessorSun aufr\'e4umen analog zu MemoryAccessor interface.\par
Und XMemory auch.\par
Dabei paar Verbesserungen.\par
\par
So. Wie gehts von hier weiter...?\par
\par
Eigentlich sind mit dem neuen Konzept, dass der "offset" zu einem Object ein abstrakter Wert ist, hinter dem irgendein Konzept steht, Feldwerte zu adressieren, solange es nur konsistent befolgt wird, die neuen BinaryObjectValues~Handler Typen \'fcberfl\'fcssig. Man k\'f6nnte die zwar weiterhin lassen, um f\'fcr den Normalfall den umst\'e4ndlichen Lookup offset->Field in der generischen Implementierung (Android) zu umgehen, aber das ist eine optionale nice-to-have Optimierung, die man sp\'e4ter immer noch nachr\'fcsten kann. Ich mach ein TODO f\'fcr das Konzept in die Reflective TypeHandler rein und l\'f6sch die dann.\par
\par
Gemacht. Gel\'f6scht.\par
\par
Ah, und die SunMemoryObjectValuesSetter Implementierung muss dann wieder umgebaut werden.\par
Ach ne, passt: Es gibt noch BinaryValueFunctions und die Sun Dings Klasse war ein Klon davon. Also komplett l\'f6schen. Passt.\par
\par
\par
2019-10-29\par
\par
Jetzt aktuellen Stand der Implementierung testen.\par
Paar Code Format Cleanups.\par
\par
Ah: Paar Initialization Reihenfolge Probleme durch das Aufr\'e4umen. Wieder umstellen.\par
Sieht gut aus.\par
\par
Dann w\'e4re jetzt der n\'e4chste Schritt, den MemoryAccessorGeneric zu implementieren.\par
\par
Erster Teil: Den Field<->offset lookup bauen.\par
\par
Mal \'fcberlegen ...\par
Eigentlich ziemlich staight forward: f\'fcr ein zu mappendes Field sicherstellen, dass es f\'fcr seine declaring class einen Eintrag mit allen Feldern gibt und in diesen Feldern dann den Index raussuchen.\par
Nat\'fcrlich mit Pr\'fcfung auf Declaring class und name, denn Field Instanzen sind nicht einzigartig (und auf anderen VMs ist das schon gar nicht garantiert) und f\'fcr zwei Declaringclasses kann ein Feldname gleich sein.\par
\par
\'dcberlegen, ob es ein Problem ist, dass persistable fields und generisch erzeugte class Fields abweichen k\'f6nnen (z.B. w\'fcrde letzte transient fields enthalten).\par
Antwort: Nein. Dann h\'e4ngen halt in der generischen Registry ein paar Felder mehr drin, f\'fcr die der offset nie angefragt und damit nie verwendet wird. Kein Problem.\par
\par
\'dcberlegung, ob die Registrierung f\'fcr eine Klasse gleich automatisch alle Superklassen mitregistrieren sollte ...\par
Antwort: Nein, weil es gar nicht sicher ist, dass f\'fcr die jemals ein Entity gehandelt werden wird. Beispiel: Abstrakte Klassen. Oder auch pseudo-abstrakte.\par
\par
\'dcberlegung, ob je Klasse nur ihre declared fields registriert werden sollten, dann mit index offset vorn dran, um Redundanzen zu vermeiden.\par
Antwort: Nein, weil der offset->field lookup so schnell wie m\'f6glich gehen soll. Daf\'fcr muss jede Klasse ihr komplettes Set an Instanzfeldern registriert haben.\par
\par
Hm, Moment mal:\par
Die Declaring class verwenden ist nicht korrekt. Es kann sein, dass eine Entity class von einer anderen class ableitet und selbst gar keine Felder hat. Dann w\'fcrde sie nie einen Eintrag bekommen und der offset->Field lookup w\'fcrde eine Exception werfen. Nicht gut.\par
Das hei\'dft die ganze objectFieldOffset Logik braucht eine explizit \'fcbergebene Klasse.\par
Das verkompliziert den Normalfall mit der Unsafe Verwendung, aber das check ich mit einer Exception weg.\par
\par
Hm, oh Mann. F\'fcr die Implementierung der Variante ohne object class in der generischen Implementierung brauch ich jetzt extra eine "determineMostSpecificClass" Methode.\par
Fertig. Weitermachen ...\par
\par
Hm. Ich bin mir jetzt nicht mehr sicher, ob die ganzen byteSize querying methoden in eine MemoryAccessor Logik reingeh\'f6ren. Denn z.B. f\'fcr Android kann ich die alle nicht implementieren.\par
Sollten die evtl nur als static in die ~Sun implementierung rein? Oder wirklich \'fcberall nix zur\'fcckgeben? Oder nochmal extra kapseln?\par
hmhm...\par
\par
\par
2019-10-30\par
\par
Idee von Zuhause:\par
Ich schieb alle Querying Methoden, die ja sowieso eigentlich nur f\'fcr debugging ben\'f6tigt werden, in ein Interface "MemoryPropertiesQuerier" oder sowas in der Art.\par
Den kann man dann implementieren und dynamisch setzen, muss man aber nicht.\par
Die Frage w\'e4r dann noch, was mit so methoden wie das asBytes usw. ist. Die braucht man eigentlich auch nur f\'fcrs debugging und da gibt es aufgrund von ByteOrder Ansichten keine eindeutig richtige implementierung.\line Evtl. auch noch auslagern in irgendwelche Utils oder so.\par
\par
Ah: das asBytes kann ich mit einer Default-method generisch nachbilden, indem ich die set_longInBytes benutze. Passt.\par
\par
Bissl rum\'fcberlegen und rumbauen, was die beste Strategie f\'fcr die beiden Interfaces ist. Inklusive Konsistenzgarantie bei den Settern.\par
Gute L\'f6sung gefunden. Passt.\par
\par
Recherche zu ensureClassInitialized.\par
Simple Antwort: wenn nicht mit dem field base offset gearbeitet wird, braucht man das gar nicht. Also einfach als no-op implementieren mit entsprechendem Kommentar.\par
\par
throwUnchecked faken mit RuntimeException und Kommentar dazu. Geht halt nicht besser.\par
Hm... Moment mal: die Funktion wird nirgends ben\'f6tigt.\par
Wenn wirklich hab ich sie immer noch in der konkreten Sun Implementierung.\par
Also einfach aus dem MemoryAccessor rausschmeissen. Passt.\par
\par
Oh, Idee: Das ensureClassInitialized ist ind er Sun Implementierung nur daf\'fcr da, die offset base f\'fcr die field offset Bestimmung zu haben.\par
In der ~Generic Implementierung gibt es daf\'fcr ein \'c4quivalent: Die object fields der Klasse registrieren, die dann in der offset Bestimmung verwendet werden.\par
Wird zwar on demand auch gemacht, aber falls man wirklich mal mehrere Klassen vorab registrieren will (z.B. f\'fcr Tests oder um Performance-Spitzen zu vermeiden), kann man die verwenden.\par
Nice. So umbauen.\par
\par
Bissl thematisch aufr\'e4umen / umstrukturieren.\par
\par
So. Dann w\'e4r jetzt schon mal alles an Rand-ged\'f6ns fertig. Fehlen nur noch ca 100 TODOs f\'fcr die manuelle Speicherverwaltung.\par
Dazu Konzeptbeschreibung wieder ausgraben ...\par
\par
Los gehts mit extreme Bitschubsing ...\par
\par
Lieber einen Identifier und die slots boolean-table direkt in den DBB als header reinschreiben ...\par
\par
... Fertig. Und wieder rausreissen, weil sonst jede Memory Accessing Operationen den Header als Offset draufz\'e4hlen muss. Und das auch noch nach SmallChunk und BigChunk unterschieden. Das w\'e4r d\'e4mlich.\par
Stattdessen die Slots lieber als 3D-Array smallChunkSlots implementieren.\par
Das witzige/coole/effiziente an diesen extra Arrays ist: eigentlich wird zum Allokieren und Deallokieren nur auf denen gearbeitet. Der eigentliche DBB wird dabei nie angefasst.\par
\par
Iteratives Entwickeln ...\par
\par
\par
}
 