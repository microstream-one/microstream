{\rtf1\ansi\ansicpg1252\deff0\nouicompat\deflang1031{\fonttbl{\f0\fnil\fcharset0 Calibri;}{\f1\fnil\fcharset0 Courier New;}}
{\colortbl ;\red0\green0\blue255;\red165\green165\blue165;\red0\green255\blue0;\red255\green0\blue255;\red255\green0\blue0;\red0\green255\blue255;}
{\*\generator Riched20 10.0.17763}\viewkind4\uc1 
\pard\sl276\slmult1\f0\fs28\lang7 2019-09-30\par
\par
Erst mal Brain Storming, was alles beteiligt ist:\par
\par
1.) Direkte Memory Allocation, z.B. um Entitydaten im Storage-Layer zu cachen.\par
-> k\'f6nnte gel\'f6st werden \'fcber ein simples byte[] bzw. evtl #3\par
ABER: wie gemeinsamen Nenner f\'fcr API?\par
\par
2.) ByteBuffer bef\'fcllen. (Wenn's kein DirectByteBuffer ist, wird intern vor dem Schreiben erst noch in einen DBB umkopiert. Kein Witz)\par
-> k\'f6nnte gel\'f6st werden, indem die ByteBuffer API aufgerufen wird, ggf. mit ByteOrder immer auf die System-Byteorder gesetzt, damit da nicht sinnlos rumgedreht wird und beim auslesen wieder zur\'fcck.\par
\par
3.) Direkte Memory-Zugriffe auf eine blanke Speicheradresse \par
-> byte[][] mit simulierter absoluter speicheradresse (siehe Issue Beschreibung)\par
? Oder evtl. einem gro\'dfen DirectByteBuffer unterteilt in mehrere Abschnitte? hm ...\par
\par
4.) Direkte Memory-Zugriffe auf eine Instanz mit offset\par
-> K\'f6nnte gel\'f6st werden mit ValueHandler Interface mit unterschiedlicher Implementierung intern (siehe Issue Beschreibung)\par
\par
5.) ValueSetter und ValueStorer Signaturen haben direkte Speicheradresse\par
-> k\'f6nnte gel\'f6st werden mit #4: \'dcbergeordnete Architekturschicht, die diese Typen gar nicht erst n\'f6tig macht.\par
ABER: wie sollen dann ValueTranslator und die ganzen um-map-Legacy-Handler geschrieben werden? Auch noch weiter abstrahieren?\par
\par
\par
\par
Ich denke, das einfachste w\'e4re erst mal, #4 und #5 umzusetzen und dann zu schauen, wie der performance Unterschied von Unsafe zu Reflection und von Unsafe zu direkten DirectByteBuffer methodenaufrufen w\'e4re.\par
\par
\par
\par
2019-10-01\par
\par
Mal im eclipse suchen, wo \'fcberall Unsafe vorkommt.\par
Kommt (immer noch) nur in der Klasse XMemory vor, das hab ich ja schon mal konsolidiert.\par
Sehr sch\'f6n.\par
Das WIP Projekt z\'e4hlt ja nicht, das wird nicht deployt.\par
\par
Also ist die Frage, wo XMemory \'fcberall vorkommt.\par
\par
Insgesamt 890 Vorkommen, die ersetzt werden m\'fcssen.\par
30 Vorkommen im JDK8Internals Projekt. Die z\'e4hlen nicht, denn die k\'f6nnen so bleiben, weil das JDK8 garantiert eine zug\'e4ngliche Unsafe Klasse hat und immer haben wird.\par
50 Vorkommen im WIP. Die sind komplett egal.\par
\par
Der Rest muss ersetzt werden:\par
\par
Ca. 130 Vorkommen im Base Projekt. Die sind erst mal nicht wichtig, m\'fcssten letztendlich aber auch ersetzt/modularisiert werden. Hm...\par
\par
6 Vorkommen im Communication Projekt. Ignorier ich erst mal. Sp\'e4ter ...\par
\par
1 ganzes Vorkommen im Persistence Projekt, n\'e4mlich f\'fcr den Instantiator.\par
Das l\'e4sst sich nat\'fcrlich irgendwie verschieben/ersetzen, wobei das schon eine interessante Frage aufwirft:\par
Ohne low-level Instantierung braucht man die "Es muss einen default Konstruktor ohne logik drin geben"-Seuche als Einschr\'e4nkung f\'fcr die Verwendung des Frameworks.\par
Oder nat\'fcrlich einen expliziten Instantiator.\par
\par
Ca. 100 Vorkommen im Storage Projekt.\par
Manche davon sind trivial, z.B. DefaultBufferSize. Oder primtive Byte sizes. Bzw. diese Aufrufe k\'f6nnen sogar bleiben. Oder man trennt die irgendwie raus, ist ja egal.\par
Der Rest sind lauter Operationen mit absoluter Speicheradresse.\par
\par
Ca. 650 Vorkommen im PersistenceBinary Projekt.\par
Lustig lustig: Davon ca. 400 in der BinaryValueTranslators Monsterklasse. Bzw. das sind alles nur Funktionsimplementierungen f\'fcr das BinaryValueSetter interface, das einen Wert von einer absoluten Adresse zu einer relativen oder absoluten Adresse setzt.\par
\par
Und dann noch 250 "sonstige" Vorkommen. In BinaryHandler Implementierungen usw.\par
\par
Puh ...\par
Da w\'e4re es fast sinnvoller, erst mal ein paar damit \'fcberschneidende Issues vorzuziehen, weil die auf saubere Art eine ansonsten eher provisorische L\'f6sung bringen w\'fcrden.\par
Z.B. Die gescheite Abstraktion von BinaryFields. Evtl. sogar das ValueAccessor Konzept.\par
\par
Diese 890 Vorkommen erzeugen unterschiedlichen Aufwand:\par
Ein paar davon (sagen wir pauschal 89) sind unproblematisch, weil sie einfach Konstanten sind (default buffer size, binary length von primitives, usw.)\par
Der eine Instantiator ist trivial ersetzbar, aber erzeugt damit ein riesen Problem: Ohne das braucht man in jeder Entityklasse einen "passenden" Konstruktor oder einen vom Entity Designer manuell zu bauenden Instantiator.\par
Die 400 f\'fcr die BinaryValueTranslators lassen sich alle nach Schema F ersetzen, sobald es ein passendes Ersatzkonzept gibt. Das ist dann nur eine Flei\'dfarbeit.\par
Die restlichen 400 m\'fcssen je nach Fall analysiert und passend ersetzt/abstrahiert werden. Das werden nat\'fcrlich keine 400 Einzelf\'e4lle, sondern vielleicht 10 oder so Kategorien an Modularisierung/Abstraktion und dann m\'fcssen alle 400 F\'e4lle auf die passende L\'f6sung umgebaut werden.\par
\par
Au\'dferdem knifflig:\par
Was immer an Modularisierung/Abstraktion gemacht wird, sollte ja m\'f6glichst so sein, dass der Normalfall keine oder kaum Performance oder gar Funktionalit\'e4t verliert.\par
Da muss ich viel analysieren, \'fcberlegen, rumprobieren.\par
\par
Mal Issue updaten ...\par
\par
\par
Jetzt mal \'fcberlegen zu BinaryValueSetter Abstraktion.\par
Gibt eigentlich nur zwei Stellen: in Binary f\'fcr #updateFixedSize und in BinaryLegacyTypeHandlerRerouting zum binary values translaten.\par
Das zweite verschieb ich mal in eine Binary#copyMemory Methode.\par
\par
\par
Hm... interessante Idee:\par
Das byte[][] w\'e4re wahrscheinlich gar nicht n\'f6tig. DirectByteBuffer gibt es \'fcberall (z.B. in Android hier: {{\field{\*\fldinst{HYPERLINK https://android.googlesource.com/platform/libcore/+/jb-mr2-release/luni/src/main/java/java/nio/DirectByteBuffer.java }}{\fldrslt{https://android.googlesource.com/platform/libcore/+/jb-mr2-release/luni/src/main/java/java/nio/DirectByteBuffer.java\ul0\cf0}}}}\f0\fs28 ). Muss es wahrscheinlich sogar geben, weil ja die JDK public API eine entsprechende Methode (ByteBuffer#allocateDirect) besitzt.\par
\par
Es k\'f6nnte also reichen, an den entsprechenden Stellen anstatt einer blanken Adresse ein Paar von DBB+Offset Werten zu \'fcbergeben. Die normale Implementierung kann sich daraus ihre absolut Adresse errechnen und gl\'fccklich arbeiten, wie bisher. Implementierungen ohne Unsafe m\'fcssen halt jedes mal einen Lookup \'fcber den Offset machen.\par
\par
Ich muss mal schauen, ob das irgendwo API-technisch Probleme macht.\par
\par
Mal daf\'fcr bissl umbauen:\par
BinaryEntityDataReader#readBinaryEntityData(long)\par
umbauen zu\par
BinaryEntityDataReader#readBinaryEntities(DirectByteBuffer)\par
Macht intern dann das gleiche wie bisher, aber evtl. kann man dann nach ein paar solcher Umformungen die LoadItemErstellung abstrahieren und modularisieren.\par
Aaach, da kommt wieder das byteOrderSwitching rein. Aber das macht nix. Da muss nur einmal ein boolean gecheckt werden f\'fcr mehrere Entities auf einmal.\par
Oh, dann f\'e4llt sogar der Check auf die ByteOrder bei jedem einzelnen LoadItem weg. Das ist super!\par
\par
Oh, beim refactoren aufgefallen:\par
Der ChunksBuffer (speichern) hat bisher die DBBs bis limit ausgelesen.\par
Der ChunksWrapper (laden) hat bisher die DBBs bis position ausgelesen.\par
\par
Dann kann ich das nicht so abstrahieren, dass beide Varianten immer bis limit auslesen.\par
Es sei denn, dass im zweiten Fall position immer gleich limit ist.\par
Muss ich recherchieren ...\par
- Also der ChunksWrapper wrapt einfach nur ein Array an ByteBuffers. Darum hei\'dft er ja wrapper.\par
- Der wird nur verwendet in der BinaryFileSource. Dort l\'e4uft das ganze sehr simpel: limit wird auf die File L\'e4nge gesetzt und es wird solange eingelesen, bis position gleich limit ist. Also kann auch limit verwendet werden.\par
- Bei der eigentlichen Storage werden zum lesen ChunkBuffers verwendet. Dort wird mit position gearbeitet und am ende geflipt (limit = position, position = 0). Darum wird dort limit verwendet.\par
Fazit: in beiden F\'e4llen passt limit als grenze. Sollte das mal ein Problem machen, muss eben das limit entsprechend gesetzt werden.\par
\par
So. Umgebaut. Testen. Passt.\par
\par
Mal weiter schauen wegen Abstraktion...\par
Also man k\'f6nnte eine zweite BinaryLoadItem Implementierung machen, die die address als Position im DBB interpretiert und sich den entsprechenden DBB dazu merkt.\par
\par
Was das ganze letztendlich ziemlich kompliziert bis unm\'f6glich macht, ist, dass Binary halt kein Interface, sondern eine Klasse ist.\par
Dadurch st\'f6ren ein paar Methoden und Modularisierung w\'fcrde bedeuten, dort interface-ierte Logikinstanzen reinzuh\'e4ngen. Dann kann man gleich das ganze Ding zu einem Interface machen und sich mit einem Provider f\'fcr eine plattform das passende geben lassen.\par
\par
Hei\'dft: Der Auftrag f\'fcr morgen ist, das Ding durch ein interface zu ersetzen und zu checken, wie sich die performance ver\'e4ndert.\par
\par
Davon unabh\'e4ngig muss die API mal aufger\'e4umt werden, damit die ganzen direkten Addressen als implementierungsdetails verschwinden. Mit 2-3 Methoden hab ich das schon gemacht. Geht ganz gut.\par
Da kommt dann auch wieder das BinaryField Konzept ins Spiel ...\par
\par
\par
\par
 2019-10-02\par
\par
Binary zu interface umbauen.\par
\par
Puh... das wird ... viel Arbeit. Die Klasse ist 2000 Zeilen lang. Darin befinden sich viele statische, private und public Methoden. Jeweils unterteilt in welche mit absolutem Memory-Address, die m\'fcssen intern implementierungsspezifisch bleiben. Und welche, die "schon" oder von Haus aus Memory-Address-unabh\'e4ngig sind, die m\'fcssen ins Interface rein.\par
Dazu muss ich erst mal Methode f\'fcr Methode durchk\'e4mmen, was wo dazugeh\'f6rt. Dann f\'fcr die eine Gruppe zu interface Methoden erstellen. Und dann Aufruferklassen entsprechend umbauen.\par
\par
Die updateFixedSize h\'e4tte noch MemoryOffsets in Instanzen rein, was f\'fcr eine Unabh\'e4ngigkeit von Unsafe nicht sein darf. Aber die m\'fcsst ich erst mal mitziehen und dann sp\'e4ter das Konzept \'e4ndern (ValueSetters, die intern den Offset halten - oder dann eben das Field direkt f\'fcr eine reflection Operation).\par
\par
Au\'dferdem stellt sich wieder mal die Frage, ob "Binary" wirklich ein unsauber typisierter Kombityp sein muss, weil die API Bestandteile wirklich nicht auf "BinaryStoring", "BinaryReading" und "? extends Binary" typisiert werden k\'f6nnen...\par
\par
... Mehrere Besprechungen, Support f\'fcr CK und FH sp\'e4ter ist der Tag irgendwie um. Kaum was am Issue gearbeitet ...\par
\par
Hm... Die \'c4nderungen commit ich mal nicht, sondern stash sie nur oder so.\par
\par
\par
2019-10-03\par
\par
Feiertag\par
\par
\par
2019-10-04\par
\par
Binary Umwandlung zu interface weitermachen.\par
\par
Public Methods in interface hochziehen.\par
Sind immer noch 200 Compilerfehler.\par
Es h\'e4ngt halt einfach noch so wahnsinnig viel von direkten Speicheradressen ab.\par
Eigentlich m\'fcsste ich dann jetzt erst das alles in das interface hochziehen, auch wenn es da nicht hingeh\'f6rt und ich es sp\'e4ter wieder rausschmeissen muss, damit ich \'fcberhaupt erst mal checken kann, wie es performancem\'e4\'dfig ist, aus der abstrakten Klasse ein interface zu machen ...\par
Und wenn das passt, dann m\'fcsste ich alle Methoden mit direkter Adresse umstellen auf entweder offset relativ zu internem address state oder DBB+Offset Parameter, z.B. im Fall von modifyLoadItem.\par
\par
\par
Bevor ein Refactoring in diese Richtung gemacht werden kann, m\'fcssen erst mal alle Methoden umgebaut werden, die absolute Speicheradressen verwenden. Da gibt es sogar unabh\'e4ngig von diesem Issue hier schon ein TODO im Code: besser w\'e4re es, in einem ChunksBuffer (Ableitung von Binary zum Speichern von Daten) die contennt Adresse des aktuellen Entities intern zu halten und dann nur noch mit Offsets drauf zuzugreifen. Der Performance Aufwand daf\'fcr sollte nahe 0 sein, denn:\par
- Aktuell muss die ermittelte contentAddress ja zur\'fcckgegeben und im Aufruferkontext in einer lokalen Variable gespeichert werden. Das ist auch nicht gratis und das w\'fcrde mit einem internen Feld wegfallen.\par
- Auch jetzt muss auf diese contentAddress schon der offset draufaddiert werden, also keine Einsparung hier. Vielleicht ist das lesen der lokalen Variable etwas schneller als das lesen des Felds, aber mit CPU caches usw. bin ich mir da gar nicht mal so sicher. Muss getestet werden.\par
- Algorithmen, die n Elemente hintereinander speichern (f\'fcr collections, arrays, usw.), k\'f6nnen in Binary intern gemacht werden bzw. sind sie inzwischen eh schon gr\'f6\'dftenteils wenn nicht alle. Sollte noch irgendwas fehlen, verschieb ich das einfach zu den anderen. Dort ist dann die contentAddress wieder eine lokale Variable in der Methode, also performancem\'e4\'dfig kein unterschied zu der externen Variante, nur API-m\'e4\'dfig sauberer und dann eben, endlich, auch abstrahierbar.\par
\par
Also bau ich jetzt zuerst das um und dann schau ich mir wieder den aktuell versuchten Schritt an.\par
\par
Issue updaten.\par
\par
\par
\par
2019-10-07\par
\par
Schnell einen Test zum Swappen von DirectByteBuffer Inhalt machen f\'fcr eine Idee/Frage vom Wochenende.\par
Schnell fertig. Laufen lassen. JVM Crash.\par
Warum des?\par
Untersuchen ...\par
Ich kann keinen Fehler finden.\par
Weitere Tests daf\'fcr bauen.\par
Ergebnis:\par
Mein Code ist korrekt. Nur ab einer gewissen Gr\'f6\'dfe, evtl. irgendwie kurz vor der out of heap exception (die da eigentlich gekommen w\'e4re), crasht eine Methode im StringBuilder (!!! Nicht in meinem Code!) die JVM.\par
Liegt wahrscheinlich an dem @HotSpotIntrinsic Zeug.\par
Mit umgangenem Crash den eigentlich test machen. Gro\'dfe DBB Datenmengen brauchen eine extra JVM -XX:MaxDirectMemorySize Angabe. Aha, hab ich auch noch nicht gewusst. Sehr gute neue Erkenntnis.\par
\par
Jetzt API refactoring weitermachen ...\par
\par
Achja, die storeStringsAsList Methode.\par
Die so zu refactoren, wie ich mir das zuerst gedacht hatte, wird schwierig ...\par
Genau: Weil da n variable-length Listen gespeichert werden und jede gibt den variablen end-offset wert zur\'fcck.\par
Einfachste L\'f6sung: Ich lass die auf absoluter Adresse, aber mach sie intern.\par
Bzw. anders rum: die beiden aufgerufenen methoden bekommen interne, absolut arbeitende Varianten und die \'e4u\'dfere, public Methode wird relativ mit this.address + offset Aufruf der anderen.\par
\par
\par
\par
2019-10-08\par
\par
Halber Tag Besprechungen, u.A. Clustering Design, aber sehr produktiv.\par
\par
Sonderfallmethoden fertig bauen.\par
Alle "_Direct" und "_Offset" Marker wegrefactoren.\par
Alle internen methoden sauber auf "internal~" umbenennen.\par
\par
Jetzt m\'fcssen dann noch die "static methods using absolut an memory address that should actually not be here" Methoden aufger\'e4umt werden.\par
Mal versuchen mit der ersten ...\par
\par
Hm. Das sieht jetzt erst mal unm\'f6glich aus, weil die BinaryReferenceTraversers n\'e4mlich auch f\'fcr gecachte Entitydaten direkt im Speicher (allocateMemory) verwendet werden.\par
Wieder l\'f6schen.\par
Aber ich muss mal schauen. Evtl. kann ich die Methode anderweitig verstecken oder einfach in die Call site verschieben, dann ist sie im binary weg.\par
Wobei das eigentliche Problem ja ist: wie kriegt man den direkten Speicherzugriff auf direkt gecachte Entities weg?\par
Oder muss da jetzt doch die Trickserei mit eigener Logik hinter allocateMemory rein? F\'fcr so "blank" allokierten Speicher ist das wahrscheinlich der einzig gangbare weg ...\par
\par
\par
\par
2019-10-09\par
\par
Aktuell gepflegte Version ausgelagert in "Speicherverwaltungskonzept.rtf" im pers\'f6nlichen Verzeichnis \\MicroStream\\Planung\\priv#111 Unsafe Modularisierung\\.\par
\cf2 Super Idee von Zuhause und Arbeitsweg:\par
\par
Manuelle Off-Heap Memory Allokierung sollte/muss eigentlich auch mit Off-Heap Memory realisiert werden.\par
Das hei\'dft zwangsweise: DirectByteBuffer. Unsafe#allocate gibt es ja eben auf manchen Systemen (Android) nicht und es gibt nur diese beiden M\'f6glichkeiten.\par
Sollte ein DBB mal intern so implementiert sein, dass er gar keinen Off-Heap Memory allokiert, dann k\'f6nnen wir das eh nicht \'e4ndern.\par
DBBs sind der beste Versuch bzw. die einzige M\'f6glichkeit, auf eine Java-Standard-API-Weise Off-Heap Memory zu allokieren. Also die.\par
\par
Nun folgendes Problem:\par
Man k\'f6nnte f\'fcr jeden allokate Aufruf einfach einen eigenen, neuen DBB instanzieren.\par
F\'fcr gro\'dfe Speicherbereiche ist das absolut okay. Aber f\'fcr kleine (z.B. 24 Byte f\'fcr ein stateless Entity, das nur aus Header besteht), w\'e4re der Overhead gigantisch.\par
\par
Darum folgende Idee:\par
"Kleine" Speicherbereiche werden zu mehreren in einem DBB zusammengefasst.\par
"Gr\'f6\'dfere" Speicherbereiche bekommen jeweils einen exklusiven DBB.\par
Cooler Nebeneffekt: ChunksBuffers zum Storen bekommen immer einen eigenen DBB. Der Lese-Fall (Entities laden und GC) ist performancem\'e4\'dfig nicht so kritisch in einer Anwendungskonzept, wo der In-Memory Objektgraph die Prim\'e4re Datenquelle darstellt.\par
\par
Die Idee ist nur, den DBB-Overhead je Item gegen 0 gegen zu lassen. Es muss nicht super-duper-intelligent die Zahl der DBBs auf einem absolut n\'f6tigen Minum gehalten werden oder sowas.\par
\par
Konkret zum Algorithmus:\par
\par
Rahmenbedingungen:\par
Man kann per DBB nur maximal Integer.MAX_VALUE an Speicherbereich reservieren. Total hinrissige Beschr\'e4nkung einfach nur, weil der ByteBuffer eine toArray Methode hat, aber in diesem Fall ist es ganz n\'fctzlich.\par
Also die maximal auf einmal reservierbare Speichergr\'f6\'dfe ist MAX_INT.\par
\par
Speicherbereiche werden aber als long addressiert. Also hat man 4 Byte "frei", um dort eine frei ausgedachte Verwaltung abzubilden.\par
Und zwar folgenderma\'dfen:\par
\par
Die unteren 4 byte werden als signed integer als index in den DBB (i) interpretiert.\par
Die oberen 4 byte werden als signed integer als Verwaltungsindex (v) interpretiert.\par
\par
Das Sign-Bit von v wird f\'fcr eine Fallunterscheidung verwendet:\par
Positiv bedeutet:\par
Der Wert identifiziert einen gro\'dfen Einzel-DBB Speicherbereich.\par
Eigentlich reicht daf\'fcr eine fortlaufende ID beginnend bei 1, die in ein BigEntry[] zeigt. Wobei beim Allokieren von index 1 an das array nach leeren Eintr\'e4gen durchsucht wird.\par
Das Array wird dynamisch gewachsen, wobei jede Gr\'f6\'dfen\'e4nderung einen upperThreshold und einen lowerThreshold wert cacht, gegen den beim allokieren und deallokieren mit dem bisher h\'f6chsten Wert getestet und ggf. rebuildet wird.\par
\par
So ein BigEntryenth\'e4lt die Referenz auf den DBB und Metadaten f\'fcr die Verwaltung. ... Hm... Was eigentlich bei einem Einzel-DBB?. Evtl. ist der Entry \'fcberfl\'fcssig.\par
D.h. man kann maximal 2,1~ Milliarden "gro\'dfe" DBBs allokieren. Das sollte reichen.\par
\par
Warum beginnend bei index 1? Weil eine generische Adresse von 0 nat\'fcrlich weiterhin "wie normal" ein nullpointer sein muss, der einen Fehler wird und nicht einfach ein generischer Indexwert, der auf den DBB mit index 0 zeigt.\par
Dieser eine Platz ist dann einfach immer leer ("da wohnt null"), aber das ist ja platzm\'e4\'dfig egal.\par
\par
\par
Negativ bedeutet:\par
Der Wert (mal *1) identifiziert einen einzelnen "kleinen" Eintrag in einem Multi-Eintrag-DBB Speicherbereich.\par
Die untersten 12 Bit definieren die L\'e4nge des allokierten Speicherbereichs und damit den Index in der Lookup Table (siehe unten).\par
Die n\'e4chsten 12 Bit definieren den Index der zweiten Dimension in der Lookup-Table (siehe unten).\par
Die obersten 7 bit identifiziert als unsigned int die Position im DBB. Nicht index, sondern index = position * L\'e4nge.\par
\par
Lookup-Table:\par
Ein Entry[][], das in der ersten Dimension immer die fest L\'e4nge 4096 (2^12) hat.\par
Der Index entspricht der L\'e4nge der allokierten Speicherbereiche. Also z.B. alle Speicherbereiche der L\'e4nge 197 werden verwaltet im Index 197.\par
Die zweite Dimension (nested Entry[] Array) ist ein ArrayList-artig wachsendes Array an Entry Instanzen.\par
\par
Ein Entry besteht aus:\par
- Referenz auf den DBB\par
- boolean[], das aussagt, ob der Eintrag an Position i gerade allokiert ist oder nicht.\par
Wobei dieses Array als header im DBB stehen k\'f6nnte. Mit einem initialen int, wie viele Eintr\'e4ge der DBB hat, d.h. wie lang das boolean-array ist.\par
Und einen size counter, um das deallokieren zu erleichtern.\par
Dann br\'e4uchte man gar keine Entry Zwischenklasse und das ganze w\'e4re etwas performanter.\par
\par
Allokieren und deallokieren liegt dann nat\'fcrlich auf der Hand:\par
usage-array checken (und ggf. exception).\par
\'fcbergebene Addresse in einen Offset in den DBB \'fcbersetzen und Bounds checken.\par
Wenn der size counter auf 0 ist, dann den ganzen DBB deallokieren und im nested array ausnullen.\par
\par
\par
Das w\'e4re ein off-heap-m\'e4\'dfig korrektes mittel, mit nur java public API (-> Android) eine absolute Speicheradressierung in manuell allokiertem Speicher zu machen.\par
Auf Entities zugreifen (base + offset) kann man damit nat\'fcrlich nicht, das braucht eine Umformung zu Reflection.\par
Auch auf explizite DBBs kann man damit nicht zugreifen. Die brauchen auch eine Umformung (DBB Referenz + Offset)\par
\cf0\par
\par
Das muss ich dann mal so implementieren, wenn ich alle kleineren Details refactort hab.\par
\par
\par
Jetzt wieder zur\'fcck zu den Methoden mit absoluter Speicheradressierung, die es eigentlich nicht geben darf.\par
\par
\par
Geht voran, aber das wird alles knifflig ...\par
\par
Und:\par
\par
Ich sollte mal ein konsistentes Benamungskonzept \'fcberlegen, wie man public API (mit relativem offset) von interner API (mit absolutem offset) unterscheiden kann.\par
\par
z.B:\par
get vs read\par
set vs store\par
\par
Ich w\'fcrd eigentlich sagen: read und store public, get und set intern.\par
Aber es gibt noch viele andere Methoden, die get~ anstatt read~ hei\'dfen. Die dann auch alle auf read~ umbenennen?\par
Aber eigentlich schon, weil der Binary Typ deutlich aussagen soll: Hier wird bin\'e4r gelesen und gestoret. Auf welche "magische" oder triviale Weise das intern dann auch immer stattfinden mag.\par
\par
F\'fcr arrays dann eher sowas wie:\par
update vs copy\par
build\par
\par
\par
\par
\par
2019-10-10\par
\par
Achja, die Benamungssache ist noch.\par
\par
Und noch die letzten paar Methoden mit absoluter Adresse rauswerfen.\par
Das geht eigentlich nicht, aber mit folgender einfacher Idee evtl doch:\par
Die Methoden zu simplen Arithmetik-Methoden reduzieren und den eigentlichen get_long Aufruf direkt in die Aufruferstelle schreiben. In diesen Klassen sind eh schon X-fach solche Aufrufe drin, da kommt es auf die paar mehr auch nicht mehr an.\par
Daf\'fcr w\'e4re dann die Binary Klasse sauber.\par
Das mach ich mal so.\par
\par
Das modifyLoadItem ist auch noch. Hm. Das \'e4nder ich auf einen \'fcbergebenen ByteBuffer und Offset. Dann passt das.\par
Die copyMemory Methode benutzt auch noch eine absolute Adresse. Umbauen.\par
\par
Bei den drei verbleibenden Methoden, den getEntity~ f\'fcr OID, TID, LEN ist das aber problematisch:\par
Das sind insgesamt 12-19 Stellen, insgesamt ca. 50. Die alle durch einen expliziten get_long Aufruf zu ersetzen ist strukturell widersinnig. Danach m\'fcssten diese 50 Stellen sofort wieder konsolidiert werden in eine statische Util-Klasse.\par
Also m\'fcsste das eine andere sein, eine "AbsoluteEntityAddressing". Aber das verschiebt das Problem ja nur, weil letztendlich auch die modularisiert werden m\'fcsste.\par
\par
Das Problem ist: Wie kann man alle Verwendungen der Unsafe Klasse modularisieren? Insbesondere die von statischen Methoden (XMemory...).\par
Man kann nat\'fcrlich einfach eine andere XMemory Klasse verwenden, die intern ihr eigenes Speichermanagement macht f\'fcr absolute Zugriffe. Das geht.\par
1.) Das geht aber nur f\'fcr die Logik, die sich so eine absolute Speicheradresse von einem kontextlosen/direkten "allocateMemory" Aufruf geholt hat.\par
2.) Logik, die per Adresse direkt auf einen DBB zugreift, muss so umgebaut werden, dass sie DBB + offset \'fcbergibt. So wie ich das bei modifyLoadItem und copyMemory gerade gemacht hab.\par
3.) Und Logik, die per reference + offset direkt auf instanzen zugreift, muss komplett eigenst\'e4ndig abstrahiert und modularisiert werden, damit man eine Alternative bauen kann, die Reflection anstatt DMA verwendet.\par
\par
Die Frage ist auch, ob man wirklich die Klasse tauschen muss, oder ob man den Memory-Zugriff \'fcber ein interface in eine instanz modularisieren kann.\par
Unsafe selbst ist witzigerweise ja auch eine Instanz, obwohl sie nur statische Funktionalit\'e4t bietet. Evtl. optimiert die JVM unbenutzte "this" argumente raus, dann w\'fcrde es keine rolle spielen.\par
Muss ich testen ...\par
\par
\par
\par
2019-10-11\par
\par
Also ich mach jetzt, einfach mal um Erfahrungs- bzw. Messwerte zu bekommen, folgendes:\line - Messen, wie lang so ein \'fcblicher Durchlauf an store und load jetzt braucht\line - Einfach mal hardgecodet in XMemory die Speicherzugriffsmethoden intern mit einer interface instanz modularisieren und schauen, was der Unterschied ist.\par
\par
Alle m\'f6glichen Besprechungen zwischendrin ...\par
\par
Testen ...\par
Oh. Erst mal JVM Crash. Debuggen. Ah, absoluten statt relativen Offset \'fcbergeben. Fixen. Testen. Passt.\par
Jetzt zu performance rumprobieren ...\par
\par
Hm. Also das variiert phasenweise. Mal ist die hardgecodete Variante meist 500 ms, manchmal bis zu 750, dann \'e4nder ich auch die dynamische und hab meist 750, dann \'e4nder ich auf die hardgecodete zur\'fcck und hab auch meist 750.\par
\par
So wird das nix. Evtl. wegen zu viel "noise" im System.\par
Muss ich doch eine main-methode mit spezifisch diesem Test bauen.\par
\par
\par
\par
Also das kann eigentlich nicht sein, aber ich kann es so reproduzieren mit ansonsten identischem Code:\par
\par
1 Million longs in einer for Schleife direkt in den Memory setzen.\par
10K warmup runs\par
10K hot runs\par
\par
Ergebnisse (SEHR konstant, mit Varianz von 0 bis -5\'b5s) :\par
\par
\par
hardcoded Aufruf von XMemory.VM.putLong()\par
average: 425\'b5s\par
minimum: 380\'b5s\par
\par
static final MemoryAccessor mit XMemory.VM.putLong() Aufruf in MemoryAccessor$Sun\par
average: 425\'b5s\par
minimum: 380\'b5s\par
\par
static MemoryAccessor mit XMemory.VM.putLong() Aufruf in MemoryAccessor$Sun gesetzt zur Laufzeit\par
average: 366\'b5s\par
minimum: 315\'b5s\par
\par
Also das flexibelste, am wenigsten eingeschr\'e4nkteste und damit am wenigsten voraussehbar optimierbar, das eigentlich einfach nur ein Umweg ist, ist SCHNELLER der als der direkte aufruf.\par
WTF?!\par
\par
Also das hei\'dft dann eigentlich eins:\par
Man kann einfach direkt in der XMemory Klasse die Unsafe Verwendung rausmodularisieren.\par
Krass\par
\par
\par
Wenn ich die Schleife in eine "hot" Methode verpack, dann sind alle drei Varianten so schnell wie die schnellste.\par
Scheinbar greift in dem oberen Beispiel eine JVM Optimierung in den ersten beiden F\'e4llen nicht richtig.\par
\par
Witzig auch:\par
Im Idealfall braucht ein long setzen 0,3 ns.\par
Auf dem 4,20 GHz Rechner also so grob 1 CPU cycle pro Aufruf.\par
Das kann doch eigentlich nicht sein: man kann doch nicht mit 1 Cycle 2 Werte verarbeiten, einen Sprung machen und den Wert dort hin schreiben. Selbst wenn's Level1 Cache ist...\par
Oder liegt das an Pipelining im CPU oder so?\par
\par
\par
\par
2019-10-14\par
\par
Noch ein paar weitere Tests.\par
Z.B., ob es einen unterschied macht, wenn die MemoryAccessor Instanz stack-escaping ist.\par
Offensichtlich nicht.\par
\par
Mal wieder ein paar Tests mit dem StorageExample machen. Das ist ja komplexer als die simple Loop.\par
Immer gleich schnell. Macht keinen Unterschied.\par
\par
Dann ist noch ein kniffliger Punkt:\par
\par
Wie soll das byte reversing zeug gehandelt werden?\par
Idealerweise gleich \'fcber eine Instanz und nicht wieder ein Flag, wie bisher.\par
Aber wo holt man sich die Instanz?\par
Von der XMemory? Oder holt man sich von der den MemoryAccessor und von dem ein toReversing() oder so?\par
Oder von einem Provider?\par
\par
Hm, mal \'fcberlegen ...\par
\par
Im Moment w\'fcrd ich sagen, dass man auf die MemoryAccessor Klasse direkt zugreifen kann und die dann eine toReversing Methode hat, wo sie eine nestete "reversing" Instanz raus gibt. Die wiederum gibt als reversing die originale zur\'fcck.\par
\par
Da f\'e4llt mir ein:\par
Ich muss noch testen, ob es einen Performance Unterschied macht, wenn die MemoryAccessor Instanz state hat ...\par
\par
\par
Und dann zerteil ich die XMemory Klasse jetzt mal in MemoryAccessor und einen allgemeinen teil ...\par
\par
\par
\par
2019-10-15\par
\par
Schnell noch den Test mit dem State auf dem vorherigen Branch commit. State im loop ver\'e4ndern und ausgeben, damit er auch wirklich verwendet wird.\par
Kein Performance Unterschied.\par
\par
Dann jetzt den Umbau weitermachen ...\par
>100 Compilerfehler/Methoden.\par
\par
Update 2019-10-16:\par
Zwischendrin alle m\'f6glichen Besprechungen, u.A. Oracle Clustering Consulting Meeting.\par
F\'fcrs Committen war abends um 19 Uhr auch keine Zeit mehr ...\par
\par
\par
2019-10-16\par
\par
XMemory Methoden zerlegen weitermachen.\par
\par
Hm. Alle Methoden, die ein Object mit memory offset akzeptieren, m\'fcssen gewrappt werden, wie beschrieben.\par
Bevor ich es noch 10 mal beschreib, mach ich das gleich mal:\par
\par
Logiktypen\par
MemoryObjectValuesCopier\par
MemoryObjectValuesSetter\par
MemoryObjectValuesHandler\par
definieren.\par
\par
Ne, das passt so nicht. Es muss ja auch noch den PersistenceStoreHandler geben. Mit Generics rumwursteln, nur um die eigentlich spezifischen Handling Typen mit Gewalt im allgemeinen memory package zu lassen, ist Quatsch.\par
Das m\'fcssen Peristence~ Varianten werden mit entsprechenden Creator Typen und deren Instanzen kennen dann intern einen MemoryAccessor.\par
\par
2019-10-17\par
\par
PersistenceMemoryObjectValuesSetter usw. weiterbauen.\par
\par
Hm. Verschiedene neue Designerkenntnisse w\'e4hrend dem bauen:\par
- Das hat auf der Persistence Ebene nix verloren, weil ja alles nur auf der Binary Ebene stattfindet. Muss ich verschieben.\par
- Ein Medium M angebeben bringt nix, sondern es gibt umgekehrt eine updateInstance Methode in der Binary Klasse, die ihren aktuellen Offset raussucht und \'fcbergibt.\par
- D.h. der BinaryMemoryObjectValuesSetter Typ br\'e4uchte doch wieder einen long offset anstatt M Medium.\par
- Aber eigentlich w\'e4re es noch besser, einen DBB + offset zu \'fcbergeben. Denn ein absoluter offset hei\'dft ohne Unsafe immer die selbstgebaute Speicherstruktur. Ein DBB ist ... \'e4h ... direkter. Und die 2 parameter statt 1 tun keinem weh.\par
\par
Und damit, Achtung lustig, kann es wieder ins Base package wandern, weil es keine Abh\'e4ngigkeiten mehr zu Typen der spezifischeren Packages hat.\par
Ach ne, fast: der PersistenceStoreHandler ist ja immer noch. Okay.\par
\par
Ach, so ein Mist: Binary kennt ja senien DBB gar nicht.\par
\par
Und das ist nicht so einfach:\par
- Ein ChunksBuffer kennt seinen eigenen DBB und arbeitet mit einem offset darauf. Ok. Das ist einfach.\par
- Ein LoadItem arbeitet aber zusammen mit vielen anderen auf demselben DBB, nur in jeweils segmentierten Bereichen.\par
\par
Jedem LoatItem eine R\'fcckreferenz auf den DBB zu geben w\'e4re teuer.\par
Immerhin gibt es f\'fcr jedes einzelne zu ladende Entity ein LoadItem.\par
\par
Jetzt k\'f6nnte man nat\'fcrlich sagen: okay, dann DBB raus und gleich explizit allokierter Speicher.\par
Dann ist aber das Problem: Wann wird der wieder freigegeben? Das sch\'f6ne am DBB ist halt, dass der implizit wieder freigibt, sobald er collectet wird.\par
Das w\'fcrde damit verloren gehen. Bl\'f6d.\par
\par
Mal \'fcberlegen.\par
\par
Also es gibt 2 M\'f6glichkeiten:\par
\par
1.)\par
Man kann beim MemoryAccessor einen DBB registrieren und kriegt eine absolute adresse zur\'fcck, auf der dann "normal" gearbeitet werden kann. Auch hier wieder intern nur mit WeakReference, damit der auch wirklich collectet wird.\par
Bzw. in der sun Implementierung w\'fcrde gar nichts passieren, sondern nur die allokierte MemoryAddress zur\'fcckgegeben.\par
\par
2.)\line Ich mach eine direkte Allkokierung im ChunksBuffer und Deallokier die explizit, wenn er nicht mehr ben\'f6tigt wird, d.h. am Ende eines Ladeprozesses.\par
Wobei das halt gef\'e4hrlich ist: momentan ist es so, dass der DBB valide ist, solang die ChunksBuffer Instanz existiert. Die h\'e4ngen automatisch lifecyclem\'e4\'dfig zusammen. Da kann nix schief gehen.\par
Wenn man so ein explizites Allokieren einbaut und irgendwann mal wird code so ge\'e4ndert, dass der danach noch auf die chunksbuffer daten zugreifen w\'fcrde, dann kracht die JVM.\par
Um sich mit genau solcher Komplexit\'e4t nicht rumschlagen zu m\'fcssen, gibt's ja das automatische Objekt-Lifecycle-Management der JVM und Referenzen auf DBBs sind eine wunderbare Art, direkte Speicheradressen dort reinzubinden.\par
\par
Genauer gesagt sollte #1 wohl implementiert werden mit einer speziellen HashTable int -> WeakReference<DirectByteBufferOwner>\par
Die Entries leiten direkt von WeakReference ab.\par
Und den Owner registrieren anstatt den DBB selbst, damit der lifecycle Zusammenhang garantiert gewahrt bleibt.\par
\par
Muss ich mal im Konzept updaten ...\par
\par
\par
2019-10-18\par
\par
Konzeptideen vom Nachhauseweg gestern aufschreiben: Ein zusammengesetzter Wert w\'fcrde bei einem \'dcberlauf des unteren eigentlich fatal verf\'e4lscht werden. ABER: das sign bit ist die Rettung.\par
Au\'dferdem Array statt int hashtable. Paar \'dcberlegungen zu effizienter Verwaltung von Leerstellen, rebuild, usw.\par
Das ist u.A. wieder das EfficientArrayChanges, an dem ich schon mal gebaut hab.\par
Das noch bissl verbessern.\par
\par
Dann also jetzt ValueCopier usw. wieder umstellen auf absolute Adresse.\par
\par
Aber saubbl\'f6d bei der Umstellerei ist echt:\par
Damit m\'fcsste es die komplette BinaryValueTranslators, die mit 2000 Zeilen bisher erst den allerwichtigsten Kern abdeckt, doppelt gemacht werden:\par
Einmal mit object base und einmal ohne.\par
Bisher wird die mit objeft base einfach f\'fcr beide F\'e4lle verwendet und im absoluten Fall einfach als object null gesetzt.\par
Evtl. sollte das auch so bleiben.\par
Man k\'f6nnte ja zumindest je nach plattform eine Exception werfen, wenn object nicht null ist.\par
Oder es k\'f6nnte sogar einfach eine interne ID f\'fcr ein Field sein und das Field wird dann benutzt, um die eigentliche operation zu machen.\par
Das w\'fcrde dann also hei\'dfen:\par
Es ist f\'fcr den Reflection Fall ein bisschen umst\'e4ndlicher Umweg, damit der Low-Level-Memory Fall performant l\'e4uft.\par
\par
Die BinaryObjectValue Dinger Kapselung w\'e4re immer noch sinnvoll daf\'fcr, diesen Umweg umgehen zu k\'f6nnen, sondern direkt Reflection per Field zu machen.\par
Gef\'e4llt mir. So mach ich das. Besser als zig tausend Zeilen code zu verdoppeln und tagelang das Legacy Type Mapping Value Translating umzureissen...\par
\par
\par
\par
2019-10-21\par
\par
Die beiden System-Info-methoden\par
- byteSizeInstance\par
- byteSizeObjectHeader\par
mach ich doch in die public API rein. Wenn die bei einer JVM nicht passen, kann man immer noch 0 zur\'fcckgeben oder eine Exception werfen oder so, aber solche Werte sind sinnvoll und sie allgemein rauszunehmen w\'fcrde die\par
Debug-Utility-Klasse unheimlich verkomplizieren.\par
\par
SunMemoryObjectValuesSetter\par
Creator daf\'fcr.\par
\par
Dabei aufgefallen:\par
- XMemory#objectFieldOffset gibts ja immer noch. Auch im Interface. Das soll eigentlich raus, eben hier rein. FIXME hinmachen.\par
- Hm. Dazu m\'fcsste auch die BinaryValueFunctions Klasser zerlegt bzw. in JVM-spezifische Implementierungen verschoben werden.\par
Dann k\'f6nnte man auch gleich das l\'e4stige switchByteOrder Flag wegbringen, indem viel fr\'fcher die passende MemoryAccessor Instanz \'fcbergeben wird.\par
Hm... w\'e4re das so dann eigentlich "sauberer", weil mehr objektorientierungskommunikationsm\'e4\'dfig oder unsauberer, weil implizierter und schwerer verst\'e4ndlich bei ansonsten irrelevanten Vorteilen (marginal weniger Code und irrelevant bessere Performance)...? Hm...\par
Ich mach jetzt mal den OOP Weg und schau, dass es sich in der Konsequenz mehr und mehr vereinfacht, dieses bl\'f6de Flag nicht immer rumschleppen zu m\'fcssen.\par
\par
\par
\par
2019-10-22\par
\par
Also beim SunMemoryObjectValuesSetter Implementieren kommen mir jetzt doch die zu vielen Baustellen in die Quere.\par
Ich zieh jetzt erst mal die 100 Compilerfehler im XMemory glatt, damit mal die Trennung zwischen dem und dem MemoryAccessor fertig ist, dann mach ich die architektonischen Sachen.\par
Evtl. ersetz ich dann gleich das nervige switchByteOrder Flag, das \'fcberall durchgezogen ist.\par
\par
\par
2019-10-23\par
\par
Weitermachen, die ~100 Compilerfehler glattzuziehen, indem die Methoden entsprechend in das Interface verschoben und verlinkt werden.\par
Dazwischen die \'fcblichen Ablenkungen und Fragen, Mails, usw.\par
\par
\par
2019-10-24\par
\par
Endlich XMemory fertig zerlegen und bissl aufr\'e4umen.\par
\par
XMemoryJDK8 anpassen bzw. Code umziehen.\par
\par
MemoryAccessor interface bissl kommentieren und aufr\'e4umen.\par
OMG da sind ja sogar bugs drin. Der setter f\'fcr byte-werte erwartet einen short. Der f\'fcr booleans einen char. Lololo. Fixen.\par
\par
MemoryAccessorReversing bauen.\par
\par
\par
2019-10-25\par
\par
MemoryAccessorReversing fertigstellen.\par
Die Methoden f\'fcr Arrays m\'fcssen mit einer Schleife extra programmiert werden. Wobei die float und double F\'e4lle wieder mal knifflig sind. Entsprechend kommentieren.\par
\par
Dabei aufgefallen:\par
so wie ein setObject(address) keinen Sinn macht, macht auch der Getter keinen Sinn. Und tats\'e4chlich wird der ja auch nie aufgerufen.\par
Darum gibt es diese Variante auch nicht in der Unsafe Klasse selbst.\par
Wieder was glernt. Also rausl\'f6schen und entsprechend kommentieren.\par
\par
Hm. Die CompareAndSwap Logik ist mit der generischen L\'f6sung nicht nachbildbar. Und MicroStream braucht die auch \'fcberhaupt nicht. Das hab ich einfach noch als \'dcberbleibsel aus meinem fr\'fcheren Unsafe Wrapping drin.\par
Ich lass das static im MemoryAccessorSun drin, aber l\'f6sch es aus dem Interface raus.\par
\par
Noch bissl aufr\'e4umen usw. Umbennenungs-TODO machen.\par
\par
\par
2019-10-28\par
\par
MemoryAccessorSun aufr\'e4umen analog zu MemoryAccessor interface.\par
Und XMemory auch.\par
Dabei paar Verbesserungen.\par
\par
So. Wie gehts von hier weiter...?\par
\par
Eigentlich sind mit dem neuen Konzept, dass der "offset" zu einem Object ein abstrakter Wert ist, hinter dem irgendein Konzept steht, Feldwerte zu adressieren, solange es nur konsistent befolgt wird, die neuen BinaryObjectValues~Handler Typen \'fcberfl\'fcssig. Man k\'f6nnte die zwar weiterhin lassen, um f\'fcr den Normalfall den umst\'e4ndlichen Lookup offset->Field in der generischen Implementierung (Android) zu umgehen, aber das ist eine optionale nice-to-have Optimierung, die man sp\'e4ter immer noch nachr\'fcsten kann. Ich mach ein TODO f\'fcr das Konzept in die Reflective TypeHandler rein und l\'f6sch die dann.\par
\par
Gemacht. Gel\'f6scht.\par
\par
Ah, und die SunMemoryObjectValuesSetter Implementierung muss dann wieder umgebaut werden.\par
Ach ne, passt: Es gibt noch BinaryValueFunctions und die Sun Dings Klasse war ein Klon davon. Also komplett l\'f6schen. Passt.\par
\par
\par
2019-10-29\par
\par
Jetzt aktuellen Stand der Implementierung testen.\par
Paar Code Format Cleanups.\par
\par
Ah: Paar Initialization Reihenfolge Probleme durch das Aufr\'e4umen. Wieder umstellen.\par
Sieht gut aus.\par
\par
Dann w\'e4re jetzt der n\'e4chste Schritt, den MemoryAccessorGeneric zu implementieren.\par
\par
Erster Teil: Den Field<->offset lookup bauen.\par
\par
Mal \'fcberlegen ...\par
Eigentlich ziemlich staight forward: f\'fcr ein zu mappendes Field sicherstellen, dass es f\'fcr seine declaring class einen Eintrag mit allen Feldern gibt und in diesen Feldern dann den Index raussuchen.\par
Nat\'fcrlich mit Pr\'fcfung auf Declaring class und name, denn Field Instanzen sind nicht einzigartig (und auf anderen VMs ist das schon gar nicht garantiert) und f\'fcr zwei Declaringclasses kann ein Feldname gleich sein.\par
\par
\'dcberlegen, ob es ein Problem ist, dass persistable fields und generisch erzeugte class Fields abweichen k\'f6nnen (z.B. w\'fcrde letzte transient fields enthalten).\par
Antwort: Nein. Dann h\'e4ngen halt in der generischen Registry ein paar Felder mehr drin, f\'fcr die der offset nie angefragt und damit nie verwendet wird. Kein Problem.\par
\par
\'dcberlegung, ob die Registrierung f\'fcr eine Klasse gleich automatisch alle Superklassen mitregistrieren sollte ...\par
Antwort: Nein, weil es gar nicht sicher ist, dass f\'fcr die jemals ein Entity gehandelt werden wird. Beispiel: Abstrakte Klassen. Oder auch pseudo-abstrakte.\par
\par
\'dcberlegung, ob je Klasse nur ihre declared fields registriert werden sollten, dann mit index offset vorn dran, um Redundanzen zu vermeiden.\par
Antwort: Nein, weil der offset->field lookup so schnell wie m\'f6glich gehen soll. Daf\'fcr muss jede Klasse ihr komplettes Set an Instanzfeldern registriert haben.\par
\par
Hm, Moment mal:\par
Die Declaring class verwenden ist nicht korrekt. Es kann sein, dass eine Entity class von einer anderen class ableitet und selbst gar keine Felder hat. Dann w\'fcrde sie nie einen Eintrag bekommen und der offset->Field lookup w\'fcrde eine Exception werfen. Nicht gut.\par
Das hei\'dft die ganze objectFieldOffset Logik braucht eine explizit \'fcbergebene Klasse.\par
Das verkompliziert den Normalfall mit der Unsafe Verwendung, aber das check ich mit einer Exception weg.\par
\par
Hm, oh Mann. F\'fcr die Implementierung der Variante ohne object class in der generischen Implementierung brauch ich jetzt extra eine "determineMostSpecificClass" Methode.\par
Fertig. Weitermachen ...\par
\par
Hm. Ich bin mir jetzt nicht mehr sicher, ob die ganzen byteSize querying methoden in eine MemoryAccessor Logik reingeh\'f6ren. Denn z.B. f\'fcr Android kann ich die alle nicht implementieren.\par
Sollten die evtl nur als static in die ~Sun implementierung rein? Oder wirklich \'fcberall nix zur\'fcckgeben? Oder nochmal extra kapseln?\par
hmhm...\par
\par
\par
2019-10-30\par
\par
Idee von Zuhause:\par
Ich schieb alle Querying Methoden, die ja sowieso eigentlich nur f\'fcr debugging ben\'f6tigt werden, in ein Interface "MemoryPropertiesQuerier" oder sowas in der Art.\par
Den kann man dann implementieren und dynamisch setzen, muss man aber nicht.\par
Die Frage w\'e4r dann noch, was mit so methoden wie das asBytes usw. ist. Die braucht man eigentlich auch nur f\'fcrs debugging und da gibt es aufgrund von ByteOrder Ansichten keine eindeutig richtige implementierung.\line Evtl. auch noch auslagern in irgendwelche Utils oder so.\par
\par
Ah: das asBytes kann ich mit einer Default-method generisch nachbilden, indem ich die set_longInBytes benutze. Passt.\par
\par
Bissl rum\'fcberlegen und rumbauen, was die beste Strategie f\'fcr die beiden Interfaces ist. Inklusive Konsistenzgarantie bei den Settern.\par
Gute L\'f6sung gefunden. Passt.\par
\par
Recherche zu ensureClassInitialized.\par
Simple Antwort: wenn nicht mit dem field base offset gearbeitet wird, braucht man das gar nicht. Also einfach als no-op implementieren mit entsprechendem Kommentar.\par
\par
throwUnchecked faken mit RuntimeException und Kommentar dazu. Geht halt nicht besser.\par
Hm... Moment mal: die Funktion wird nirgends ben\'f6tigt.\par
Wenn wirklich hab ich sie immer noch in der konkreten Sun Implementierung.\par
Also einfach aus dem MemoryAccessor rausschmeissen. Passt.\par
\par
Oh, Idee: Das ensureClassInitialized ist ind er Sun Implementierung nur daf\'fcr da, die offset base f\'fcr die field offset Bestimmung zu haben.\par
In der ~Generic Implementierung gibt es daf\'fcr ein \'c4quivalent: Die object fields der Klasse registrieren, die dann in der offset Bestimmung verwendet werden.\par
Wird zwar on demand auch gemacht, aber falls man wirklich mal mehrere Klassen vorab registrieren will (z.B. f\'fcr Tests oder um Performance-Spitzen zu vermeiden), kann man die verwenden.\par
Nice. So umbauen.\par
\par
Bissl thematisch aufr\'e4umen / umstrukturieren.\par
\par
So. Dann w\'e4r jetzt schon mal alles an Rand-ged\'f6ns fertig. Fehlen nur noch ca 100 TODOs f\'fcr die manuelle Speicherverwaltung.\par
Dazu Konzeptbeschreibung wieder ausgraben ...\par
\par
Los gehts mit extreme Bitschubsing ...\par
\par
Lieber einen Identifier und die slots boolean-table direkt in den DBB als header reinschreiben ...\par
\par
... Fertig. Und wieder rausreissen, weil sonst jede Memory Accessing Operationen den Header als Offset draufz\'e4hlen muss. Und das auch noch nach SmallChunk und BigChunk unterschieden. Das w\'e4r d\'e4mlich.\par
Stattdessen die Slots lieber als 3D-Array smallChunkSlots implementieren.\par
Das witzige/coole/effiziente an diesen extra Arrays ist: eigentlich wird zum Allokieren und Deallokieren nur auf denen gearbeitet. Der eigentliche DBB wird dabei nie angefasst.\par
\par
Iteratives Entwickeln ...\par
\par
\par
\par
2019-10-31\par
\par
Idee vom Heimweg:\par
(Spazierengehen im Park von der Arbeit zum Auto ist anscheinend h\'f6chst denkanregend ...)\par
\par
Den SlotIndex muss ich gar nicht in den Identifier packen.\par
Der ergibt sich aus dem Offset von Beginn des Buffers an.\par
\par
Und:\par
Die Anzahl der Slots kann man von der chunkSize ableiten.\par
Bisher hab ich da viel zu viel gemacht: immer 127, auch bei 4096 Gr\'f6\'dfe. Das belegt gleich mal ein halbes MB nur f\'fcr eine ChunkSize.\par
Besser ist:\par
Jeder Small Chunk Buffer ist immer maximal 4096 lang und die Zahl der Slots ergibt sich daraus, wie viel ganze ChunkSizes da rein passen.\par
Das l\'e4sst sich leicht ausrechnen:\par
chunkSize > 2048: 1 slot\par
chunkSize > 1365: 2 slots\par
chunkSize > 1024: 3 slots\par
chunkSize > 819: 4 slots (oberstes if der Fallunterscheidung aus Performancegr\'fcnden)\par
chunkSize <= 32: 127 slots\par
ansonsten: slotCount = 4096 / chunkSize. (Integer Division rundet das Ergebnis automatisch immer ab, also kann die Gesamtl\'e4nge niemals die 4096 \'fcbersteigen)\par
\par
\par
Letztendlich hei\'dft das:\par
Ich muss in dem SmallChunk Identifier nur 2 Werte unterbringen:\par
- Sign Bit (1 bit)\par
- ChunkSize (12 bit)\par
- ChainIndex (19 bit)\par
\par
Und:\par
Die SmallChunk F\'e4lle m\'fcssen doch das Sign Bit bekommen, also negative Adresse haben. Denn: Mit einem BigChunk Index beginnend bei 1 kann man einen NPE erkennen. Also muss der positiv sein. Bei dem composite Identifier der SmallChunks geht das nicht.\par
\par
Wobei ... da f\'e4llt mir auf: Adressen d\'fcrfen \'fcberhaupt nicht negativ sein, sonst ruiniert die Arithmetik ja die bits, weil sie bei negativen Zahlen r\'fcckw\'e4rts z\'e4hlt.\par
Hm. Also umdenken:\par
- Sign Bit ist tabu (1 bit)\par
- Type Flag (1 bit)\par
- ChunkSize (12 bit)\par
- ChainIndex (18 bit)\par
\par
Damit kann eine ChunkSize Chain maximal 250K lang werden. Muss halt dann reichen bzw. als Fallback kann ich ja dann BigChunks von kleiner gr\'f6\'dfe allokieren.\par
\par
So bau ich das mal ein...\par
\par
\par
Hm. Ein Problem ist dann nat\'fcrlich, dass man nicht mehr pr\'fcfen kann, ob ein Offset aus dem zugewiesenen Speicherbereich rausschreibt.\par
Aber eigentlich muss man das auch nicht. Mit normalem low-level Speicherzugriff kann man auch \'fcberall hinschreiben, wo man will und damit beliebigen schaden anrichten. Nur wenn man mit der adresse einen segmentation fault macht, krachts direkt. Das w\'e4re hier praktisch, wenn man aus den buffer bounds rausschreiben will. Da muss nix gecheckt werden.\par
\par
Aber Moment mal:\par
Wenn small chunks nur maximal 4096 gro\'df sind, dann braucht das von den unteren 4 bytes ja nur 12 bit. Die restlichen 19-20 bits sind immer 0. Da kann man noch was reinbauen.\par
\par
Mal \'fcberlegen ...\par
\par

\pard\sl240\slmult1\f1\fs22 6666655555555554444444444333333333322222222221111111111000000000\par
4321_987654321_987654321_987654321_987654321_987654321_987654321\par
\highlight3 _TSSSSSSSSSSSSCCCCCCCCCCCCCCCCCC\highlight0 _\highlight4 IIIIIII\highlight5 LLLLLLLLLLLL\highlight6 PPPPPPPPPPPP\par
\highlight0\par
\highlight3 Identifier part:\tab\tab\tab\tab\par
\tab _ = sign bit, ignored\tab\tab\tab\highlight0\par
\highlight3\tab T = type flag (small or big)\tab\highlight0\par
\highlight3\tab S = chunk size\tab\tab\tab\tab\par
\tab C = chain index\tab\tab\tab\tab\par
\highlight0\par
Offset part:\par
\tab _ = sign bit, ignored\highlight3\par
\highlight0\tab\highlight4 I = chunk index\par
\highlight0\tab\highlight5 L = unused / offset overflow protection\highlight0\par
\tab\highlight6 P = buffer position\highlight0  (= chunkSize * chunkIndex + offset)\par

\pard\sl276\slmult1\f0\fs28\par
Damit kann man den unteren Teil wunderbar validieren. Sogar gegen so ziemlich alle vorstellbaren overflow-Artithmetikfehler.\par
Aber ich denk f\'fcr den Moment nehm ich mal die Variante mit dem Ignorieren. Es ist auf jeden Fall noch genug Platz, um alles super duper wasserdicht zu machen.\par
\par
\par
Beim implementieren ist mir aufgefallen, dass ich ein bisschen dumm bin:\par
Wie erkennt man wohl eine null-addresse, ganz unabh\'e4ngig davon, welche variante wo mit welchem flag-bit realisiert wird?\par
Ganz einfach: if(address == 0).\par
Hurra! :-[\par
\par
Small Chunk Allokierung testen...\par
Funktioniert auf Anhieb. Bitschubsing 4tw!\par
Feierabend.\par
\par
\par
\par
2019-11-04\par
\par
Paar Verbesserungsideen vom Wochenende:\par
\par
1.)\par
Small Chunk Buffers sollten nat\'fcrlich immer mit exakt passender Gr\'f6\'dfe allokiert werden.\par
Es macht keinen Sinn, pauschal 4096 Byte zu allokieren und dann f\'fcr z.B. eine 1025er Gr\'f6\'dfe nur 2050 davon zu allokieren und 2046 einfach ungenutzt rumliegen zu lassen.\par
\par
2.)\par
Die Mindestanzahl an Small Chunks in einem Buffer muss 2 sein. Wenn es nur 1 ist, k\'f6nnte man es gleich als BigChunk behandeln. Das h\'e4tte weniger Overhead.\par
Also ist die Frage: Entweder SmallChunk Maximalgr\'f6\'dfe verkleinern auf 2048 oder SmallChunk Buffergr\'f6\'dfe erweitern auf 8192?\par
\par
Man k\'f6nnte nat\'fcrlich folgendes machen:\par
- Small Chunk Max Size reduzieren auf 1024 (10 bit statt 12 bit)\par
- Daf\'fcr chain length von 18 auf 20 bits erh\'f6hen, d.h. 1 Million Eintr\'e4ge je small chunk size.\par
- Buffer Size auf 4096 lassen, d.h. es gehen immer mindestens 4 chunks in einen Buffer. Oder 4 Millionen Chunks. Oder 4 GB an adressierbarem Speicherbereich. NUR f\'fcr 1024er Chunks.\par
- f\'fcr 820 Byte (ung\'fcnstigster Fall 1 Byte \'fcber 5 Chunks) w\'e4ren es dann nur 820*4*1024*1024 = 3,2 GB anstatt 4,0 GB. Bei 819 w\'e4ren es dann wieder 819*5*1024*1024 = 3,999 GB.\par
\par
Ich glaub, so mach ich das.\par
\par
\par
Layout Update:\par
\par

\pard\sl240\slmult1\f1\fs22 6666655555555554444444444333333333322222222221111111111000000000\par
4321_987654321_987654321_987654321_987654321_987654321_987654321\par
\highlight3 _TSSSSSSSSSSCCCCCCCCCCCCCCCCCCCC\highlight0 _\highlight4 IIIIIII\highlight5 LLLLLLLLLLLL\highlight6 PPPPPPPPPPPP\par
\highlight0\par
\highlight3 Identifier part:\tab\tab\tab\tab\par
\tab _ = sign bit, ignored\tab\tab\tab\highlight0\par
\highlight3\tab T = type flag (small or big)\tab\highlight0\par
\highlight3\tab S = chunk size\tab\tab\tab\tab\par
\tab C = chain index\tab\tab\tab\tab\par
\highlight0\par
Offset part:\par
\tab _ = sign bit, ignored\highlight3\par
\highlight0\tab\highlight4 I = chunk index\par
\highlight0\tab\highlight5 L = unused / offset overflow protection\highlight0\par
\tab\highlight6 P = buffer position\highlight0  (= chunkSize * chunkIndex + offset)\par

\pard\sl276\slmult1\f0\fs28\par
\par
Umbauen...\par
Kommentare updaten.\par
Bitshifting testen.\par
Oh, da f\'e4llt mir auf: 0 Byte allokieren macht keinen Sinn und mit 0 Byte kann man nur 1023 anstatt 1024 abdecken. Hei\'dft: Ich muss erstens mal auf 0 Byte gr\'f6\'dfe checken und zweitens dann vom definierten Bereich 1 abziehen.\par
Dann passt das Konzept wieder.\par
\par
Ich mach jetzt doch mal zumindest eine "MemoryException" Basisexception.\par
\par
Bissl rumtesten.\par
Ah... jenseits des ersten chainIndex sind schon noch paar Bugs drin ... nacheinander isolieren und fixen.\par
\par
So. Small Chunks allokieren l\'e4uft sauber durch f\'fcr 1 Million St\'fcck von Gr\'f6\'dfe 1024.\par
\par
Jetzt Deallokierung bauen.\par
\par
Achja, Moment:\par
Noch paar Sonderf\'e4lle in Unsafe testen:\par
Was ist bei ...\par
- 0 bytes (de)allokieren\par
- 1 byte (de)allokieren\par
- negative zahl an bytes (de)allokieren\par
- nicht-Basisadresse deallokieren\par
- usw.\par
\par
2019-11-05\par
\par
Deallkorieren weiterbauen.\par
Paar Utilmethoden zum Arrays managen mit Logik zum Allokieren zusammenlegen.\par
Testen.\par
Sieht gut aus.\par
\par
Ah, aber jetzt noch was testen:\par
Viel allokieren.\par
Einiges davon zuf\'e4llig wieder deallokieren.\par
Dann wieder einiges allokieren und schauen, ob die entstandenen L\'fccken korrekt gef\'fcllt werden.\par
\par
Test bauen.\par
Testen...\par
\par
Sieht ganz gut aus.\par
Aber noch einen Cleanup machen:\par
Am Ende alle Addressen durchlaufen und != 0 deallokieren.\par
\par
Aha: Da bleiben Eintr\'e4ge \'fcbrig. Das darf nicht sein.\par
Oder hab ich im Test Allokationen, die ich nicht tracke ...?\par
\par
\par
2019-11-06\par
\par
Fehlersuche ...\par
\par
Hmpfl. Find ich so einfach nicht.\par
Mal \'fcberlegen...\par
\par
Simple Idee: Erst mal Counter f\'fcr Allokierungen und Deallokierungen einbauen.\par
Nach der Cleanup Schleife m\'fcssen beide genau gleich gro\'df sein, sonst passt was nicht.\par
\par
Testen ...\par
\par
Aha! Unterschied.\par
\'c4h... aber es sind so um die 10 WENIGER Allokierungen als Deallokierungen. Trotzdem bleiben Verwaltungseintr\'e4ge \'fcbrig...\par
Seltsam.\par
Also noch mehr sysouts reinbauen.\par
\par
Ahhh... Jetzt hab ichs!\par
Die mixed allocations/deallocations bestimmen einen random index, aber dann wird anstelle dieses Index i - 1 f\'fcr den tats\'e4chlichen Zugriff verwendet. Das sind dann \'f6fter mal 0er Adressen, die im freeMemory aber keine Exception erzeugen.\par
Fixen.\par
Testen.\par
Und siehe da: es bleiben am Ende keine allokierten Eintr\'e4ge mehr \'fcbrig.\par
\par
Sysos im Produktivcode rausmachen und noch bissl testen.\par
Also das sollte passen.\par
\par
Dann mach ich jetzt noch das Big Chunk Handling. Aber das sollte relativ trivial sein.\par
War relativ schnell fertig.\par
Jetzt testen...\par
\par
Exception. Kurz anschauen. Seltsam. Warum ist index 64 beim deallokieren immer null?\par
Ausgaben verbessern usw.\par
\par
Hm, Idee: Breakpoint schon nach dem ersten Block Allokieren.\par
Tats\'e4chlich: Index 64 wird \'fcbersprungen und bleibt darum null.\par
Ah, das muss man mit dem Buffer enlargen zu tun haben.\par
Ach lol: ich hab schlicht das Buffer erzeugen und zuweisen in diesem Fall vergessen. Nat\'fcrlich ist der array slot dann immer null.\par
Fixen.\line Testen.\par
Passt.\par
\par
Bissl debuggen und alles durchschauen.\par
Moment mal: Alles wurde sauber allokiert und wieder deallokiert, aber in index 0 h\'e4ngt noch ein Buffer. Wie kann das sein?\par
...\par
\par
Ahhhhh!\par
Index 0, left shift 32, plus offset 0, ohne flag bit, ohne sign bit...\par
... ergibt den long Wert ... 0.\par
\'c4h, Mist.\par
Okay, dann muss ich machen: bigChunkIdentifier = bigChunkIndex + 1\par
Einbauen.\par
Testen.\par
Passt.\par
\par
Noch ein Test mit kleinerer Segmentgr\'f6\'dfe.\par
\par
Hm. Das wird nicht mehr sauber abgebaut.\par
Ahja, ein Problem ist schon mal: ich scan bei den big Chunks nicht r\'fcckw\'e4rts. Das muss ich noch einbauen.\par
Sysos einbauen f\'fcr den Testlauf.\par
Testen.\par
Hm, exception. Das decreasen nimmt zu viel weg.\par
Debuggen.\par
\par
Ah. Break vergessen.\par
Einbauen.\par
Testen.\par
Passt.\par
\par
Hm. Die Sysos haben auf einen interessanten Punkt hingewiesen: soll das array bis auf 0 verkleinert werden?\par
Konsequenterweise dann: soll es evtl. doch mit L\'e4nge 0 initialisiert werden?\par
\par
Hm. Vorteil: Es braucht weniger Speicher, wenn die Speicherverwaltung inaktiv ist.\par
Aber: die 3 Small Chunk Arrays werden mit jeweils 1024 L\'e4nge initialisiert und bleiben f\'fcr immer so. Das sind 9 bzw. 17 KB, je nach coops. Ob da eine Handvoll Bytes f\'fcr die bigChunks einen Unterschied macht?\par
Ich lass mal ein Segment stehen.\par
Testen. Nat\'fcrlich falsche Logik: Wenn er zum Schluss mehrere Segmente auf einmal abbauen w\'fcrde, soll er nicht gar nichts machen, sondern alles bis auf ein Segment abbauen.\par
Testen.\par
Jetzt passts.\par
\par
Damit w\'e4ren die BigChunks auch fertig implementiert.\par
\par
\par
Gleich mal die 16 simplen Getter und Setter implementieren.\par
ByteBuffer#getBoolean und putBoolean gibts nicht, weil das anscheinend zu schwierig f\'fcr die JDK Boum gewesen w\'e4r...\par
Selber was bauen.\par
Gleich mit ordentlicher L\'f6sung in XTypes.\par
\par
Fertig f\'fcr heute.\par
\par
Morgen dann die restlichen Methoden, inklusive Objects mit Offset.\par
\par
\par
2019-11-07\par
\par
Heute die object field offset Zugriffe implementieren und testen.\par
\par
Hm. Es fehlt im MemoryAccessor noch eine convenience Methode\par
public long[] objectFieldOffsets(Class<?> c);\par
\par
Die Logik daf\'fcr gibts schon. Da bau ich noch ein Predicate dazu und steck das in eine Default Method rein.\par
\par
Testen.\par
Scheint auf Anhieb korrekt zu laufen.\par
Bissl mehr Tests machen.\par
Z.B., ob bei double Wert in boolean Feld und umgekehrt auch wirklich eine Exception kommt.\par
Ja. Passt alles.\par
\par
Jetzt noch die restlichen Methoden implementieren.\par
\par
Die absolute copyRange m\'fcsste gut mit ByteBuffer-zu-ByteBuffer kopieren gehen.\par
Die mit Objects ... hm. Die ist generisch kaum l\'f6sbar.\par
Mal schauen, wo die \'fcberhaupt verwendet wird.\par
Ergebnis: Au\'dfer in Tests nirgends. Weil sie in Produktivbetrieb auch kaum Sinn macht.\par
Ich mach es so: ich lass die in der Sun Implementierung, aber l\'f6sch sie aus dem Interface und der XMemory raus.\par
\par
Sehr sch\'f6n. Dann w\'e4ren zwei knifflige F\'e4lle schon mal erledigt.\par
\par
F\'fcr die 8 set*inBytes k\'f6nnte es eigentlich eine generische Implementierung in XArrays geben.\par
Die verlink ich dann dort nur noch.\par
\par
Ah, Mist, aber dann muss im MemoryAccesor Aufruf ein Check der ByteOrder rein.\par
Naja, who cares. Bei dem ist performance eh nicht die Priorit\'e4t. Daf\'fcr gibts die Low-Level Implementierung und die braucht den check nicht.\par
\par
So. Dann brauch ich nur noch die copy Methoden f\'fcr Arrays.\par
Ach, und das fillMemory ist noch. Auch noch machen.\par
\par
So. Jetzt sind nur noch Exception TODOs und das L\'f6schen des Testcodes.\par
Hm. Ich denk den lass ich und kommentier ihn nur aus.\par
\par
Tja. Dann w\'e4r der MemoryAccessorGeneric jetzt fertig.\par
Mal noch Code nach priv#111 Tasks durchsuchen.\par
Ach ja. Zwei St\'fcck. Aber das sind eigentlich keine Tasks daf\'fcr, sondern die sind nur im Rahmen der Arbeiten daran aufgetreten. \'c4nder ich zu normalen TODOs ohne Issuebezug.\par
\par
Mal nochmal Konzeptbeschreibung durchschauen ...\par
\par
Aaahh!\par
Es gibt ja noch den Fall, dass Code sich selber DBBs allokiert und dann per Adresse drauf zugreift.\par
Die m\'fcssen als dritte Art gemanagte DBBs ja noch in den MemoryAccessor rein.\par
Hm. Aber es w\'e4r bl\'f6d, da jetzt so einen BufferOwner Dings bauen zu m\'fcssen.\par
\par
Besser w\'e4re, wenn eien WeakReference direkt auf den Buffer zeigt. Dann bestimmt weiterhin allein der Owner dar\'fcber, wie lang der Buffer lebt, nur halt implizit.\par
Und man muss den Owner nicht an den Memoryaccessor \'fcbergeben, damit der den irgendwie in einer Hashtable verwurstet, aber wenn man denselben Buffer von einem zweiten Owner aus \'fcbergibt, gibts inkonsistenzen, usw.\par
Das w\'e4r alles heikel.\par
\par
Einfacher ist:\par
- Von der BigChunk Index Range wird noch ein Bit abgezwackt f\'fcr die Fallunterscheidung.\par
- Die dritte Art registriert \'fcbergebene ByteBuffer als Weak Keys einer speziellen HashTable. Value ist ein long, der die adresse darstellt.\par
- Dann muss es noch ein index Array geben, um von der Adresse wieder auf den DBB zu kommen.\par
- Wenn im laufenden Betrieb auf einen verwaisten WeakReference eintrag gesto\'dfen wird, wird entsprechend aufger\'e4umt.\par
- Das getDirectBufferAddress wird dann \'fcber die XMemory geroutet. Die Sun Implementierung gibt einfach nur stateless die address zur\'fcck. Die Generic macht dann ihren Registrierungskram.\par
- Deallocate ebenso mit Aufr\'e4umlogik in der Generic Implementierung.\par
\par
Hm. Die Klasse PlatformInternals muss eigentlich in den MemoryAccessor reingemerget werden. Sonst w\'fcrde z.B. der "PlatformInternals.guaranteeUsability();" Aufruf in der Binary Klasse auf Android fehlschlagen.\par
Das DBB handling muss eleganter \'fcber MemoryAccessor gel\'f6st werden. Durch die Generic Implementation kann man jetzt ja sogar eine directByteBuffer Address holen, obwohl man gar nicht an die eigentliche rankommt.\par
\par
Hm. Da drin muss ich erst mal einiges aufr\'e4umen.\par
Die Unterscheidung zwischen DirectBuffer und DirectByteBuffer ist unn\'f6tig. Es geht hier allein um DirectByteBuffers. Welche crazy shit JDK Klasse auch immer DirectBuffer zuk\'fcnftig auch mal implementieren sollte hat in der DBB Logik nichts verloren und darf bei einer Abfrage nicht als DBB identifiziert werden.\par
Also DirectBuffer Class komplett raus.\par
\par
Dann, DBB Klasse feststellen:\par
Anstatt nacheinander magic value Strings durchzuprobieren, bis irgendeiner mal als Klasse geladen werden kann, einfach folgendes machen:\par
ByteBuffer.allocateDirect(Long.BYTES).getClass()\par
\par
Funktioniert garantiert immer. Wenn nicht, dann kann MicroStream mit den betreffenden Plattform so oder so nicht betrieben werden.\par
\par
Abh\'e4ngigkeiten zu XCollections mach ich auch lieber raus. Hat in diesem Fall ja keinen Nachteil und sonst drehen wieder alle durch.\par
\par
Das mit dem Cleaner ist leider tats\'e4chlich ein riesen Fuck. Das muss so bleiben.\par
\par
Noch ein Punkt: anstatt die Funktionstypen optional zu machen, mach ich gleich nur die.\par
\par
Also alles bissl umbauen und optimieren.\par
Letztendlich PlatformInternals in die MemoryAccessorSun reinmergen.\par
Und dann die Klasse zerlegen und den static Teil umbenennen zu JdkInternals.\par
\par
\par
\par
2019-11-08\par
\par
Hm. Bevor ich den Trick mit dem ByteBuffer.allocateDirect(Long.BYTES).getClass() im Generic Handler nochmal nachbau und dann dort nochmal f\'fcr statische Verwendung, mach ich es gleich anders:\par
Das ist eine allgemein verwendbare Logik, die aber implizit platformspezifisch funktioniert. Hei\'dft: Ich steck das direkt eine zentrale Utilklasse. Am besten XTypes. Und dann ruf ich die von beiden Stellen aus einfach auf.\par
Der redundante static Grusch entf\'e4llt dabei komplett.\par
Sehr sch\'f6n.\par
\par
Gleich noch ausf\'fchrliche Kommentierung dazu schreiben. Nicht das irgendein Checker zuk\'fcnftig mal sagt "Aber es gibt doch Buffer#isDirect".\par
(Inklusive potenziell mir selbst... *h\'fcstel*)\par
\par
Jetzt BufferRegistry bauen. Simple WeakHashTable mit #ensureRegistered, #remove und den entsprechenden increase, decrease und cleanUp Methoden.\par
\par
Beinahe fertig implementiert zum testen, aber jetzt muss ich Feierabend machen.\par
\par
\par
2019-11-11\par
\par
Noch fehlende Bitschubserei Methoden implementieren.\par
Ah, hehe: f\'fcr die get~Buffer Methode fehlt noch ein get() in der BufferRegistry. Haha.\par
Schnell noch kopieren und anpassen.\par
Achso, hehe. Das ist ja gar kein Hash Lookup, sondern einfach nur ein array getter.\par
Wobei es so einfach auch nicht ist:\par
Null entries d\'fcrfen keinen NPE werfen. Aber die Memory Exception darf erst au\'dferhalb geworfen werden.\par
\par
So, fertig.\par
Testen.\par
\par
registered capacity ist maximum oder bound? Aktueller wert von REGISTERED_MAXIMUM_CAPACITY ist bound, aber ich glaub logik ist maximum.\par
\'c4hnlich BIG_CHUNK_TABLE_MAX_LENGTH: Ist zwar 1 weniger, aber daf\'fcr ist ja auch ein Offset von 1 mit drin.\par
Beide fixen und f\'fcr beide den gleichen Wert verwenden.\par
\par
Einzelner registeredBuffer sieht gut aus. Jetzt wieder so einen "mixed" Test bauen.\par
Testen ...\par
Okay, da ist noch einiges falsch. Scheint immer bei Index 0 zu bleiben. Haha.\par
\par
Ah. War nur ein Bitschubsing Fehler. Kaum castet man den int vorher auf long, kommen sogar die richtigen Werte raus.\par
Scheint soweit alles korrekt zu sein. Noch bissl debuggen.\par
Sieht gut aus.\par
\par
TODOs zu max capacity wegmachen.\par
Nach priv#111 Tasks suchen.\par
Gibt keine mehr. Dann w\'fcrd ich sagen: das ist fertig.\par
\par
Jetzt Funktionstest mit komplettem Storage Example. Ich hab scho Angst ...\par
\par
Ah. Lustiger erster Fehler:\par
cannot access a member of class one.microstream.collections.EmptyTable with modifiers "private final"\par
\par
setAccessible vergessen. Haha. Daran hatte ich beim programmieren sogar gedacht, aber es ignoriert. Dumm. Schnell einbauen.\par
Testen.\par
L\'e4uft schon mal durch. Hurra.\par
Aber:\par
Illegal reflective access by one.microstream.reflect.XReflect ({{\field{\*\fldinst{HYPERLINK file:/D:/workspaces/microstream/microstream/base/target/classes/ }}{\fldrslt{file:/D:/workspaces/microstream/microstream/base/target/classes/\ul0\cf0}}}}\f0\fs28 ) to field java.util.Optional.value\par
\par
Hm... Wieso Optional? Das d\'fcrfte durch den Handler ja gar nicht generisch analysiert werden m\'fcssen. Daf\'fcr gibts ja den Handler.\par
\par
Mal neu starten, um das Laden zu testen.\par
Ach Mist:\par
IllegalArgumentException: newPosition > limit: (20966 > 20862)\par
at one.microstream.memory.MemoryAccessorGeneric.copyRange(MemoryAccessorGeneric.java:1443)\par
Ah. Man sollte vielleicht das limit vor der position setzen, weil die position gegen das limit validiert wird. Macht Sinn.\par
Nat\'fcrlich gleich an allen Stellen im neuen Source Code.\par
Testen.\par
\par
PersistenceExceptionTypeHandlerConsistencyUnhandledTypeId: No type handler found for type id "0".\par
BinaryLoader$Default.createBuildItem\par
Ahhh... das klingt nach Byteged\'f6ns Arithmetik Fehler in den gemanageten Buffers.\par
Aber jetzt untersuch ich erst mal das Optional zeug.\par
\par
Ahh... wegen der Art, wie Optional implementiert ist, geht das nur mit einem generischen Handler. Man muss in das final Field nachtr\'e4glich Werte reinsetzen.\par
Zur Creation time kann man den Wert nicht setzen, weil die Referenzierte instanz evtl. noch nicht createt ist.\par
Sp\'e4ter durch eine andere Instanz ersetzen kann man die Optional Instanz nicht, weil sie dann schon mit einer OID fest assoziiert ist und ein Ersatz eine Exception werfen w\'fcrde. Darum herumhacken k\'f6nnte Inkonsistenzen erzeugen.\par
Witzigerweise l\'e4uft das genau auf ein TODO aus BinaryLoader raus: Instanzen werden aktuell zu fr\'fch registriert. W\'e4ren sie etwas l\'e4nger nur lokal, k\'f6nnte man solche Schweinereien treiben, ohne dass es global Probleme geben w\'fcrde.\par
\par
\par
Ah. Und wenn man --illegal-access=warn an macht, kommt folgende Liste:\par
WARNING: Illegal reflective access by one.microstream.reflect.XReflect ({{\field{\*\fldinst{HYPERLINK file:/D:/workspaces/microstream/microstream/base/target/classes/ }}{\fldrslt{file:/D:/workspaces/microstream/microstream/base/target/classes/\ul0\cf0}}}}\f0\fs28 ) to field ... \par
java.util.Optional.value\par
java.util.AbstractList.modCount\par
java.util.AbstractMap.keySet\par
java.util.AbstractMap.values\par
java.util.Collections$UnmodifiableCollection.c\par
java.util.Collections$UnmodifiableSortedSet.ss\par
java.util.Collections$UnmodifiableNavigableSet.ns\par
java.util.Collections$UnmodifiableCollection.c\par
java.util.Collections$UnmodifiableSortedSet.ss\par
java.util.Collections$UnmodifiableNavigableSet.ns\par
java.util.Collections$UnmodifiableMap.m\par
java.util.Collections$UnmodifiableMap.keySet\par
java.util.Collections$UnmodifiableMap.entrySet\par
java.util.Collections$UnmodifiableMap.values\par
java.util.Collections$UnmodifiableSortedMap.sm\par
java.util.Collections$UnmodifiableNavigableMap.nm\par
java.util.Collections$UnmodifiableMap.m\par
java.util.Collections$UnmodifiableMap.keySet\par
java.util.Collections$UnmodifiableMap.entrySet\par
java.util.Collections$UnmodifiableMap.values\par
java.util.Collections$UnmodifiableSortedMap.sm\par
java.util.Collections$UnmodifiableNavigableMap.nm\par
\par
\par
Aber Moment mal:\par
Wieso \'fcberhaupt AbstractList und AbstractMap?\par
Und wieso die ganzen Collections?\par
\par
Mal debuggen ...\par
\par
Aaaach, klar. Macht Sinn:\par
Generisch behandelte Collections ohne problematische Felder erzeugen einen BinaryHandlerGenericType.\par
Z.B. f\'fcr EmptyList: Die persistable Fields sind leer. Die Instanz selbst ist nur ein unproblematischer Dummy. Also einfach generischen Handler daf\'fcr bauen ohne Felder. Passt.\par
In AbstractBinaryHandlerReflective wird aber leider XMemory.ensureClassInitialized aufgerufen. Kein Problem bei Unsafe Verwendung. Dann wird n\'e4mlich wirklich nur die Klasse initialisiert, was sie h\'f6chstwahrscheinlich eh schon ist.\par
Mit dem generic Ding werden dann aber nochmal alle Felder gesammelt und zwar OHNE persistable Evaluierung.\par
Auf einmal werden die eigentlich geskippten Felder doch wieder gesammelt und auf accessible gesetzt. V\'f6llig unn\'f6tig.\par
Dieses Setzen erzeugt dann die Warning.\par
\par
Simpler Fix:\par
Es muss dem XMemory.ensureClassInitialized noch ein Iterable<Field> \'fcbergeben werden k\'f6nnen f\'fcr die tats\'e4chlich ben\'f6tigten Felder.\par
Das ist dann halt eine special Variante im MicroStream MemoryAccessor und die Unsafe Implementierung ignoriert die Felder einfach.\par
So mach ich das.\par
\par
Hm. Das l\'f6ste aber nur das Problem mit den Abstract Classes.\par
Die Optional und die ganzen unmodified ged\'f6ns bla Klassen m\'fcssen tats\'e4chlich Felder analysieren.\par
Bei der Unsafe Verwendung kommt die Warning nur deswegen nicht, weil die Unsafe Logik den Check umgeht. Aber eigentlich ist die L\'f6sung noch genauso unvollendet / zukunftsunsicher wie die reflection L\'f6sung der Generic implementierung.\par
Aber das lass ich erst mal so.\par
\par
Allerdings exception:\par
Unmodifyable BlaBlub Schei\'dfklasse findet f\'fcr offset 4 das feld nicht.\par
Debuggen:\par
Drei Felder: Offset 0, 4, 5.\par
Seltsam. Das muss doch dann neu hochgez\'e4hlt werden: 0, 1, 2.\par
Debuggen.\par
\par
Ah. Der Fehler kommt davon, dass irgendwo beim lookup mal Field.getDeclaringClass aufgerufen wird. Und das ist dann eine andere als die eigentliche class und die hat dann andere indizes.\par
\par
Hm. Wie l\'f6st man sowas?\par
Mal \'fcberlegen und im Code rumschauen.\par
\par
Eigentlich ist es ganz einfach:\par
Anstatt eine explizite Schleife f\'fcr jedes Field ohne eigentliche class bau ich die Methode in AbstractBinaryHandlerReflective#objectFieldOffsets leicht um, so dass die sich das ganze array auf einmal holt, inklusive tats\'e4chlicher Klasse.\par
\par
Ah, nice. Immerhin sind es damit jetzt nur noch 7 warnings:\par
1 f\'fcr Optional und 6 f\'fcr UnmodifiableGed\'f6nsKlasse mit ihren spatzenhirning behinderten Feldnamen "c", "ss", "ns", "m", "sm", "nm".\par
Code immer sch\'f6n unlesbar halten, damit auch m\'f6glichst viele Bugs entstehen und neue JDK Versionen m\'f6glichst langwierig und teuer werden.\line Affen.\par
\par
Aber gut. Das lass ich f\'fcrs erste mal so.\par
Im Moment gehts mit dem JDK.\par
Eigentlich ist es ja eh nur f\'fcr Android gedacht.\par
Die schwulen Collections k\'f6nnte man mit handlern handeln. Hoff ich.\par
Und f\'fcr Optional k\'f6nnte man die Registrierreihenfolge im BinaryLoader mal fixen, dann kann man da einen zwischendummy erzeugen und im update die richtige Instanz zur\'fcckgeben.\par
\cf5 UPDATE: Siehe "Notiz zu Optional" unten.\cf0\par
\par
Dann auf zum Byteschubser Arithmetik Fehler.\par
\par
Hm. Da werd ich wohl eine "print den Buffer und seinen gesamten Inhalt" Debugmethode in die ~Generic Klasse reinbauen m\'fcssen.\par
\par
So. Wundervolle Debug Print Methode gebaut. Und die zeigt: Alle Bytes sind 0.\par
\par
Debuggt und mehr prints bis ins Entity Daten Laden rein.\par
Printing bissl gefixt und verbessert.\par
\par
Und siehe da, die Ausgaben sagen:\par
Immer, wenn die BufferPosition 0 ist (z.B. gro\'dfer Chunk oder kleiner mit slotIndex 0), dann sind Daten da. Ansonsten sind alle Bytes 0.\par
Hei\'dft: Da hab ich bei den Datenkopiermethoden irgendwo einen Offset ausgelassen oder sowas in der Art.\par
Muss ich dann morgen suchen.\par
\par
\par
2019-11-12\par
\par
Jetzt Offset Fehler untersuchen.\par
Debugging f\'fchrt schnell zu #copyRange\par
Mal buffers dort ausgeben lassen und durchdebuggen.\par
\par
Ach! Nat\'fcrlich!\par
Ich setz ja dem target buffer seine Position nicht.\par
Hei\'dft: F\'fcr index 0 ist es richtig.\par
Danach wird seine Position wieder auf 0 resettet.\par
Der n\'e4chste write schreibt wieder auf 0 anstatt auf eine position weiter hinten.\par
Das bedeutet: f\'fcr Small Chunks mit position 0 sind immer daten da (wenn auch inkonsistente, nehm ich an), aber f\'fcr alle dr\'fcber sind die bytes immer 0, weil sie nie beschrieben werden.\par
\par
Also target buffer position setzen ist klar.\par
Der Rest, limit setzen und die beiden Werte am Ende wiederherstellen, ist gar nicht so klar.\par
Denn: m\'fcssen die nicht eigentlich in ihrem ver\'e4nderten Zustand bleiben, falls es registrierte Buffer sind und die anwendung mit diesen werten arbeitet?\par
So ein mist ...\par
\par
Hm. Also erst mal ist es so:\par
Es m\'fcssten aus den source- und target-Adressen viel mehr Informationen rausgezogen werden, wenn sie da schon drin stecken.\par
N\'e4mlich:\par
- target buffer offset\par
- target buffer limit (chunk size bei small, capacity bei den anderen beiden)\par
- source buffer limit\par
\par
Man k\'f6nnt es sogar so machen:\par
F\'fcr Registered Buffers wird dort -1 zur\'fcckgegeben. Hei\'dft: Gar nicht beschr\'e4nken, sondern den inh\'e4renten Navigationsstate lassen, wie er ist.\par
Nur die anderen beiden buffer arten, bei denen der NavState ja irrelevant ist, werden mit der Brechstange gesetzt und dann wieder zur\'fcck.\par
Das ist die L\'f6sung.\par
\par
Hm. Aber was ist, wenn der Fall RregisteredBuffer zutrifft mit der expliziten bufferposition? Die werden in der Anwendung ja auch nur als allokierter Speicher verwendet, ohne Bedeutung ihres NavStates. Bzw. der wird bei Bedarf dann nachtr\'e4glich gesetzt.\par
Also doch State setzen und resetten?\par
Hm. Mal so programmieren und dann testen.\par
Sieht so weit gut aus.\par
\par
Achja, eine Sache fehlt ja noch: ich brauch ja noch einen explizit gesetzten blank instantiator.\par
Und tats\'e4chlich, hehe: gleich mal eine NoSuchMethod Exception, weil die Default Konstruktor Strategie nicht geht.\par
Muss ich noch setzen.\par
\par
Gleich eine Klasse JdkInstantiatorBlank schreiben und JdkInternals um eine entsprechende Convenience Methode erweitern, die eine Instanz davon zur\'fcckgibt.\par
\par
\par
Und noch eine Notiz zu Optional von daheim:\par
Das mit der Fake Instanz f\'fcr Optional f\'fcr nach #update geht nicht. Denn die von #create gelieferten Instanzen sind ja die, die in #update Aufrufen f\'fcr andere Instanzen verlinkt werden.\par
Irgendwo bei\'dft sich immer die Katze in den Schwanz (z.B. Optional mit Referenz auf Optional). Um einen Graph konsistent aufzubauen muss es halt nunmal erst Instanzen geben, die danach bef\'fcllt werden.\par
\par
Aber f\'fcr die drei EmptyUnmodifiable Drecksimplementierungen (empties mit Feldern, noch dazu mit unsauberer Vererbung. Weil die alle zu bl\'f6d f\'fcr interfaces sind) k\'f6nnte man l\'f6sen, indem man f\'fcr JDK Collections mit "Empty" im Namen keine Felder mitnimmt oder so.\par
\par
Ewig rumrecherchiert. In der Generic Type handlererzeugung fehlte noch ein check auf keine persistable fields und dann ein stateless handler als Optimierung.\par
\par
Aber die L\'f6sung f\'fcr das eigentliche Problem war:\par
Genau wie f\'fcr Collections.reverseOrder() explizit stateless handler registrieren.\par
\par
Damit sind jetzt alle Warnings weg, bis auf die f\'fcr Optional. Und die geht einfach nicht weg, weil man halt Instanzen erst erzeugen und dann bef\'fcllen muss. Hilft alles nix.\par
\par
Ah: Wenn ich das TypeDictionary anpass und einfach alle Felder rausl\'f6sch, gibts nat\'fcrlich eine entity length validation exception. Ist ja auch richtig.\par
Also eher drin lassen und schauen, ob das LTM es checkt. M\'fcsste es eigentlich.\par
Lol, interessant: die default implementiering von isVariableLengthType verwendet "minLength == maxLength" und darum kommt eine Exception. Muss nat\'fcrlich "!=" hei\'dfen. Fixen und kommentieren.\par
Und schwups, schon gehts.\par
\par
Damit w\'e4ren jetzt die unmodified empty Seuche Typen gehandelt, #copyRange ist gefixt, Instantiator passt.\par
\par
Weitertesten ...\par
Exception. Sieht wieder nach ByteArithmetik Fehler aus.\par
Hm. Au\'dferdem muss ich ja erst mal die drei anderen MemoryAccessorGeneric Methoden mit dem .limit() Denkfehler fixen ...\par
\par
Jetzt Arithmetik Exception ansehen.\par
Ach, das sind ja wieder die Unmodifiable Dinger.\par
Also es gibt einen Rerouting Legacy Handler.\par
Aber warum will der f\'fcr loadable References drei Felder iterieren?\par
Muss ich die LTM Handler Erzeugung doch debuggen ...\par
\par
Ah:\par
Der AbstractBinaryLegacyTypeHandlerTranslating Konstruktor sagt zum references loaden muss die alte definition verwendet werden, weil die zu dem Datensatz Layout in der Datenbank passt.\par
Macht Sinn.\par
Aber was ich dabei nat\'fcrlich vergessen hab: die m\'fcssen auf den rerouteten ByteBuffer zugreifen.\par
\'c4h... beziehungsweise: Damit ist es eigentlich falsch.\par
Kurz recherchiert:\line Erst werden die Instanzen erzeugt, dann werden die loadable References iteriert.\par
Beim Instanz erzeugen wird der ByteBuffer ersetzt durch einen nach dem neuen Layout.\par
Hei\'dft: es muss auch der neue Handler f\'fcr die Ableitung der loadableReferences verwendet werden.\par
\par
Fixen. Testen.\par
\par
Ah, jetzt knallts wieder da, wo es vor der Unmodified Seuche \'c4nderung mal geknallt hat:\par
MemoryAccessorGeneric#getSmallChunkBuffer\par
\par
Ich nehm mal an, dass das damit passt.\par
Dann schau ich jetzt diese Exception hat.\par
M\'fchsam ern\'e4hrt sich das Eichh\'f6rnchen ...\par
\par
Oh!\line Da wird in Binary als Offset die address nochmal draufgez\'e4hlt. Das ergibt nat\'fcrlich eine katastrophal kaputte Adresse.\par
...\par
H\'e4? Warum hat das ohne Generic Implementierung keinen Fehler gemacht?\par
\par
Gefixt. Laufen lassen.\par
L\'e4uft durch, hurraaa!\par
Uuuund Exception beim CSV-Konvertieren:\par
"The source buffer is this buffer"\par
\'c4h ... well, shit.\par
Mal schauen ob das ein Bug ist, oder ob das bisher nur mit unsafe kein Problem war.\par
\par
Ah, das UTF8 double assembling kopiert alle vorkomma-bytes um eins um, um den dot einzuf\'fcgen.\par
Okay, das is evtl. nicht perfekt effizient (aber erst mal einen pragmatisch schnelleren Weg finden), aber mal eine dumme Frage: Kann ein ByteBuffer seine Bytes nicht intern umkopieren/verschieben?\par
Ja und was macht man dann? Doppelt hin und her kopieren, weil die JDK Boum zum tausendsten mal wieder mal d\'e4mlich sind?\par
\par
Sonderfall implementieren.\par
Testen.\par
Sieht gut aus.\par
Weiterlaufen lassen.\par
\par
L\'e4uft durch.\line Export-CSVs anschauen. Sieht gut aus.\par
\par
Bissl Performance Tests.\par
H\'f6? Ist das wirklich gleich schnell?\par
\par
Gr\'f6\'dferen Test machen...\par
\par
\par
\par
Interessant:\par
Speichern mit Generic, laden mit Unsafe, gibt folgende Exception:\par
0 Inconsistent file length of file 72057594037927936: -8627499406762967040 < 435160313994674176\par
\par
Muss ich morgen gegen\'fcberstellen...\par
}
 