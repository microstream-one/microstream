{\rtf1\ansi\ansicpg1252\deff0\nouicompat\deflang1031{\fonttbl{\f0\fnil\fcharset0 Calibri;}}
{\colortbl ;\red0\green0\blue255;}
{\*\generator Riched20 10.0.17763}\viewkind4\uc1 
\pard\sl276\slmult1\f0\fs28\lang7 2019-09-30\par
\par
Erst mal Brain Storming, was alles beteiligt ist:\par
\par
1.) Direkte Memory Allocation, z.B. um Entitydaten im Storage-Layer zu cachen.\par
-> k\'f6nnte gel\'f6st werden \'fcber ein simples byte[] bzw. evtl #3\par
ABER: wie gemeinsamen Nenner f\'fcr API?\par
\par
2.) ByteBuffer bef\'fcllen. (Wenn's kein DirectByteBuffer ist, wird intern vor dem Schreiben erst noch in einen DBB umkopiert. Kein Witz)\par
-> k\'f6nnte gel\'f6st werden, indem die ByteBuffer API aufgerufen wird, ggf. mit ByteOrder immer auf die System-Byteorder gesetzt, damit da nicht sinnlos rumgedreht wird und beim auslesen wieder zur\'fcck.\par
\par
3.) Direkte Memory-Zugriffe auf eine blanke Speicheradresse \par
-> byte[][] mit simulierter absoluter speicheradresse (siehe Issue Beschreibung)\par
? Oder evtl. einem gro\'dfen DirectByteBuffer unterteilt in mehrere Abschnitte? hm ...\par
\par
4.) Direkte Memory-Zugriffe auf eine Instanz mit offset\par
-> K\'f6nnte gel\'f6st werden mit ValueHandler Interface mit unterschiedlicher Implementierung intern (siehe Issue Beschreibung)\par
\par
5.) ValueSetter und ValueStorer Signaturen haben direkte Speicheradresse\par
-> k\'f6nnte gel\'f6st werden mit #4: \'dcbergeordnete Architekturschicht, die diese Typen gar nicht erst n\'f6tig macht.\par
ABER: wie sollen dann ValueTranslator und die ganzen um-map-Legacy-Handler geschrieben werden? Auch noch weiter abstrahieren?\par
\par
\par
\par
Ich denke, das einfachste w\'e4re erst mal, #4 und #5 umzusetzen und dann zu schauen, wie der performance Unterschied von Unsafe zu Reflection und von Unsafe zu direkten DirectByteBuffer methodenaufrufen w\'e4re.\par
\par
\par
\par
2019-10-01\par
\par
Mal im eclipse suchen, wo \'fcberall Unsafe vorkommt.\par
Kommt (immer noch) nur in der Klasse XMemory vor, das hab ich ja schon mal konsolidiert.\par
Sehr sch\'f6n.\par
Das WIP Projekt z\'e4hlt ja nicht, das wird nicht deployt.\par
\par
Also ist die Frage, wo XMemory \'fcberall vorkommt.\par
\par
Insgesamt 890 Vorkommen, die ersetzt werden m\'fcssen.\par
30 Vorkommen im JDK8Internals Projekt. Die z\'e4hlen nicht, denn die k\'f6nnen so bleiben, weil das JDK8 garantiert eine zug\'e4ngliche Unsafe Klasse hat und immer haben wird.\par
50 Vorkommen im WIP. Die sind komplett egal.\par
\par
Der Rest muss ersetzt werden:\par
\par
Ca. 130 Vorkommen im Base Projekt. Die sind erst mal nicht wichtig, m\'fcssten letztendlich aber auch ersetzt/modularisiert werden. Hm...\par
\par
6 Vorkommen im Communication Projekt. Ignorier ich erst mal. Sp\'e4ter ...\par
\par
1 ganzes Vorkommen im Persistence Projekt, n\'e4mlich f\'fcr den Instantiator.\par
Das l\'e4sst sich nat\'fcrlich irgendwie verschieben/ersetzen, wobei das schon eine interessante Frage aufwirft:\par
Ohne low-level Instantierung braucht man die "Es muss einen default Konstruktor ohne logik drin geben"-Seuche als Einschr\'e4nkung f\'fcr die Verwendung des Frameworks.\par
Oder nat\'fcrlich einen expliziten Instantiator.\par
\par
Ca. 100 Vorkommen im Storage Projekt.\par
Manche davon sind trivial, z.B. DefaultBufferSize. Oder primtive Byte sizes. Bzw. diese Aufrufe k\'f6nnen sogar bleiben. Oder man trennt die irgendwie raus, ist ja egal.\par
Der Rest sind lauter Operationen mit absoluter Speicheradresse.\par
\par
Ca. 650 Vorkommen im PersistenceBinary Projekt.\par
Lustig lustig: Davon ca. 400 in der BinaryValueTranslators Monsterklasse. Bzw. das sind alles nur Funktionsimplementierungen f\'fcr das BinaryValueSetter interface, das einen Wert von einer absoluten Adresse zu einer relativen oder absoluten Adresse setzt.\par
\par
Und dann noch 250 "sonstige" Vorkommen. In BinaryHandler Implementierungen usw.\par
\par
Puh ...\par
Da w\'e4re es fast sinnvoller, erst mal ein paar damit \'fcberschneidende Issues vorzuziehen, weil die auf saubere Art eine ansonsten eher provisorische L\'f6sung bringen w\'fcrden.\par
Z.B. Die gescheite Abstraktion von BinaryFields. Evtl. sogar das ValueAccessor Konzept.\par
\par
Diese 890 Vorkommen erzeugen unterschiedlichen Aufwand:\par
Ein paar davon (sagen wir pauschal 89) sind unproblematisch, weil sie einfach Konstanten sind (default buffer size, binary length von primitives, usw.)\par
Der eine Instantiator ist trivial ersetzbar, aber erzeugt damit ein riesen Problem: Ohne das braucht man in jeder Entityklasse einen "passenden" Konstruktor oder einen vom Entity Designer manuell zu bauenden Instantiator.\par
Die 400 f\'fcr die BinaryValueTranslators lassen sich alle nach Schema F ersetzen, sobald es ein passendes Ersatzkonzept gibt. Das ist dann nur eine Flei\'dfarbeit.\par
Die restlichen 400 m\'fcssen je nach Fall analysiert und passend ersetzt/abstrahiert werden. Das werden nat\'fcrlich keine 400 Einzelf\'e4lle, sondern vielleicht 10 oder so Kategorien an Modularisierung/Abstraktion und dann m\'fcssen alle 400 F\'e4lle auf die passende L\'f6sung umgebaut werden.\par
\par
Au\'dferdem knifflig:\par
Was immer an Modularisierung/Abstraktion gemacht wird, sollte ja m\'f6glichst so sein, dass der Normalfall keine oder kaum Performance oder gar Funktionalit\'e4t verliert.\par
Da muss ich viel analysieren, \'fcberlegen, rumprobieren.\par
\par
Mal Issue updaten ...\par
\par
\par
Jetzt mal \'fcberlegen zu BinaryValueSetter Abstraktion.\par
Gibt eigentlich nur zwei Stellen: in Binary f\'fcr #updateFixedSize und in BinaryLegacyTypeHandlerRerouting zum binary values translaten.\par
Das zweite verschieb ich mal in eine Binary#copyMemory Methode.\par
\par
\par
Hm... interessante Idee:\par
Das byte[][] w\'e4re wahrscheinlich gar nicht n\'f6tig. DirectByteBuffer gibt es \'fcberall (z.B. in Android hier: {{\field{\*\fldinst{HYPERLINK https://android.googlesource.com/platform/libcore/+/jb-mr2-release/luni/src/main/java/java/nio/DirectByteBuffer.java }}{\fldrslt{https://android.googlesource.com/platform/libcore/+/jb-mr2-release/luni/src/main/java/java/nio/DirectByteBuffer.java\ul0\cf0}}}}\f0\fs28 ). Muss es wahrscheinlich sogar geben, weil ja die JDK public API eine entsprechende Methode (ByteBuffer#allocateDirect) besitzt.\par
\par
Es k\'f6nnte also reichen, an den entsprechenden Stellen anstatt einer blanken Adresse ein Paar von DBB+Offset Werten zu \'fcbergeben. Die normale Implementierung kann sich daraus ihre absolut Adresse errechnen und gl\'fccklich arbeiten, wie bisher. Implementierungen ohne Unsafe m\'fcssen halt jedes mal einen Lookup \'fcber den Offset machen.\par
\par
Ich muss mal schauen, ob das irgendwo API-technisch Probleme macht.\par
\par
Mal daf\'fcr bissl umbauen:\par
BinaryEntityDataReader#readBinaryEntityData(long)\par
umbauen zu\par
BinaryEntityDataReader#readBinaryEntities(DirectByteBuffer)\par
Macht intern dann das gleiche wie bisher, aber evtl. kann man dann nach ein paar solcher Umformungen die LoadItemErstellung abstrahieren und modularisieren.\par
Aaach, da kommt wieder das byteOrderSwitching rein. Aber das macht nix. Da muss nur einmal ein boolean gecheckt werden f\'fcr mehrere Entities auf einmal.\par
Oh, dann f\'e4llt sogar der Check auf die ByteOrder bei jedem einzelnen LoadItem weg. Das ist super!\par
\par
Oh, beim refactoren aufgefallen:\par
Der ChunksBuffer (speichern) hat bisher die DBBs bis limit ausgelesen.\par
Der ChunksWrapper (laden) hat bisher die DBBs bis position ausgelesen.\par
\par
Dann kann ich das nicht so abstrahieren, dass beide Varianten immer bis limit auslesen.\par
Es sei denn, dass im zweiten Fall position immer gleich limit ist.\par
Muss ich recherchieren ...\par
- Also der ChunksWrapper wrapt einfach nur ein Array an ByteBuffers. Darum hei\'dft er ja wrapper.\par
- Der wird nur verwendet in der BinaryFileSource. Dort l\'e4uft das ganze sehr simpel: limit wird auf die File L\'e4nge gesetzt und es wird solange eingelesen, bis position gleich limit ist. Also kann auch limit verwendet werden.\par
- Bei der eigentlichen Storage werden zum lesen ChunkBuffers verwendet. Dort wird mit position gearbeitet und am ende geflipt (limit = position, position = 0). Darum wird dort limit verwendet.\par
Fazit: in beiden F\'e4llen passt limit als grenze. Sollte das mal ein Problem machen, muss eben das limit entsprechend gesetzt werden.\par
\par
So. Umgebaut. Testen. Passt.\par
\par
Mal weiter schauen wegen Abstraktion...\par
Also man k\'f6nnte eine zweite BinaryLoadItem Implementierung machen, die die address als Position im DBB interpretiert und sich den entsprechenden DBB dazu merkt.\par
\par
Was das ganze letztendlich ziemlich kompliziert bis unm\'f6glich macht, ist, dass Binary halt kein Interface, sondern eine Klasse ist.\par
Dadurch st\'f6ren ein paar Methoden und Modularisierung w\'fcrde bedeuten, dort interface-ierte Logikinstanzen reinzuh\'e4ngen. Dann kann man gleich das ganze Ding zu einem Interface machen und sich mit einem Provider f\'fcr eine plattform das passende geben lassen.\par
\par
Hei\'dft: Der Auftrag f\'fcr morgen ist, das Ding durch ein interface zu ersetzen und zu checken, wie sich die performance ver\'e4ndert.\par
\par
Davon unabh\'e4ngig muss die API mal aufger\'e4umt werden, damit die ganzen direkten Addressen als implementierungsdetails verschwinden. Mit 2-3 Methoden hab ich das schon gemacht. Geht ganz gut.\par
Da kommt dann auch wieder das BinaryField Konzept ins Spiel ...\par
\par
\par
\par
 2019-10-02\par
\par
Binary zu interface umbauen.\par
\par
Puh... das wird ... viel Arbeit. Die Klasse ist 2000 Zeilen lang. Darin befinden sich viele statische, private und public Methoden. Jeweils unterteilt in welche mit absolutem Memory-Address, die m\'fcssen intern implementierungsspezifisch bleiben. Und welche, die "schon" oder von Haus aus Memory-Address-unabh\'e4ngig sind, die m\'fcssen ins Interface rein.\par
Dazu muss ich erst mal Methode f\'fcr Methode durchk\'e4mmen, was wo dazugeh\'f6rt. Dann f\'fcr die eine Gruppe zu interface Methoden erstellen. Und dann Aufruferklassen entsprechend umbauen.\par
\par
Die updateFixedSize h\'e4tte noch MemoryOffsets in Instanzen rein, was f\'fcr eine Unabh\'e4ngigkeit von Unsafe nicht sein darf. Aber die m\'fcsst ich erst mal mitziehen und dann sp\'e4ter das Konzept \'e4ndern (ValueSetters, die intern den Offset halten - oder dann eben das Field direkt f\'fcr eine reflection Operation).\par
\par
Au\'dferdem stellt sich wieder mal die Frage, ob "Binary" wirklich ein unsauber typisierter Kombityp sein muss, weil die API Bestandteile wirklich nicht auf "BinaryStoring", "BinaryReading" und "? extends Binary" typisiert werden k\'f6nnen...\par
\par
... Mehrere Besprechungen, Support f\'fcr CK und FH sp\'e4ter ist der Tag irgendwie um. Kaum was am Issue gearbeitet ...\par
\par
Hm... Die \'c4nderungen commit ich mal nicht, sondern stash sie nur oder so.\par
\par
\par
2019-10-03\par
\par
Feiertag\par
\par
\par
2019-10-04\par
\par
Binary Umwandlung zu interface weitermachen.\par
\par
Public Methods in interface hochziehen.\par
Sind immer noch 200 Compilerfehler.\par
Es h\'e4ngt halt einfach noch so wahnsinnig viel von direkten Speicheradressen ab.\par
Eigentlich m\'fcsste ich dann jetzt erst das alles in das interface hochziehen, auch wenn es da nicht hingeh\'f6rt und ich es sp\'e4ter wieder rausschmeissen muss, damit ich \'fcberhaupt erst mal checken kann, wie es performancem\'e4\'dfig ist, aus der abstrakten Klasse ein interface zu machen ...\par
Und wenn das passt, dann m\'fcsste ich alle Methoden mit direkter Adresse umstellen auf entweder offset relativ zu internem address state oder DBB+Offset Parameter, z.B. im Fall von modifyLoadItem.\par
\par
\par
Bevor ein Refactoring in diese Richtung gemacht werden kann, m\'fcssen erst mal alle Methoden umgebaut werden, die absolute Speicheradressen verwenden. Da gibt es sogar unabh\'e4ngig von diesem Issue hier schon ein TODO im Code: besser w\'e4re es, in einem ChunksBuffer (Ableitung von Binary zum Speichern von Daten) die contennt Adresse des aktuellen Entities intern zu halten und dann nur noch mit Offsets drauf zuzugreifen. Der Performance Aufwand daf\'fcr sollte nahe 0 sein, denn:\par
- Aktuell muss die ermittelte contentAddress ja zur\'fcckgegeben und im Aufruferkontext in einer lokalen Variable gespeichert werden. Das ist auch nicht gratis und das w\'fcrde mit einem internen Feld wegfallen.\par
- Auch jetzt muss auf diese contentAddress schon der offset draufaddiert werden, also keine Einsparung hier. Vielleicht ist das lesen der lokalen Variable etwas schneller als das lesen des Felds, aber mit CPU caches usw. bin ich mir da gar nicht mal so sicher. Muss getestet werden.\par
- Algorithmen, die n Elemente hintereinander speichern (f\'fcr collections, arrays, usw.), k\'f6nnen in Binary intern gemacht werden bzw. sind sie inzwischen eh schon gr\'f6\'dftenteils wenn nicht alle. Sollte noch irgendwas fehlen, verschieb ich das einfach zu den anderen. Dort ist dann die contentAddress wieder eine lokale Variable in der Methode, also performancem\'e4\'dfig kein unterschied zu der externen Variante, nur API-m\'e4\'dfig sauberer und dann eben, endlich, auch abstrahierbar.\par
\par
Also bau ich jetzt zuerst das um und dann schau ich mir wieder den aktuell versuchten Schritt an.\par
\par
Issue updaten.\par
\par
\par
\par
2019-10-07\par
\par
Schnell einen Test zum Swappen von DirectByteBuffer Inhalt machen f\'fcr eine Idee/Frage vom Wochenende.\par
Schnell fertig. Laufen lassen. JVM Crash.\par
Warum des?\par
Untersuchen ...\par
Ich kann keinen Fehler finden.\par
Weitere Tests daf\'fcr bauen.\par
Ergebnis:\par
Mein Code ist korrekt. Nur ab einer gewissen Gr\'f6\'dfe, evtl. irgendwie kurz vor der out of heap exception (die da eigentlich gekommen w\'e4re), crasht eine Methode im StringBuilder (!!! Nicht in meinem Code!) die JVM.\par
Liegt wahrscheinlich an dem @HotSpotIntrinsic Zeug.\par
Mit umgangenem Crash den eigentlich test machen. Gro\'dfe DBB Datenmengen brauchen eine extra JVM -XX:MaxDirectMemorySize Angabe. Aha, hab ich auch noch nicht gewusst. Sehr gute neue Erkenntnis.\par
\par
Jetzt API refactoring weitermachen ...\par
\par
Achja, die storeStringsAsList Methode.\par
Die so zu refactoren, wie ich mir das zuerst gedacht hatte, wird schwierig ...\par
Genau: Weil da n variable-length Listen gespeichert werden und jede gibt den variablen end-offset wert zur\'fcck.\par
Einfachste L\'f6sung: Ich lass die auf absoluter Adresse, aber mach sie intern.\par
Bzw. anders rum: die beiden aufgerufenen methoden bekommen interne, absolut arbeitende Varianten und die \'e4u\'dfere, public Methode wird relativ mit this.address + offset Aufruf der anderen.\par
\par
\par
\par
2019-10-08\par
\par
Halber Tag Besprechungen, u.A. Clustering Design, aber sehr produktiv.\par
\par
Sonderfallmethoden fertig bauen.\par
Alle "_Direct" und "_Offset" Marker wegrefactoren.\par
Alle internen methoden sauber auf "internal~" umbenennen.\par
\par
Jetzt m\'fcssen dann noch die "static methods using absolut an memory address that should actually not be here" Methoden aufger\'e4umt werden.\par
Mal versuchen mit der ersten ...\par
\par
Hm. Das sieht jetzt erst mal unm\'f6glich aus, weil die BinaryReferenceTraversers n\'e4mlich auch f\'fcr gecachte Entitydaten direkt im Speicher (allocateMemory) verwendet werden.\par
Wieder l\'f6schen.\par
Aber ich muss mal schauen. Evtl. kann ich die Methode anderweitig verstecken oder einfach in die Call site verschieben, dann ist sie im binary weg.\par
Wobei das eigentliche Problem ja ist: wie kriegt man den direkten Speicherzugriff auf direkt gecachte Entities weg?\par
Oder muss da jetzt doch die Trickserei mit eigener Logik hinter allocateMemory rein? F\'fcr so "blank" allokierten Speicher ist das wahrscheinlich der einzig gangbare weg ...\par
\par
\par
\par
2019-10-09\par
\par
\par
Super Idee von Zuhause und Arbeitsweg:\par
\par
Manuelle Off-Heap Memory Allokierung sollte/muss eigentlich auch mit Off-Heap Memory realisiert werden.\par
Das hei\'dft zwangsweise: DirectByteBuffer. Unsafe#allocate gibt es ja eben auf manchen Systemen (Android) nicht und es gibt nur diese beiden M\'f6glichkeiten.\par
Sollte ein DBB mal intern so implementiert sein, dass er gar keinen Off-Heap Memory allokiert, dann k\'f6nnen wir das eh nicht \'e4ndern.\par
DBBs sind der beste Versuch bzw. die einzige M\'f6glichkeit, auf eine Java-Standard-API-Weise Off-Heap Memory zu allokieren. Also die.\par
\par
Nun folgendes Problem:\par
Man k\'f6nnte f\'fcr jeden allokate Aufruf einfach einen eigenen, neuen DBB instanzieren.\par
F\'fcr gro\'dfe Speicherbereiche ist das absolut okay. Aber f\'fcr kleine (z.B. 24 Byte f\'fcr ein stateless Entity, das nur aus Header besteht), w\'e4re der Overhead gigantisch.\par
\par
Darum folgende Idee:\par
"Kleine" Speicherbereiche werden zu mehreren in einem DBB zusammengefasst.\par
"Gr\'f6\'dfere" Speicherbereiche bekommen jeweils einen exklusiven DBB.\par
Cooler Nebeneffekt: ChunksBuffers zum Storen bekommen immer einen eigenen DBB. Der Lese-Fall (Entities laden und GC) ist performancem\'e4\'dfig nicht so kritisch in einer Anwendungskonzept, wo der In-Memory Objektgraph die Prim\'e4re Datenquelle darstellt.\par
\par
Die Idee ist nur, den DBB-Overhead je Item gegen 0 gegen zu lassen. Es muss nicht super-duper-intelligent die Zahl der DBBs auf einem absolut n\'f6tigen Minum gehalten werden oder sowas.\par
\par
Konkret zum Algorithmus:\par
\par
Rahmenbedingungen:\par
Man kann per DBB nur maximal Integer.MAX_VALUE an Speicherbereich reservieren. Total hinrissige Beschr\'e4nkung einfach nur, weil der ByteBuffer eine toArray Methode hat, aber in diesem Fall ist es ganz n\'fctzlich.\par
Also die maximal auf einmal reservierbare Speichergr\'f6\'dfe ist MAX_INT.\par
\par
Speicherbereiche werden aber als long addressiert. Also hat man 4 Byte "frei", um dort eine frei ausgedachte Verwaltung abzubilden.\par
Und zwar folgenderma\'dfen:\par
\par
Die unteren 4 byte werden als signed integer als index in den DBB (i) interpretiert.\par
Die oberen 4 byte werden als signed integer als Verwaltungsindex (v) interpretiert.\par
\par
Das Sign-Bit von v wird f\'fcr eine Fallunterscheidung verwendet:\par
Positiv bedeutet:\par
Der Wert identifiziert einen gro\'dfen Einzel-DBB Speicherbereich.\par
Eigentlich reicht daf\'fcr eine fortlaufende ID beginnend bei 1, die in ein BigEntry[] zeigt. Wobei beim Allokieren von index 1 an das array nach leeren Eintr\'e4gen durchsucht wird.\par
Das Array wird dynamisch gewachsen, wobei jede Gr\'f6\'dfen\'e4nderung einen upperThreshold und einen lowerThreshold wert cacht, gegen den beim allokieren und deallokieren mit dem bisher h\'f6chsten Wert getestet und ggf. rebuildet wird.\par
\par
So ein BigEntryenth\'e4lt die Referenz auf den DBB und Metadaten f\'fcr die Verwaltung. ... Hm... Was eigentlich bei einem Einzel-DBB?. Evtl. ist der Entry \'fcberfl\'fcssig.\par
D.h. man kann maximal 2,1~ Milliarden "gro\'dfe" DBBs allokieren. Das sollte reichen.\par
\par
Warum beginnend bei index 1? Weil eine generische Adresse von 0 nat\'fcrlich weiterhin "wie normal" ein nullpointer sein muss, der einen Fehler wird und nicht einfach ein generischer Indexwert, der auf den DBB mit index 0 zeigt.\par
Dieser eine Platz ist dann einfach immer leer ("da wohnt null"), aber das ist ja platzm\'e4\'dfig egal.\par
\par
\par
Negativ bedeutet:\par
Der Wert (mal *1) identifiziert einen einzelnen "kleinen" Eintrag in einem Multi-Eintrag-DBB Speicherbereich.\par
Die untersten 12 Bit definieren die L\'e4nge des allokierten Speicherbereichs und damit den Index in der Lookup Table (siehe unten).\par
Die n\'e4chsten 12 Bit definieren den Index der zweiten Dimension in der Lookup-Table (siehe unten).\par
Die obersten 7 bit identifiziert als unsigned int die Position im DBB. Nicht index, sondern index = position * L\'e4nge.\par
\par
Lookup-Table:\par
Ein Entry[][], das in der ersten Dimension immer die fest L\'e4nge 4096 (2^12) hat.\par
Der Index entspricht der L\'e4nge der allokierten Speicherbereiche. Also z.B. alle Speicherbereiche der L\'e4nge 197 werden verwaltet im Index 197.\par
Die zweite Dimension (nested Entry[] Array) ist ein ArrayList-artig wachsendes Array an Entry Instanzen.\par
\par
Ein Entry besteht aus:\par
- Referenz auf den DBB\par
- boolean[], das aussagt, ob der Eintrag an Position i gerade allokiert ist oder nicht.\par
Wobei dieses Array als header im DBB stehen k\'f6nnte. Mit einem initialen int, wie viele Eintr\'e4ge der DBB hat, d.h. wie lang das boolean-array ist.\par
Und einen size counter, um das deallokieren zu erleichtern.\par
Dann br\'e4uchte man gar keine Entry Zwischenklasse und das ganze w\'e4re etwas performanter.\par
\par
Allokieren und deallokieren liegt dann nat\'fcrlich auf der Hand:\par
usage-array checken (und ggf. exception).\par
\'fcbergebene Addresse in einen Offset in den DBB \'fcbersetzen und Bounds checken.\par
Wenn der size counter auf 0 ist, dann den ganzen DBB deallokieren und im nested array ausnullen.\par
\par
\par
Das w\'e4re ein off-heap-m\'e4\'dfig korrektes mittel, mit nur java public API (-> Android) eine absolute Speicheradressierung in manuell allokiertem Speicher zu machen.\par
Auf Entities zugreifen (base + offset) kann man damit nat\'fcrlich nicht, das braucht eine Umformung zu Reflection.\par
Auch auf explizite DBBs kann man damit nicht zugreifen. Die brauchen auch eine Umformung (DBB Referenz + Offset)\par
\par
\par
Das muss ich dann mal so implementieren, wenn ich alle kleineren Details refactort hab.\par
\par
\par
Jetzt wieder zur\'fcck zu den Methoden mit absoluter Speicheradressierung, die es eigentlich nicht geben darf.\par
\par
\par
Geht voran, aber das wird alles knifflig ...\par
\par
Und:\par
\par
Ich sollte mal ein konsistentes Benamungskonzept \'fcberlegen, wie man public API (mit relativem offset) von interner API (mit absolutem offset) unterscheiden kann.\par
\par
z.B:\par
get vs read\par
set vs store\par
\par
Ich w\'fcrd eigentlich sagen: read und store public, get und set intern.\par
Aber es gibt noch viele andere Methoden, die get~ anstatt read~ hei\'dfen. Die dann auch alle auf read~ umbenennen?\par
Aber eigentlich schon, weil der Binary Typ deutlich aussagen soll: Hier wird bin\'e4r gelesen und gestoret. Auf welche "magische" oder triviale Weise das intern dann auch immer stattfinden mag.\par
\par
F\'fcr arrays dann eher sowas wie:\par
update vs copy\par
build\par
\par
\par
\par
\par
2019-10-10\par
\par
Achja, die Benamungssache ist noch.\par
\par
Und noch die letzten paar Methoden mit absoluter Adresse rauswerfen.\par
Das geht eigentlich nicht, aber mit folgender einfacher Idee evtl doch:\par
Die Methoden zu simplen Arithmetik-Methoden reduzieren und den eigentlichen get_long Aufruf direkt in die Aufruferstelle schreiben. In diesen Klassen sind eh schon X-fach solche Aufrufe drin, da kommt es auf die paar mehr auch nicht mehr an.\par
Daf\'fcr w\'e4re dann die Binary Klasse sauber.\par
Das mach ich mal so.\par
\par
Das modifyLoadItem ist auch noch. Hm. Das \'e4nder ich auf einen \'fcbergebenen ByteBuffer und Offset. Dann passt das.\par
Die copyMemory Methode benutzt auch noch eine absolute Adresse. Umbauen.\par
\par
Bei den drei verbleibenden Methoden, den getEntity~ f\'fcr OID, TID, LEN ist das aber problematisch:\par
Das sind insgesamt 12-19 Stellen, insgesamt ca. 50. Die alle durch einen expliziten get_long Aufruf zu ersetzen ist strukturell widersinnig. Danach m\'fcssten diese 50 Stellen sofort wieder konsolidiert werden in eine statische Util-Klasse.\par
Also m\'fcsste das eine andere sein, eine "AbsoluteEntityAddressing". Aber das verschiebt das Problem ja nur, weil letztendlich auch die modularisiert werden m\'fcsste.\par
\par
Das Problem ist: Wie kann man alle Verwendungen der Unsafe Klasse modularisieren? Insbesondere die von statischen Methoden (XMemory...).\par
Man kann nat\'fcrlich einfach eine andere XMemory Klasse verwenden, die intern ihr eigenes Speichermanagement macht f\'fcr absolute Zugriffe. Das geht.\par
1.) Das geht aber nur f\'fcr die Logik, die sich so eine absolute Speicheradresse von einem kontextlosen/direkten "allocateMemory" Aufruf geholt hat.\par
2.) Logik, die per Adresse direkt auf einen DBB zugreift, muss so umgebaut werden, dass sie DBB + offset \'fcbergibt. So wie ich das bei modifyLoadItem und copyMemory gerade gemacht hab.\par
3.) Und Logik, die per reference + offset direkt auf instanzen zugreift, muss komplett eigenst\'e4ndig abstrahiert und modularisiert werden, damit man eine Alternative bauen kann, die Reflection anstatt DMA verwendet.\par
\par
Die Frage ist auch, ob man wirklich die Klasse tauschen muss, oder ob man den Memory-Zugriff \'fcber ein interface in eine instanz modularisieren kann.\par
Unsafe selbst ist witzigerweise ja auch eine Instanz, obwohl sie nur statische Funktionalit\'e4t bietet. Evtl. optimiert die JVM unbenutzte "this" argumente raus, dann w\'fcrde es keine rolle spielen.\par
Muss ich testen ...\par
\par
\par
\par
2019-10-11\par
\par
Also ich mach jetzt, einfach mal um Erfahrungs- bzw. Messwerte zu bekommen, folgendes:\line - Messen, wie lang so ein \'fcblicher Durchlauf an store und load jetzt braucht\line - Einfach mal hardgecodet in XMemory die Speicherzugriffsmethoden intern mit einer interface instanz modularisieren und schauen, was der Unterschied ist.\par
\par
Alle m\'f6glichen Besprechungen zwischendrin ...\par
\par
Testen ...\par
Oh. Erst mal JVM Crash. Debuggen. Ah, absoluten statt relativen Offset \'fcbergeben. Fixen. Testen. Passt.\par
Jetzt zu performance rumprobieren ...\par
\par
Hm. Also das variiert phasenweise. Mal ist die hardgecodete Variante meist 500 ms, manchmal bis zu 750, dann \'e4nder ich auch die dynamische und hab meist 750, dann \'e4nder ich auf die hardgecodete zur\'fcck und hab auch meist 750.\par
\par
So wird das nix. Evtl. wegen zu viel "noise" im System.\par
Muss ich doch eine main-methode mit spezifisch diesem Test bauen.\par
\par
\par
\par
Also das kann eigentlich nicht sein, aber ich kann es so reproduzieren mit ansonsten identischem Code:\par
\par
1 Million longs in einer for Schleife direkt in den Memory setzen.\par
10K warmup runs\par
10K hot runs\par
\par
Ergebnisse (SEHR konstant, mit Varianz von 0 bis -5\'b5s) :\par
\par
\par
hardcoded Aufruf von XMemory.VM.putLong()\par
average: 425\'b5s\par
minimum: 380\'b5s\par
\par
static final MemoryAccessor mit XMemory.VM.putLong() Aufruf in MemoryAccessor$Sun\par
average: 425\'b5s\par
minimum: 380\'b5s\par
\par
static MemoryAccessor mit XMemory.VM.putLong() Aufruf in MemoryAccessor$Sun gesetzt zur Laufzeit\par
average: 366\'b5s\par
minimum: 315\'b5s\par
\par
Also das flexibelste, am wenigsten eingeschr\'e4nkteste und damit am wenigsten voraussehbar optimierbar, das eigentlich einfach nur ein Umweg ist, ist SCHNELLER der als der direkte aufruf.\par
WTF?!\par
\par
Also das hei\'dft dann eigentlich eins:\par
Man kann einfach direkt in der XMemory Klasse die Unsafe Verwendung rausmodularisieren.\par
Krass\par
\par
\par
Wenn ich die Schleife in eine "hot" Methode verpack, dann sind alle drei Varianten so schnell wie die schnellste.\par
Scheinbar greift in dem oberen Beispiel eine JVM Optimierung in den ersten beiden F\'e4llen nicht richtig.\par
\par
Witzig auch:\par
Im Idealfall braucht ein long setzen 0,3 ns.\par
Auf dem 4,20 GHz Rechner also so grob 1 CPU cycle pro Aufruf.\par
Das kann doch eigentlich nicht sein: man kann doch nicht mit 1 Cycle 2 Werte verarbeiten, einen Sprung machen und den Wert dort hin schreiben. Selbst wenn's Level1 Cache ist...\par
Oder liegt das an Pipelining im CPU oder so?\par
}
 