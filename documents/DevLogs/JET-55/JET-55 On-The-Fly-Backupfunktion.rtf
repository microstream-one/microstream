{\rtf1\ansi\ansicpg1252\deff0\deflang1031{\fonttbl{\f0\fnil\fcharset0 Calibri;}}
{\*\generator Msftedit 5.41.21.2510;}\viewkind4\uc1\pard\sl276\slmult1\lang7\b\f0\fs28 Jetstream JET-55 On-The-Fly-Backupfunktion Entwicklertagebuch\par
\b0\par
2019-02-13\par
\par
Brainstorming:\par
- Kennt ein Zielverzeichnis, in das die Storage Dateien kopiert werden.\par
- Nach dem erfolgreichen Initialisieren der prim\'e4ren Storage Dateien wird abgeglichen, bis wie weit die Storage Dateien schon im Zielverzeichnis sind und ob die vorhandenen konsistent sind. Nur das Head File darf unvollst\'e4ndig im Backup vorhanden sein.\par
- In der prim\'e4ren Storage vorhandene Dateien bzw. Teile des Head Files, die noch nicht im Backup Verzeichnis vorhanden sind, werden in die Backup Queue (siehe unten) eingereiht. \par
- Write Listener umbauen zu Write Wrapper\par
- BackuppingWriteWrapper registriert jeden Write in einer Backup Queue.\par
- wichtig: jedes dabei beteiligte file bekommt seinen use count inkrementiert, damit es nicht vor dem backup schreiben weggel\'f6scht wird.\par
- Die backup Queue wird von einem dedizierten Backup Thread (einer f\'fcr alle Channels) abgearbeitet.\par
- Direktes Backupping im Channel Thread wird erst mal nicht implementiert.\par
- Ein backup Item abzuarbeiten dekrementiert den use count des betreffenden Files.\par
- Transaction Eintr\'e4ge m\'fcssen genauso gebackupt werden\par
- Das TypeDictionary muss unabh\'e4ngig von den Daten gebackupt werden. Das w\'e4re dann nur "zuf\'e4llig" das selbe Verzeichnis.\par
\par
- Jeder zu kopierende Bereich wird optional (!) vom Backup Thread durchiteriert (nur entity zu entity, nicht die inhalte), um sicherzugehen, dass wirklich ein konsistentes backup raus kommt.\par
\par
\par
Jetzt einlesen in bestehenden Code. Das mit dem Umbau zum Wrapper k\'f6nnte gar nicht so einfach sein, weil die Aktionen verteilt sind \'fcber mehrere Methoden f\'fcr eigentliche Ausf\'fchrung und f\'fcr Commit.\par
Oder evtl. muss ja dann das mit ge\'e4ndert werden.\par
\par
Es m\'fcsste eigentlich reichen, einen Wrapper f\'fcr StorageFileWriter zu bauen. Dazu bissl konsolidieren.\par
\par
Wrapper bauen. Sieht gut aus.\par
Gut w\'e4r, wenn die write Methode gleich die neue L\'e4nge zur\'fcckgeben w\'fcrde.\par
Dann ist aber die Frage, warum das .force() im write auskommentiert ist und in die Aufrufersteller verschoben worden ist. Das passt doch da hin.\par
Seltsam. Muss ich recherchieren.\par
Hm. Es werden head file und transaction file auf einmal geflusht. Aber warum? In der Zwischenzeit k\'f6nnten einwandfrei vollst\'e4ndig geschriebene Daten verloren gehen.\par
Naja gut: Die Daten sind eh erst gesichert, wenn auch das transaction file sicher geschrieben worden ist. Vorher werden die beim Neustart verworfen.\par
\par
Andererseits: Mittelfristig wird das transaction file eh raus fliegen und durch inlined chunk headers ersetzt werden. Dann ist es eh nur noch ein monolithischer write.\par
Also den Flush wieder da rein ziehen.\par
\par
Der WriteListener kann dann ganz raus.\par
Hm, aber die folgenden Methoden als Varianten in den WriteWrapper zu \'fcbernehmen w\'e4r sinnvoll:\par
\par
public void registerStore(StorageDataFile<?> dataFile, long offset, long length);\par
public void registerTransfer(StorageDataFile<?> dataFile, long offset, long length);\par
public void registerDelete(StorageDataFile<?> dataFile);\par
public void registerCreate(StorageDataFile<?> dataFile);\par
public void registerTruncate(int channelIndex);\par
\par
plus eigentlich auch einen import. Das ist weder ein store aus der Anwendung noch ein housekeeping transfer, sondern was eigenes\par
\par
\par
2019-02-14\par
\par
Varianten einbauen.\par
\par
Oh, dabei interessanten Sonderfall entdeckt:\par
Es gibt die M\'f6glichkeit, eine Datenbank komplett zu l\'f6schen. Also ein "truncate" f\'fcr den ganzen Channel (und das in jedem Channel).\par
Im bisherien Write Listener war das die Methode "registerTruncate".\par
Im Writer gabs das bisher nicht bzw. nur eine truncate Methode f\'fcr eine Datei, die f\'fcr mehrere aufgerufen wurde.\par
Wenn jetzt der WriteListener raus fliegt und dessen Aufgabe vom Writer mit \'fcbernommen wird, braucht der so einen anonsten effektlose "registerChannelTruncation" Methode (bissl besser benannt).\par
Das ist schon mal ein Sonderfall.\par
Aber das wirklich interessante ist:\line Was soll eine Backup Logik in so einem Fall machen?\par
Das Backup l\'f6schen? Wohl kaum. Das ist ja ein Backup.\par
Wenn es aber nicht gel\'f6scht wird, dann w\'fcrden ab da Original und Backup zueinander inkonsistente Dateinamen usw. haben. Das geht auch nicht.\par
Hm...\par
\par
Ich hab das mal durchgedacht und sehe nur folgende zwei M\'f6glichkeiten:\par
1.) Als Konsequenz aus dem Konflikt die truncate Funktionalit\'e4t entfernen\par
2.) Bei einem Truncate alle Backup Dateien in einen speziall benannten Order (etwa "Truncation_2019-02-14") verschieben.\par
\par
F\'fcr #1 spricht:\par
- Es ist kein nennenswerter Aufwand, vermeidet sogar Programmieraufwand und zuk\'fcnftig Wartung von Code.\par
- So ein special Ordner f\'fcr #2 w\'fcrde evtl. unerwartete Probleme erzeugen.\par
- Aber vor allem: Diese Funktion wird, soweit absehbar, eh nicht benutzt und wenn man wirklich seine ganze Datenbank truncaten will, dann nullt man die Root Referenz aus und speichert einmal ab.\par
\par
F\'fcr #2 spricht:\par
- Naja, das es schon ein cooles Feature w\'e4re, wenn man mal in die Situation k\'e4me, dass man genau das br\'e4uchte. Aber siehe oben. \'c4u\'dferst unwahrscheinlich und sehr leicht implizit nachbildbar.\par
\par
Also hier keine sinnlose Flei\'dfarbeit anfangen, sondern die truncation einfach l\'f6schen. Fertig.\par
\par
Hm. Es gibt ein Argument daf\'fcr: Testing.\par
Aber andererseits: man m\'fcsste sich f\'fcr das Resetten von State auf eine komplexe interne Methode verlassen.\par
Wenn man einfach nur die Storage stopt, alle Dateien l\'f6sche und die Storage wieder startet, hat man genau den gleichen Effekt, nur ohne komplexe Logik.\par
Also ich lass die entscheidende Methode mit der Logik mal auskommentiert mit einem Kommentar daneben drin. Die restlichen Methoden zum Task erzeugen usw. l\'f6sch ich mal.\par
\par
\par
Weiter mit der Implementierung der eigentlichen Backup Logik:\par
Wrapping Provider bauen.\par
\par
Interessant: Die Backup Logik braucht ja bei Transfers 2 Files: source und target.\par
Mal sehen, ob das trotzdem mit einer einheitlichen Logik gemacht werden kann...\par
Hm...\par
\par
Also bei Transfer ist es einfach: SourceFile und TargetFile. F\'fcr beide wird das \'c4quivalent im Backup Verzeichnis gesucht und dann die Aktion repliziert.\par
Bei Store wird das storage-TargetFile zum backup-SourceFile. Das wird zu dem gleichnamigen im Backup aufgel\'f6st und dann die Aktion repliziert. Ein TargetFile gibt es beim storen nicht.\par
\par
Am Rande f\'e4llt mir wieder mal auf: es w\'e4re alles so viel einfacher, wenn es die Transfers nicht mehr g\'e4be. Achja und die Transaction Files auch nicht mehr.\par
\par
A propos: Writes in das Transaction File m\'fcssen ja auch noch enqueuet werden.\par
\par
\par
2019-02-15\par
\par
Weitermachen:\par
Transaction File Eintr\'e4ge auch noch in Backupping FileWriter.\par
Hm. Truncate von Datei ist wieder Sonderfall. Aber der muss diesmal mit rein. Zweite Methode machen, hilft nix.\par
\par
Bissl aufr\'e4umen.\par
\par
Jetzt StorageBackupHandler und die Queue, Items, daf\'fcr usw. bauen.\par
\par
Hm, knifflig:\par
F\'fcr jeden Channel eine Queue machen ist problematisch, weil dann der BackupHandler Thread nicht mehr einfach auf das n\'e4chste Item warten kann.\par
Da m\'fcsste ultra kompliziert ein bisschen gewartet und dann die anderen channels gecheckt werden.\par
Viel besser w\'e4re, wenn alle Channels in dieselbe Queue reinenqueuen. Dann ist blo\'df wieder das Problem, dass der Channelkontext fehlt.\par
Der Channelkontext k\'f6nnte implizit mit\'fcbergeben werden, wenn jedes File mindestens StorageLockedChannelFile w\'e4re. Dann kann man sich den channel rausziehen.\par
Das trifft aber bei imports nicht zu.\par
Hm. Oder eigentlich muss man bei einem Import das Quellfile gar nicht \'fcbergeben, sondern nur das Storage-Zielfile als Quellfile f\'fcr das Backup.\par
Auf jeden Fall ist das Quellfile f\'fcr die Backup-Kopieraktion IMMER ein ChannelFile. Das w\'fcrde passen. Mal so umbauen.\par
\par
\par
\par
2019-02-16\par
\par
Initialisierungsmethode bauen.\par
Hm. F\'fcr die Initialisierung brauch ich sowieso eine Inventar-Map. Dann kann ich die gleich mitpflegen und damit die st\'e4ndigen (teuren) File Instanzierungen sparen.\par
Also Inventarmethode bauen. Bzw. erst mal in Storage Initialisierung reinschauen, weil die dort auch schon drin sein muss.\par
Hm. Und dann k\'f6nnt ich gleich eine Channel-Verwaltungsklasse bauen, bevor ich tausend sachen in einzelnen redundanten Channel-Arrays halte.\par
Hm... sollten backup files gelockt sein, oder nicht?\par
\par
Ne. Extra BackupFile machen. Daf\'fcr Interfaces bissl umbauen.\par
Dass es neben nummerierten Files auch noch das Transaction File gibt ist nervig ...\par
\par
\par
2019-02-17\par
\par
Angefangene Baustellen implementieren ...\par
\par
Der StorageFileProvider providet nat\'fcrlich LockedFiles f\'fcr die Verwendung im Storage Verzeichnis, die ich f\'fcr das Backup Verzeichnis aber nicht brauchen kann.\par
Aber von der Logik her sollte es durchaus ein StorageFileProvider sein.\par
\par
Hm.\par
Also muss ich das zerlegen:\par
Entweder der Provider liefert ein schlichteres, f\'fcr beide F\'e4lle kompatibleres File und das wird dann f\'fcr die Storage-Verwendung nochmal gewrappt, oder es gibt einen wrappenden FileProvider, der den schlichteren wrappt.\par
Ersteres w\'e4r mir lieber, mal recherchieren ...\par
\par
Das extern wrappen nicht, weil der provider direkt die FileTyp-Instanz zur\'fcckgibt, die gebraucht wird.\par
Aber ich kann eine Implementierung ohne Lock machen, die dann mit einer lock() Methode eine Instanz einer Implementierung mit Lock zur\'fcckgibt.\par
So gehts!\par
\par
\par
Durch ein paar Umstrukturierungen ist StorageInventoryFile jetzt das gleiche wie StorageLockedChannelFile nur mit einem anderen Namen.\par
Und der andere Name st\'f6rt bei den Methodensignaturen.\par
Also muss ich das noch konsolidieren.\par
\par
So. Jetzt sieht das alles schon recht ordentlich aus. Noch ein paar TODOs in den neuen Backup-Klassen, und dann gehts an die eigentliche Backup-Logik.\par
\par
\par
\par
2018-02-18\par
\par
Ich hab die Eintr\'e4ge f\'fcr diesen Tag ganz vergessen.\par
War aber nicht so viel.\par
Neben Timeline nachtragen, Bonus Standup Meeting, Brainstorming zu Produktnamen und -logo und Besprechung mit MK dazu hab ich halt die JET-55 TODOs bissl weitergemacht und Methoden konsolidiert.\par
\par
\par
\par
2018-02-19\par
\par
Weitermachen:\par
#fillEmptyBackup konsolidieren mit FileManager#readStorage\par
Achso, das geht nicht, wegen unterschiedlichen File Typen. Dann redundant bauen, macht ja nix.\par
\par
\par
\par
16:30\par
So, nach Glasschiebet\'fcr, Griffe der anderen T\'fcren durchgehen, Wasserwart, Rumtesten zu M\'e4ngeln der Glasschiebet\'fcr, Mangelmeldung Mail an Bautr\'e4ger, mach ich jetzt, 6 Stunden sp\'e4ter, wieder weiter.\par
\par
So ein BackupFile braucht irgendwoher ja dann auch mal einen Channel.\par
Aber die deswegen jetzt doch wieder auf die normale StorageFile Implementierung mit permanent gelocktem und offenem Channel \'e4ndern, w\'e4r doof.\par
Besser: FileChannel, bzw. FileLock, wird on demand ge\'f6ffnet und nach dem kopieren wieder geschlossen.\par
Implementieren. Konsolidieren mit bisherigen File Implementierungen.\par
\par
Initialisierung bauen.\par
API verbessern.\par
FIXMEs aufr\'e4umen.\par
Problem handling an allen Stellen einbauen.\par
\par
\par
2018-02-20\par
\par
Jetzt bau ich mal so einen Problemhandler, damit die ganzen TODOs verschwinden.\par
\par
Hm. Eigentlich ist es ungeschickt bzw. sogar logisch falsch. so einen problem handler tief in die Logik reinzuweben.\par
Beispiel:\par
\par
- \'e4u\'dferster Methodenaufruf (1)\par
-- enthaltener Methodenaufruf (2)\par
--- enthaltener Methodenaufruf (3)\par
\par
In (3) wird auf ein spezifisches Problem gepr\'fcft und an den Problemhandler gemeldet. Der oder sp\'e4testens eine Fallback-Logik danach muss eine Exception werfen, damit der Vorgang sauber abgebrochen wird.\par
In 1, 2 und 3 k\'f6nnen aber auch noch andere Probleme auftreten. Also muss ganz au\'dfen in (1) sowieso ein allgemeines try-catch rein, das im catch jegliche Exception an den Problem Handler reportet.\par
F\'fcr den beschriebenen spezifischen Fall hei\'dft das aber: Der Problem handler kriegt dasselbe Problem zweimal reportet, sogar seine eigene Exception.\par
Das ist mindestens ungeschickt, streng genommen sogar logisch falsch.\par
\par
Die richtige L\'f6sung ist:\par
- Problem Reporting nur in den "\'e4u\'dfersten" Methoden, die ansonsten m\'f6glichst klein ist und an innere Methoden delegiert.\par
- Innere Methoden werfen bei Problemen Exceptions, in denen der relevante State (meist Refrenzen auf die problemausl\'f6senden Instanzen) vermerkt wird.\par
- Das Problem Reporting zieht sich dann aus den Exceptions den n\'f6tigen state f\'fcr bestimmte Reporting-Methoden raus.\par
\par
Hm. Oder sollte einfach die blanke Exception weitergereicht werden? Der State ist ja mit drin. Dann m\'fcsste halt in der Empf\'e4nger-Logik ein instanceof-Baum oder ein Type-Mapping drin sein.\par
Jup. So mach ich das.\par
Entsprechend umbauen.\par
\par
\par
\par
2018-02-21\par
\par
Jetzt fehlen noch:\par
1.) ProblemHandler Implementierung bauen und entsprechend auf die Channel-Threads r\'fcckwirken lassen.\par
2.) Foundation Klasse erweitern.\par
3.) copy und truncate Methode implementieren.\par
4.) Testen, nat\'fcrlich, wie \'fcblich.\par
5.) Evtl. gleich so eine Validierungslogik bauen, die die frisch geschriebenen Teile der Backup Dateien validiert.\par
\par
Punkt #1 planen und implementieren.\par
\par
Daf\'fcr muss der StorageChannelController erweitert werden um eine Funktionalit\'e4t, fatale Exceptions zu registrieren und sobald die nicht leer sind, wirft der die in den ChannelThreads weiter.\par
\par
Achja und den Thread an sich muss ich ja auch noch irgendwo starten.\par
Das ist der BackupHandler. Der muss dann aber noch anhand des ChannelControllers checken, ob er laufen soll.\par
Hm... braucht es dann \'fcberhaupt den eingeschobene Mini-Typ ExceptionHandler? Der BackupHandler kann ja eigentlich gleich direkt dem ChannelController auftretende exceptions \'fcbergeben...\par
Rausschmeissen.\par
Passt.\par
\par
Jetzt mal zur Verkabelung des ganzen:\par
Foundaten Erweiterung bauen.\par
Es reicht eigentlich, einen StorageFileProvider backupFileProvider dort zu setzen. Wenn es einen gibt, werden die restlichen Teile referenziert bzw. bei Bedarf erstellt.\par
So bau ich das mal.\par
\par
Paar Details:\par
Der StorageBackupHandler braucht noch einen Threadnamen, nat\'fcrlich mit einem Defaultwert.\par
Und es muss auch noch so einen "gravedigger" Mechanismus f\'fcr gel\'f6schte Dateien geben.\par
Denn es muss doch m\'f6glich sein, im Backupverzeichnis Dateien zu l\'f6schen, sonst w\'fcrde eine kleine Datenbasis mit vielen stores eine gigantische Menge an Backupplatz belegen.\par
Darum steuerbar \'fcber ein Verzeichnis:\par
Selbes Verzeichnis -> lassen.\par
Andere Verzeichnis -> verschieben.\par
Kein Verzeichnis -> l\'f6schen.\par
\par
Bl\'f6d ist nur, dass ich das wieder direkt als File machen m\'fcsste, aber eigentlich will ich das ja abstrahieren.\par
Hm, oder ich mach einen String Verzeichnisnamen f\'fcr das Unterverzeichnis.\par
\par
Mit den zus\'e4tzlichen Variablen muss aber ein neuer Typ "StorageBackupConfiguration" her, der das alles h\'e4lt.\par
Dann f\'e4llt immerhin gleich die Zweideutigkeit mit dem normalen StorageFileProvider weg, nice.\par
\par
So. BackupConfiguration gebaut. Foundation erweitert. FIXMEs zum integrieren ins Starten der Storage Threads geschrieben, usw.\par
\par
Das w\'e4rs mal f\'fcr den Moment...\par
\par
\par
2019-02-22\par
\par
Besser als ein plain ThreadName mit hardgecodeter Thread Instanzierung w\'e4re ein ThreadProvider.\par
Genauso l\'e4uft das ja bei den ChannelThreads auch.\par
Also aktuellen ThreadProvider umbenennen zu ChannelThreadProvider und per copy&paste einen BackupThreadProvider bauen.\par
Hm. Und damit die Zahl der Felder im StorageManager nicht unn\'f6tig explodiert wrap ich beides jetzt wieder in einem allgemeinen ThreadProvider.\par
Hehe.\par
\par
Storage-Konstrukturmethoden f\'fcr BackupConfiguration bauen.\par
\par
BackupHandler Erstellung bauen.\par
\par
Einbauen in Storage Start.\par
\par
Das war jetzt alles bissl knifflig durch die verschiedenen Methoden und Instanzen, \'fcber die das verteilt ist.\par
StorageBackupConfiguration umbenannt zu StorageBackupSetup und um ein paar entsprechende setup~ Methoden erweitert, um das sauber zu l\'f6sen.\par
\par
Damit w\'e4ren jetzt nur noch die drei Item-Handling-Logik Methoden \'fcbrig, dann ist das Backup (ohne Validierung) fertig zum testen.\par
\par
\par
2019-02-23\par
\par
Item-Handling-Logik Methoden implementieren.\par
\par
Und gleich wieder was aufgefallen:\par
Eigentlich ist es Quatsch, die Information f\'fcr das Deleted-Verzeichnis au\'dferhalb zum FileProvider zu halten und durch die Abstraktion st\'e4ndig Probleme zu haben.\par
Viel simplere und elegantere L\'f6sung:\par
Der FileProvider providet auch die DeletedFiles und dort kann man dann hin moven. Da Waaahnsinn. D\'e4mlich, dass ich da nicht gleich drauf gekommen bin.\par
Mal so umbauen ...\par
\par
\par
2019-02-24\par
\par
Util-Konstruktur-Methoden in Klasse Storage anpassen.\par
\par
Hm. Das hei\'dft aber auch, dass ich die StorageFileWriterConserving Logik komplett wo anders hinschieben muss.\par
Fertig.\par
Sehr sch\'f6n: Die Logik f\'fcr das "Retten" normaler Storage Dateien kann f\'fcr die Backup Files mitverwendet werden.\par
Damit ist es jetzt weniger Code als zuvor, sauberer strukturiert und das Weitergeben von L\'f6schen in Backup Files ist auch gleich abgedeckt. Passt!\par
\par
\par
2019-02-05\par
\par
Die auskommentierte Sicherheitskopie eines truncateten Files k\'f6nnte ich eigentlich auch in den FileProvider rein machen.\par
Wobei das bl\'f6d ist, weil das im normalen Betrieb keinen Sinn macht, nur beim backup.\par
Hm, oder? Eigentlich machts im normalen Betrieb genauso viel Sinn wie das deletionDirectory.\par
Ok, dann bau ich das so.\par
\par
Das werden jetzt aber so viele Konstruktur-Varianten, dass es besser wird, einen Builder zu bauen.\par
Also bauen.\par
\par
So. Builder gebaut. Defaults umgezogen. Bestehende Util-Konstruktoren reduziert.\par
Dann Truncation Logik gebaut analog zu deletion Logik, aber mit Copy statt Move.\par
\par
Und dann war die eigentlich copy Methode auch nicht mehr viel: Copy Logik bissl umbenennen und dort nochmal aufrufen.\par
\par
Damit sind alle TODOs erledigt.\par
\par
Jetzt fehlt noch testen.\par
Und dann so eine Validierung der tats\'e4chlich geschriebenen Backup Daten.\par
\par
Test bauen.\par
\par
Hm. Dabei aufgefallen:\par
- Das Backup Zeug muss in die StorageConfiguration rein\par
- StorageConfiguration muss auch einen Builder haben. Ich seh das an mir selber: ich will m\'f6glichst keine eigene Configuration angeben, weil ich dann gleich alle Teile definieren m\'fcsste, anstatt nur den einen Teil, den ich brauch.\par
\par
Haha. Da gibts ein TODO von 2013 dazu.\par
Bauen.\par
\par
Hm, toll. Irgendie ist das "BackupSetup" jetzt fast \'fcberfl\'fcssig ...\par
Entweder das l\'f6schen oder, falls es doch beibehalten wird, muss das in die StorageConfiguartion rein.\par
\par
\par
2019-02-26\par
\par
Interessante Anregung aus dem Bonus Sprint Retro:\par
1.) Backup queue beim Shutdown abarbeiten (optional?)\par
2.) Zippen? Alles auf einmal oder jede Datei f\'fcr sich?\par
\par
Punkt 1 wird knifflig:\par
Es muss einen Zustand geben, in dem die Channels schon deaktiviert sind, d.h. keine neuen Tasks mehr annehmen, evtl. sogar schon die Threads beendet haben, aber die storage immer noch nicht ganz shutdown ist, sondern nur auf "interne Tasks", wie z.B. den Backup Thread, wartet.\par
Die Unterscheidung zwischen shutting down und shutdown gibt es schon, aber erst mal nur als dumme flags.\par
Was noch fehlt, w\'e4re so ein Registrierungssystem f\'fcr interne Tasks und an geeigneter Stelle eine Pr\'fcfung, ob noch einer von denen arbeitet.\par
\par
Aber erst mal die aktuelle Baustelle weitermachen:\par
BackupSetup Entscheidung: Das ist ja schon mehr als ein Wrapper f\'fcr den FileProvider. Da ist z.B. auch Logik drin.\par
Darum muss das beibehalten werden.\par
Configuration darauf umstellen.\par
\par
Jetzt noch EmbeddedStorage.Foundation() Methoden \'fcberarbeiten bzgl. eingef\'fchrtem Configuration.Builder Konzept.\par
\par
Passt.\par
Testen.\par
\par
Backup Verzeichnis legt er an.\par
Dateien werden aber keine reinkopiert. Debuggen.\par
\par
Ehm ... momendamal. In der Methode, die St\'fccke von Dateien kopiert, einfach das Kopieren kompletter Dateien aufzurufen, ist ja Bl\'f6dsinn.\par
Fixen. Bzw. das richtige Kopieren erst mal implementieren lol.\par
\par
So, fertig. Jetzt debuggen, warum da nix kopiert wird.\par
\par
Aha, der Backup Thread l\'e4uft ja gar nicht. \'c4hm lol.\par
Ah. Hehe. Ich hab den BackupHandler bisher nirgends gestartet. D.h. der Thread wird erzeugt, l\'e4uft los, checkt auf running, das ist false, und beendet sich sofort wieder. Haha.\par
Start Aufruf einbauen. Und gleich kommentieren, wieso es zwei start() gibt: Einmal state setzen, einmal den Thread starten.\par
\par
Jetzt weiter testen:\par
Oh. IllegalMonitorState. Untersuchen.\par
Achso: ich hab versehentlich statt "this.head.wait()" nur "this.wait()" aufgerufen. Sowas sind echt gef\'e4hrliche Fehler. Gut, dass das Monitoring Zeug das pr\'fcft.\par
\par
NPE: BackupHandler#dataFiles ist null. Evtl. wird der #ensureRegisteredFiles Aufruf nicht gemacht. Denn wenn, dann kann das nicht null sein.\par
Jup: das \'e4u\'dfere #initialize wird nie aufgerufen.\par
Entsprechend einbauen.\par
Daf\'fcr muss der BackupHandler zum FileManager durchgereicht werden.\par
Und daf\'fcr muss ich die Initialisierung des BackupHandlers umbauen.\par
Aber wird schon.\par
\par
Testen.\par
L\'e4uft durch.\par
Dateien sind da.\par
Aufs Byte genau gleich gro\'df.\par
\par
Also erster Test erfolgreich.\par
\par
Jetzt w\'fcrden dann noch viele weitere Tests fehlen f\'fcr weitere Headfiles, teilweises Kopieren, deletion, truncation, ...\par
\par
Prinzipiell ist es mal fertig implementiert.\par
\par
\par
2019-02-27\par
\par
Dann bau ich jetzt gleich mal die Validierung mit ein.\par
\par
Dazu im FileManager den Code zum Iterieren von Storage Dateien suchen.\par
Evtl. sollt ich den dann sauber rausmodularisieren und wiederverwenden.\par
Hm, ja, das m\'fcsst ich daf\'fcr alles ein wenig umgestalten.\par
Mal einen Plan machen ...\par
\par
\par
\par
\par
Vorbereitung:\par
- Leseoffset feststellen (f\'fcr initialisierung 0, f\'fcr backup validierung bisherige file l\'e4nge)\par
- Lesel\'e4nge feststellen (f\'fcr Initialisierung L\'e4nge des Files, f\'fcr backup validierung l\'e4nge der backup kopie)\par
- Buffer vorbereiten mit lesel\'e4nge\par
\par
Einlesen:\par
In:\par
- File (Quelle der Daten)\par
- FileOffset (Beginn der Daten im File)\par
- Buffer (bereits mit richtiger L\'e4nge)\par
Out:\par
[nichts, \'fcbergebener Buffer ist gef\'fcllt]\par
\par
Iterieren:\par
- von buffer startadresse bis buffer endadresse:\par
- item l\'e4nge lesen und evaluieren (negativ ist kommentar, 0 ist Fehler, positiv ist L\'e4nge des Entities)\par
- Adresse des n\'e4chsten Items berechnen: Aktuelle adresse plus item l\'e4nge. Validieren: darf nicht nach buffer endadresse liegen.\par
- F\'fcr Entity Handling Logik aufrufen mit Entity Adresse (f\'fcr Storage Initialisierung Entity Index erweitern, f\'fcr backup Validierung TID und OID pr\'fcfen, evtl. auch die G\'fcltigkeit der L\'e4nge anhand des TypeHandlers)\par
\par
Nachbereitung:\par
- File IO-Resource zur\'fcckgeben (bei Storage File Channel offen lassen, bei Backup File channel schlie\'dfen)\par
- Evtl. buffer state resetten\par
\par
\par
Dann mach ich eine Instanz, bei deren Erzeugung mitgegeben wird:\par
- eine maximum Buffer Capacity\par
- eine File Callback Logik, die am Ende der handling Methode aufgerufen wird.\par
\par
Und eine Methode, die \'fcbergeben bekommen:\par
- File\par
- offset\par
- length (darauf wird der buffer gelimitet)\par
- entity handler callback\par
\par
\par
Hm, es g\'e4b schon den StorageDataFileItemIterator, aber der macht das ziemlich komplexe Konzept, \'fcber die Daten st\'fcckchenweise dr\'fcberzuiterieren. Theoretisch besser, falls mal ein File riesig sein sollte, aber auf absehbare Zeit nicht n\'f6tig.\par
Ersetzen/l\'f6schen kann ich ihn nicht, weil der noch im Import verwendet wird.\par
\par
Ich denk ich bau neben dem einfach einen neuen, simpleren und eleganteren nach obigem Konzept.\par
\par
\par
\par
2019-02-28\par
\par
09:00 OGS\tab\tab JET-55 weitermachen.\par
09:45 ---\tab\tab Pause.\par
10:55 Bonus\tab BON-830 Teamviewer Recherche. Vorher rumprobieren mit VPN, ob ich auf den EMV Bugtracker zugreifen kann.\par
11:10 OGS\tab\tab JET-55 weitermachen.\par
12:15 ---\tab\tab Pause.\par
13:50 Bonus\tab Telefonat mit XH zu Perfacto Datei \'c4nderung und neu erzeugen lassen.\par
14:05 OGS\tab\tab JET-55 weitermachen.\par
\par
\par
EntityDataIterator fertig bauen.\par
\par
Wenn ich einen L\'e4ngenwert zur\'fcckgeb, um unvollst\'e4ndiges Lesen anzugeben, kann die Implementierung sogar so wie die alte zum iterativen durchschaufeln einer Datei verwendet werden.\par
F\'fcr den konkreten Anwendungsfall, eine komplette Byte Range durchiterieren, kann ich bei einem Mismatch im \'e4u\'dferen Kontext immer noch eine Exception werfen.\par
\par
Die Frage ist jetzt nur, welchen Wert ich zur\'fcck geb. Gesamtl\'e4nge aller komplett gelesenen Items oder irgendwie ein lookahead Wert oder so, um gleich zum n\'e4chsten Item springen zu k\'f6nnen.\par
Hm. Die erste Variante ist die einfachste und m\'fcsste trotzdem f\'fcr alle denkbaren Anwendungsf\'e4lle reichen.\par
Beispiel:\par
Buffer ist 1000 gro\'df aber bei Index 0 liegt ein Entity mit L\'e4nge 1200.\par
Wenn nur header gescannt werden sollen (validierung und initialisierung), kann das ja gemacht werden und die Methode gibt dann als verarbeitete Gesamtl\'e4nge 1200 zur\'fcck. Auch wenn der Buffer nur 1000 lang ist, macht ja nix.\par
Wenn das Entity komplett gelesen werden soll, wird 0 zur\'fcckgegeben, d.h. das entity konnte nicht verarbeitet werden.\par
Es gibt dann verschiedene M\'f6glichkeiten, mitzukriegen, dass der Buffer erweitert werden soll:\par
- In der Implementierung intern in so einem "incomplete" Fall die l\'e4nge des letzten Entities checken und die Buffer Capacity damit abgleichen und ggf. einen gr\'f6\'dferen Buffer allokieren.\par
- Oder: R\'fcckgabewert 0 interpretieren als: Buffer Kapazit\'e4t ist zu klein. Als Sonderfallbehandlung entity(header) aus dem Buffer auslesen (die muss ja an index 0 stehen) und dann den Buffer im externen Kontext vergr\'f6\'dferen.\par
\par
So oder so, man hat M\'f6glichkeiten, ein "h\'e4ngenbleiben" an einem zu kleinen Buffer zu verhindern.\par
Dann geb ich einfach die Gesamtl\'e4nge der verarbeiteten Items zur\'fcck. Passt.\par
\par
\par
Einen Validator muss ich auch noch bauen. Den kann man dann gleich h\'fcbsch autark aufrufen, unabh\'e4ngig vom Backup.\par
Die Logik kopier ich aus der Entity Registrierung raus. Macht schon Sinn, dass die ihre eigene hardgecodete Implementierung beh\'e4lt, um so schnell wie m\'f6glich zu sein.\par
\par
Hm.\par
Die Validierung der TypeId erfolgt implizit \'fcber den Lookup des TypeHandlers, klar.\par
Validierung der Entity L\'e4nge beim Einlesen find ich gar nicht. Muss ich rausgenommen haben. War das was wegen Legacy Type Mapping? Kanns eigentlich nicht sein ...\par
Und ObjectId Validierung ... mal schauen.\par
Aaach, L\'e4ngenvalidierung wird doch gemacht. Zusammen mit der OID Validierung in der extra Methode StorageEntityCache#validateEntities, mit der auch die ID Analyse gemacht wird.\par
Nebenbei dort die Validierung einer OID als TID mit Kommentar auskommentieren, weil das seit dem LegacyTypeMapping nicht mehr stimmt.\par
\par
F\'fcr die blanke Validierung reicht aber eine viel simplere Methode. Die gibts auch schon, wird z.B. f\'fcr den Import verwendet:\par
Persistence.validateObjectId(objectId);\par
\par
\par
\par
Hei\'dft:\par
1.) TID Validierung \'fcber StorageEntityTypeHandler Lookup\par
2.) Length Validierung \'fcber StorageEntityTypeHandler#validateEntityGuaranteedType\par
3.) OID Validierung \'fcber Persistence#validateObjectId\par
\par
Das hei\'dft der EntityValidator muss den TypeHandlerLookup der Storage kennen.\par
Und das geht \'fcber:\line final StorageEntityTypeHandler typeHandler = this.typeDictionary.lookupTypeHandlerChecked(typeId);\par
(Checked Variante schnell eingebaut, damit das l\'e4stige if aus dem verwendenden Kontext raus und zentral ist)\par
\par
Mal so einbauen.\par
\par
Dabei aufgefallen:\par
Der Validator muss timeouten und dann aufger\'e4umt werden, damit er nicht mit einem bequem riesig allokierten ByteBuffer permanent sinnlos Memory belegt.\par
FIXME daf\'fcr geschrieben.\par
\'c4h ... und gleich einbauen.\par
\par
Initialisierung durchreichen zu StorageManager.\par
Creator Stuff usw. daf\'fcr bauen.\par
Auch gleich mit optionalem DebugLogger, damit man das h\'fcbsch einfach sehen kann.\par
\par
StorageFoundation erweitern.\par
\par
Testen ...\par
\par
L\'e4uft auf Anhieb durch mit sauberen Loggingausgaben.\par
Aber, hehe, ein Problem:\par
Es wird nat\'fcrlich auch versucht, Transaction Files auf enthaltene Entities zu validieren. Das ist nat\'fcrlich Quatsch.\par
Es macht jetzt auch keinen gro\'dfen Sinn mehr, die ganze API aufzublasen mit Fallunterscheidungen f\'fcr Data Files und Transaction Files.\par
Die Transaction Files fliegen mittelfristig eh raus.\par
Stattdessen hack ich eine Sonderfallabfrage rein: if transaction file, dann keine validierung.\par
\par
Oh, bug: Backup Data Files werden mit fileindex -1 (transaction file hack) erzeugt. Untersuchen.\par
\par
Ach, dreher in der umgestalteten Identifizierungsmethode drin.\par
Fixen. Testen. Passt.\par
\par
\par
Jetzt noch die Testklasse ein bisschen verbessern bzw. \'fcberhaupt mal eine eigene bauen, die die g\'e4ngigen F\'e4lle abdeckt. Mehrfach storen, Neues Headfile, usw.\par
\par
Oh, StorageExceptionBackupInconsistentFileLength bei bestehender Storage. Muss ich mal untersuchen.\par
Da f\'e4llt mir auf: Es fehlen bei den Backup Exceptions noch die assemble Methoden, damit die zugeh\'f6rigen Werte ausgegeben werden.\par
Einbauen.\par
Damit debuggen.\par
Exception beim Exception assemblen, haha, weil length nicht geht, weil der channel schon geschlossen ist.\par
Exception erweitern um felder f\'fcr die tats\'e4chlichen l\'e4ngen zum zeitpunkt der validierung.\par
\par
Damit testen.\par
Weicht tats\'e4chlich ab.\par
Debuggen / printen, warum.\par
\par
irgendwie scheint ab dem zweiten kopieren im sourcefile der source offset um ein entity zur\'fcck zu gehen oder so \'e4hnlich.\par
Muss ich dann morgen checken.\par
\par
\par
2019-03-01\par
\par
Erst mal die fehlgeschlagenen beiden Committs manuell mergen.\par
\par
Jetzt Fehlersuche. Debugausgaben verbessern, damit ich nicht immer manuell L\'e4ngen nachrechnen muss.\par
Rumsuchen ...\par
\par
Ach! Ich bin ja ein Depp. Ich kopier bei einem Transfer vom richtigen source file, richtigem Offset, richtige L\'e4nge an das Ende des Backup File, das dem Source File entspricht anstatt dem Target File des Transfers.\par
Dann bekommt die Backup Version des Source files nat\'fcrlich eine inkonsistente (zu gro\'dfe) L\'e4nge.\par
\par
Hm. Das w\'e4r ohnehin der einzige Fall, wo source- und target file \'fcbergeben werden.\par
Eigentlich k\'f6nnte ich das konsolidieren auf nur source file und im transfer fall wird das target file als source f\'fcr die backup kopie angegeben.\par
\par
Umbauen.\par
Testen.\par
Jetzt siehts gut aus.\par
\par
Testen, ob beim Neustart wieder die Exception kommt.\par
Nein. Backup Files sind konsistent.\par
Aber daf\'fcr: ClosedChannelException.\par
Seltsam. Die Backup Files sollten doch eigentlich den channel bzw. das lock beim closen vergessen und bei bedarf neu aufmachen.\par
Muss ich dann untersuchen.\par
\par
Puh. Erst mal die Implementierung etwas konsolidieren. Da werden die logisch gleichen Dateien an mehreren Stellen instanziert.\par
So. Jetzt ist es noch genau eine Stelle f\'fcr Transaction Files und eine f\'fcr normale Files. Passt.\par
\par
Jetzt Exception untersuchen ...\par
Ah, okay: das sammeln von existierenden Dateien erzeugt immer noch direkt inventory Files.\par
Hm, aber warum stand dann im Debugger NumberedFile?\par
Aach: Erst wird beim Sammeln ein InventoryFile erzeugt. Das holt sich einen Lock. Dann wird f\'fcr dieses File als Vorlage nochmal (unn\'f6tig) ein File providet. D.h. andere Instanz, die auf dasselbe physische File zeigt. Und die kollidieren dann mit ihren Locks.\par
\par
L\'f6sung:\par
1.) Erst mal darf das Sammeln kein Inventory File instanzieren, das ein permanentes Lock h\'e4lt. Ggf. muss daf\'fcr die Verwendung in der Storage Initialisierung angepasst werden.\par
2.) Doppeltes Providen rausmachen. Einmal reicht.\par
\par
Ah, #1 ist schon mal kein Problem, weil dort eh schon inventorize() aufgerufen wird. Dann hab ich neulich nur die Anpassung in der Sammellogik vergessen. Passt.\par
\par
Umbauen.\par
Testen.\par
Passt. Keine Exception mehr.\par
\par
Jetzt gleich noch die bisher fehlende Validierung des Iterierungsr\'fcckgabewerts im Validator einbauen.\par
Testen. Nat\'fcrlich Bug reinprogrammiert. Fixen. Passt.\par
\par
Weiter testen. Nach paar mal problemlosen durchl\'e4ufen kommt jetzt eine StorageExceptionBackupCopying beim Backup updaten w\'e4hrend dem Initialisieren.\par
Da fehlt nat\'fcrlich erst mal wieder die assemble Logik. Nachr\'fcsten.\par
\par
Damit das eigentliche Problem weiter testen.\par
Aha. Da ist ein Data File mit L\'e4nge 0. Wenn das entsteht, bringt der n\'e4chste Start eine Exception. Der \'fcbern\'e4chste aber seltsamerweise nicht mehr, weil wohl die Storage Initialisierungslogik die Datei l\'f6scht oder einen Transfer reinkopiert oder so.\par
Die Frage ist, wieso es \'fcberhaupt ein L\'e4nge-0 File geben kann ohne unvorhergesehenen Programmabbruch.\par
Hm. Bzw anders rum: Es kann auch mal ein unvorhergesehener Programmabbruch sein, d.h. ein L\'e4nge-0-File kann schon mal zustande kommen. Das darf dann aber beim Backupdateien checken keine Exception ergeben.\par
\par
Au\'dferdem ein Problem: das BaseException Konzept assemblet die Details mehrfach, obwohl der assemble Code das offensichtlich nicht macht. Muss ich debuggen.\par
Ach, der Throable Konstruktur ruft pauschal das getMessage auf, wenn ein cause mit \'fcbergeben wird.\par
Sowas Schwachsinniges hab ich noch nicht gesehen...\par
Mal schauen, ob ich das fixen kann. Ja, gottseidank.\par
Auch gleich f\'fcr die anderen Konstruktoren mit cause. Ach Moment: die verhalten sich ja inkonsistent zum anderen Konstruktur und damit korrekt, lol.\par
\par
Wieder weitertesten.\par
Ah, \'fcber 5 Ecken war der Grund, dass bei Lese-Buffer null eine capacity 0 zur\'fcckgegeben wird. Bei Lesel\'e4nge 0 hei\'dft das, es muss kein neuer Buffer instanziert werden. D.h. das Feld bleibt null. Dann kommts beim Buffer vorbereiten f\'fcrs lesen zu einem NPE.\par
Das ist ein bug: 0 Capacity ist ein valider wert. Eine null-Buffer-Referenz muss -1 zur\'fcckgeben. Dann passt die Pr\'fcfung.\par
\par
Testen. Sieht gut aus. Keine Exception mehr bei 0-Files.\par
\par
L\'f6schen von Dateien, also verschieben der gel\'f6schten Dateien in einen "deleted" Ordner unter Backup, funktioniert auch, seh ich.\par
\par
Hm. Eigentlich br\'e4uchte ich es kleines skriptls, das storage-Dateien und Pendant im Backup Verzeichnis byte f\'fcr byte vergleicht, um wirklich zu pr\'fcfen, ob alle Backup-St\'fcckel-Kopierungen immer aufs Byte exakt richtig arbeiten.\par
Das muss ich dann mal bauen. Ist ja nicht so viel.\par
Jetzt noch Issues updaten.\par
\par
\par
2019-03-03\par
\par
Lokale Committs mergen.\par
Okay, ist mal erfrischend unproblematisch gegangen ...\par
\par
Beim Issue Update schreiben war mir ja noch aufgefallen, dass ich mich noch um das Backuppen des Dictionaries k\'fcmmern muss.\par
Am besten w\'e4re, wenn der Pfad daf\'fcr auch von einem FileProvider k\'e4me und der BackupFileProvider leitet dann dieses Interface auch einfach mit ab.\par
Muss ich mal anschauen...\par
\par
Das w\'fcrde auch gleich die bisher recht l\'e4stige Notwendigkeit f\'fcr einen redundanten Pfad im Foundation instanzieren (einmal f\'fcr Storage, einmal f\'fcr Dictionary) eliminieren.\par
\par
Das Problem w\'e4r allerdings, dass es f\'fcr das TypeDictionary keine File Abstrahierung gibt, so wie f\'fcr Storage Dateien.\par
Bzw. die gibts dort auch noch nicht, sind bisher nur plain strings, aber vorgesehen ist es schon.\par
Naja gut, ich k\'f6nnt analog dazu f\'fcrs TypeDictionary auch so machen. Aber dann m\'fcsste das Ding, das bei der Storage nur ein FileProvider ist, beim Dictionary gleich der DictionaryProvider sein, das ist doof.\par
Mal \'fcberlegen ..\par
\par
Also eigentlich ist es ja so:\par
Wenn das Ding mal unabh\'e4ngig bzw. abstrahiert von einem konkreten Filesystem, also auch irgendwie \'fcber ein Cloud Store bla dings oder \'fcber ein RDBMS oder so laufen soll, dann m\'fcssen alle Dateien abstrahiert sein, nicht nur die Storage Dateien.\par
D.h. es m\'fcsste eigentlich schon auf Persistence-Ebene eine Abstraktion geben wie etwa:\par
- PersistenceDataItem (kann Folder oder File sein)\par
- PersistenceDataLocation extends PersistenceDataItem (Folder, hat n PersistenceDataItems, jedes mit unique name)\par
- PersistenceDataFile extends PersistenceDataItem (File, muss immer Folder + String name sein)\par
\par
Dann k\'f6nnte man einen PersistenceFileProvider machen, der sowohl f\'fcr Storage als auch f\'fcr Dictionary File Items providet. F\'fcr die Storage selbst und f\'fcrs Backup.\par
\par
Die Storagedateien k\'f6nnten diese Typen extenden.\par
\par
Problem ist, dass diese Dinger dann auch ihre spezifische, aber gekapselte IO-Logik mitbringen m\'fcssen.\par
Und das bei\'dft sich dann ziemlich damit, dass \'fcberall FileChannel verwendet wird.\par
Die Abstraktion daf\'fcr hab ich ja schon mal angefangen, aber nur f\'fcr die Storage Ebene und noch nicht fertig.\par
Daran jetzt wieder rumzurei\'dfen w\'e4re zu viel Aufwand.\par
Oh Mann!\par
\par
Also es w\'fcrde eigentlich schon reichen, einen PersistenceTypeDictionaryIoHandler.Provider zu bauen und den dann zu extenden.\par
Das mach ich mal. Plus Kommentar dazu, wie man das eigentlich sauber abstrahieren m\'fcsste.\par
\par
Beim einbauen aufgefallen: Wenn im FileProviderBuilder null Werte gesetzt werden, sollten/m\'fcssen die ja noch mit defaults aufgef\'fcllt werden. Aber das mach ich nicht in Konstruktoren und Gettern, sondern beim createn. Damit kann man sauber abfragen, ob Werte null sind.\par
}
 