{\rtf1\ansi\ansicpg1252\deff0\deflang1031{\fonttbl{\f0\fnil\fcharset0 Calibri;}}
{\colortbl ;\red102\green102\blue102;\red255\green0\blue0;}
{\*\generator Msftedit 5.41.21.2510;}\viewkind4\uc1\pard\sl276\slmult1\cf1\lang7\f0\fs28 2019-12-04\par
\par
Erst mal Konzeptplanung notieren.\par
\par
Der aktuelle Stand ist:\par
- Es gibt eine zentrale ObjectRegistry, in der object<->objectId Assoziationen registriert werden.\par
- objectIds werden assoziiert bevor rausgeschrieben wird.\par
- Wenn beim Rausgeschrieben was schief gehen sollte, bleiben die assoziierten Eintr\'e4ge stehen.\par
- Der n\'e4chste store, der auf die Instanzen trifft, sieht die existierende objectId und speichert die Instanz nicht, weil sie als schon gespeichert angenommen wird.\par
=> Instanz wurde nie gespeichert.\par
\par
L\'f6sung:\par
W\'e4hrend einem Store neu vergebene objectIds m\'fcssen erst mal vorgehalten werden und erst nach erfolgreichem store gemerget werden.\par
\par
Nat\'fcrlich kann es mehrere gleichzeitig aktive Storer in mehreren Threads geben, darum muss das ganze multithreading-f\'e4hig ablaufen.\par
Ungef\'e4hr so:\par
\par
- Jeder storer registriert sich bei der ObjectRegistry.\par
- Neu vergebene ObjectIds werden NICHT in die ObjectRegistry eingetragen, sondern nur lokal im Storer.\par
- Wenn ein Storer im zentralen Register f\'fcr ein Objekt keine ObjectId findet, schaut er erst mal in den lokalen der anderen, aktuell existierenden storer.\par
- Wenn er f\'fcndig wird, kopiert er diesen Eintrag in sein eigenes Register. Es kann n\'e4mlich sein, dass der andere storer fehl schl\'e4gt, aber er nicht und dann muss sein Id-commit die Assoziation enthalten.\par
- Wenn ein storer erfolgreich geschrieben hat, merget der commit am Ende die lokal vergebenen ObjectIds in das zentrale register.\par
\par
Concurrency:\par
Lokale Lookups \par
\par
\par
2019-12-05\par
\par
Okay, wieder mal was dazwischen gekommen. Weiter im Text.\par
\par
Concurrency:\par
Lokale Lookups m\'fcssen nat\'fcrlich synchronized sein.\par
Der Lookup insgesamt muss synchronizet sein.\par
Hei\'dft:\par
- Lock auf Registry\par
- Wenn keine OID gefunden, dann storer f\'fcr storer locken und pr\'fcfen (synchronized lookupObjectId(object) ).\par
\par
Genauer gesagt so:\par
- erst mal sich selbst locken und bei sich selbst nachschauen\par
- Dann registry locken und dort nachschauen\par
- Wenn darin nix gefunden, dann unter immer noch dem Lock auf die Registry die registrierten storer durchlaufen (und sich selber skippen).\par
\par
Klingt sehr aufwendig, aber im normalfall sollten die Storer allein sein oder es gibt vielleicht mal 1-2 gleichzeitige. Da spielt das keine Rolle.\par
\par
Als Typ reicht registry-intern PersistenceObjectIdLookup. Mehr soll so eine Storer den anderen nicht bereitstellen.\par
\par
\par
Interessant ist jetzt aber noch folgender Fall:\par
- Ein Storer registriert eine Instanz neu. Erst mal lokal bei sich.\par
- Damit storet er sie auch voll.\par
- Ein anderer storer storet dieselbe Instanz und holt sich die OID vom ersten storer.\par
- Jetzt geht beim rausschreiben des ersten storers war schief.\par
- Dann w\'fcrde wieder kein Datensatz f\'fcr das objekt gespeichert.\par
Hei\'dft:\par
Wenn ein storer von einem anderen die ID \'fcbernimmt anstatt aus der zentralen registry, muss er das objekt "vorsichtshalber" auch nochmal speichern.\par
Dass das dann noch einen konsistenten Zustand hat ist die (Concurrency-)Verantwortung der Anwendung: Wann werden welche instanzen mit welchen Zustand serialisiert?\par
\par
\par
Um sich selbst skippen und Registrierungen \'fcbernehmen zu k\'f6nnen, muss sich der storer beim ensureObjectId aber selbst mit \'fcbergeben.\par
Ah, das gibts sogar schon, aber nur mit PersistenceAcceptor.\par
Dann bohr ich das auf, l\'f6sch daf\'fcr die Einzel-Parameter-Methode und dann passt das.\par
\par
Ah, noch ein Sonderfall:\par
Skip-Eintr\'e4ge d\'fcrfen nat\'fcrlich nicht am Ende mitgemerget werden.\par
Hm. Eigentlich d\'fcrfen sie auch nicht von anderen Storern \'fcbernommen werden, sonst storen die einen geskippten Eintrag n\'e4mlich auf einmal doch.\par
Hei\'dft: solche Skips m\'fcssen eigentlich in einer extra storer-lokalen registry sein.\par
Aber das geht auch nicht, weil die ja in den normalen storer Items drin sein sollen, damit sie mit verarbeitet werden.\par
Ne, stimmt nicht, die sind nicht in der item linked list drin, nur im hash lookup.\par
Hm. Aber mich nervt das mit dem doppelten lookup.\par
Wie w\'e4r es denn so:\par
Der Lookup zwischen zwei Storern erfolgt \'fcber eine extra Methode und die pr\'fcft auf handler == null. Wenn null, dann nicht \'fcbergeben.\par
Wobei auch das nicht so einfach ist. Dann speichert der eine Storer Instanz X mit ID so-und-so und der andere Storer mit einer ganz anderen.\par
Hm. Oder ist das dann die Gefahr von dem skipMapped? Weil die anderen beiden Versionen w\'e4ren ja recht konsistent: null-out oder existierende Id.\par
Hm.\par
Aber das Problem ist:\par
Es m\'fcsste dann auch \'fcbergeben werden, dass f\'fcr solche Eintr\'e4ge eben doch nur die Id gespeichert werden soll und nicht der Datensatz. Also braucht das auch eine zweite Methode beim Empf\'e4nger-Storer.\par
Aber dann gehts.\par
\par
\par
2019-12-06\par
\par
Aber Moment mal ... sollten Skip-Eintr\'e4ge \'fcberhaupt \'fcbernommen werden? Die wurden ja immerhin lokal beim Storer registriert und niemand sagt, dass alle zuf\'e4llig aktiven Storer die auch genauso verwenden sollen.\par
Also sollten Skipeintr\'e4ge also eher ignoriert werden.\par
Konsistentzprobleme sollte es nicht geben, denn:\par
- beim default skip wird entweder die global g\'fcltige objectId verwendet oder 0/null.\par
- bei skipNulled wird immer 0/null verwendet, also kein Problem.\par
- bei skipMapped muss man schon wissen, was man tut. Etwa ein "ummappen" von objectIds f\'fcr eine Aufteilung der Storage oder irgendsowas. Das muss nicht konsistent zu anderen, gleichzeitigen Storern sein.\par
\par
Ah, und es muss auch gar keine accept methode f\'fcr den normalfall geben, weil das ist genau die accept des storers, die es schon gibt.\par
\par
Hm. Dabei muss ich jetzt mal das ganze Gewurschtel mit Persistence.nullId() mal als "not found" und mal als "null" konsolidieren.\par
Am besten gleich mit gescheit zentralisierten Methoden inklusive Testmethoden, so dass die tats\'e4chlichen Werte letztendlich fast egal sind. Zumindest f\'fcr den unfound Fall.\par
\par
Oh, dabei aufgefallen:\par
Wenn man das gescheit macht, kann man in Lazy ordentlich unterscheiden zwischen "null und noch nicht geladen" und "null, weil es wirklich null sein soll". Das erste hat null & properId, das zweite hat null & nullId.\par
Hurra!\par
Einfach mal sauber arbeiten, dann kriegt man Mehrwert gratis geschenkt ...\cf0\par
\par
\par
2020-03-12\par
\par
Nach ... gerade mal 4 Monaten ... und unz\'e4hligen dazwischengeschobenen \'c4nderungen mach ich hier wieder weiter.\par
Ich hab versucht, das Ding zu mergen, aber es gibt haufenweise konflikte in einem halben Dutzend Dateien. Die Lazy.java erkennt zumindest Sourcetree gar nicht mehr als Textdatei (was wirr ist), usw.\par
Ich denke, es ist g\'fcnstiger, einen zweiten Branch f\'fcr dieses Issue aufzumachen, mich wieder in Konzept und Code einzulesen und dann die bisherigen \'c4nderungen manuell in den aktuellen Stand zu \'fcbernehmen.\par
\par
Beim Einlesen ist mir auch gleich ein Problem am bisherigen Konzept aufgefallen. Oben steht:\par
---\par
\i Interessant ist jetzt aber noch folgender Fall:\par
- Ein Storer registriert eine Instanz neu. Erst mal lokal bei sich.\par
- Damit storet er sie auch voll.\par
- Ein anderer storer storet dieselbe Instanz und holt sich die OID vom ersten storer.\par
- Jetzt geht beim rausschreiben des ersten storers war schief.\par
- Dann w\'fcrde wieder kein Datensatz f\'fcr das objekt gespeichert.\par
Hei\'dft:\par
Wenn ein storer von einem anderen die ID \'fcbernimmt anstatt aus der zentralen registry, muss er das objekt "vorsichtshalber" auch nochmal speichern.\par
Dass das dann noch einen konsistenten Zustand hat ist die (Concurrency-)\b Verantwortung der Anwendung\b0 : Wann werden welche instanzen mit welchen Zustand serialisiert?\i0\par
---\par
\par
Ich bin mir nicht sicher, ob es wirklich korrekt bzw. nachvollziehbar und zumutbar w\'e4re, das so zu l\'f6sen.\par
Dass man einen concurrency-m\'e4\'dfig korrekt koordiniert einen konsistenten Zustand in den Storer kriegt, ist die Verantwortung der Anwendungslogik. Das ist soweit richtig.\par
Aber das Problem hier ist ja:\par
NACHDEM man das korrekt gemacht hat, kann es sein, dass das "vorsichtshalber nochmal speichern" einen inkonsistenten Zustand speichert, weil die Locks der Anwendungslogik schon l\'e4ngst wieder aufgehoben sind und die Anwendung schon wieder rumge\'e4ndert hat.\par
Hm. Oder m\'fcsste der zweite Speichervorgang mit dem zweiten Storer, der ja die betreffende Instanz nochmal speichern will, dann eben auch nochmal f\'fcr Sicherheit und konsistentes Speichern sorgen?\par
Eigentlich schon. Wahrscheinlich hab ich oben das gemeint.\par
Das k\'f6nnte dann sogar schon ein anderer Stand sein als der, der in den ersten Storer reinserialisiert worden ist.\par
Hm. DAS wiederum wirft wieder ein neues Problem auf:\par
- Storer 1 speichert Zustand zum Zeitpunkt t+0.\par
- Storer 2 speichert Zustand zum Zeitpunkt t+1.\par
- Storer 2 Inhalt wird rausgeschrieben.\par
- Storer 1 Inhalt wird rausgeschrieben.\par
Damit ist der "aktuellste" Stand der persistenten Daten der des Zeitpunkts t+0, obwohl in der Anwendung der Stand t+1 vorliegt.\par
Das ist datenm\'e4\'dfig eine Inkonsistenz und concurrencym\'e4\'dfig eine Racecondition.\par
\'c4h... Shit.\par
\par
Also muss irgendwie eine Reihenfolge sichergestellt werden oder es darf immer nur einen aktiven Storer gleichzeitig geben.\par
Wobei das mit der Reihenfolge kaum l\'f6sbar w\'e4re. Es w\'fcrde ja nicht reichen, die Storer in der Reihenfolge ihrer Erstellung rauszuschreiben.\par
Erstens w\'fcrde dann ein lange brauchender oder sogar nie committeter fr\'fcherer Storer alle anderen Storer blocken. "F\'fcr immer" oder zumindest bis zu einem Timeout, der aber auch erst mal zu implementieren w\'e4re. Und Timeouts sind immer schei\'dfe, weil sie in verschiedenen F\'e4llen immer zu kurz oder zu lang sind.\par
Zweitens kann es ja sein, dass ein FR\'dcHER erstellter Storer den SP\'c4TEREN Zustand eines Datensatzes speichert.\par
Puh...\par
Also so:\par
- Storer 1 wird erzeugt und eingereiht.\par
- Storer 2 wird erzeugt und eingereiht.\par
- Storer 1 speichert anderes Zeug ...\par
- Storer 2 speichert Zustand von Object X zum Zeitpunkt t+0.\par
- Storer 1 speichert Zustand von Object X zum Zeitpunkt t+1.\par
- Storer 1 Inhalt wird rausgeschrieben.\par
- Storer 2 Inhalt wird rausgeschrieben.\par
\par
Damit w\'fcrde halt WIEDER der alte Zustand den neuen \'fcberschreiben. Genauso inkonsistent. Genauso eine Race Condition, nur im Graph durchlaufen anstatt in der Rausschreibereihenfolge.\par
\par
Da kommt wirklich die Idee auf, ob es nicht einfach nur zu jedem Zeitpunkt nur einen Storer geben darf.\par
Wobei der ja eben erstellt und einfach nie verwendet werden kann, wenn man keinen commit aufruft. Und Timeouts sind schei\'dfe.\par
Das wird jetzt ganz sch\'f6n knifflig ...\par
Da muss ich morgen mal genauer dr\'fcber nachdenken ...\par
\par
\par
\cf2\ul\b /!\\\ulnone\b0  ACH, und das mit der Lazy Reference muss ich mal noch checken und ggf. \'fcbernehmen.\cf0\par
\par
\par
2020-03-13\par
\par
Das mit den Lazy References schau ich jetzt mal an.\par
Ach, das war das mit dem notFoundId -1 anstatt null zur\'fcckgeben und paar querying-Methoden daf\'fcr.\par
Das wird jetzt nicht so einfach zu mergen ...\par
Mal wichtige Klassen manuell kopieren und dann mit dem aktuellen master bzw. priv#182_2 branch abgleichen.\par
Hm. Das notFoundId gibts schon, aber anders benannt.\par
Die Querying Methoden gibts noch nicht.\par
Zusammenf\'fchren.\par
Und am besten gleich mal alles von diesem grundlegenden ID-Zeug in die Swizzling Klasse verschieben.\par
Erstens, damit nicht haufenweise redundante delegate-Methoden entstehen.\par
Und zweitens, weil die ja eh alle dort sein m\'fcssen, wenn die in Lazy verwendbar sein sollen. Das liegt ja im base package und hat keinen Zugriff auf das Persistence Package.\par
\par
\par
2020-03-15\par
\par
Diese Sache mit der Race Condition zwischen parallelen Storern hat mich ziemlich viel nachdenken lassen. Inklusive L\'f6sung, was ich jetzt mal alles aufschreibe.\par
Man k\'f6nnte ja sagen, dass mehrere parallelle Storer managen in der Verantwortung der Anwendung liegt. ABER: Wenn man die Convenience API des StorageManager verwendet, sieht man von Storern gar nichts.\par
Zwei parallele Aufrufe derselben Methode k\'f6nnen zwei parallel verwendete Storer Instanzen erzeugen, die dann je nach gr\'f6\'dfe des iterierten Objektgraphs, Thread-Unterbrechungen, usw. jede beliebige Kombination von inkonsistenten Zust\'e4nden sammeln und dann in einer Race Condition rausschreiben k\'f6nnen.\par
Darum liegt die Idee nahe, den Weg \'fcber die Convenience-Schicht concurrency-m\'e4\'dfig zu vereinfachen. Und nur, wenn das wirklich ein Problem ist, kann man dann auf parallele Storer umsteigen, aber dann muss man auch selbst Verantwortung daf\'fcr \'fcbernehmen, dass die parallelen storer race-condition-frei verwendet werden. Das ist die optimale L\'f6sung f\'fcr jeden Anwendungsfall und jede Problembewusstseinstiefe.\par
\par
Erst dachte ich, ich mach in den StorageManager neben der singleton Connection auch einen singleton storer rein. Und der m\'fcsste dann irgendwie ein buffer-gr\'f6\'dfen-basiertes "AutoCommit" haben. Wobei dann knifflig w\'e4re, wann der letzte commit erfolgen sollte. Per extra gestartetem Thread nach einem Timeout? Viel zu kompliziert und ... "unverl\'e4sslich" (oder was ist das deutsche Wort f\'fcr unreliable?).\par
Dann dachte ich: Einfach einen Singleton Storer und den immer locken.\par
Inzwischen denk ich mir aber: Es reicht v\'f6llig, mit der Storer-Instanzierung alles so zu lassen, wie es ist. Es muss einfach nur die Methode, in der der storer erzeugt wird, synchronized sein.\par
Dann stellen sich alle Threads, die den sorglos-simpel Weg nehmen, brav hintereinander an. Und wem das nicht reicht, der kann \'fcber explizit erzeugte storer Parallelit\'e4t haben, muss dann aber die Verantwortung daf\'fcr \'fcbernehmen.\par
\par
Also letztendlich reduziert sich die L\'f6sung nun auf ein "synchronized" und einen Kommentar dazu, anstatt mordsm\'e4\'dfig eine extra storer Implementierung oder einen Wrapper daf\'fcr zu bauen, aber macht ja nix.\par
Ich wollt nur mal die wochenendlichen \'dcberlegungen zu Protokoll geben.\par
\par
Die Sache mit der Storer ObjectRegistry Robustness und dem Fix \'fcber lokale Registries bleibt nat\'fcrlich. Das kann nach wie vor passieren und muss abgedeckt werden.\par
Nur die im Rahmen dieser Arbeiten entdeckte Race Condition Problematik l\'e4sst sich sehr leicht l\'f6sen.\par
\par
Code Stuff mach ich dann aber "morgen", bzw. heute nach bissl schlafen.\par
\par
\par
So, sp\'e4ter:\par
Weiter ID-Zeug umziehen.\par
\par
Soweit fertig.\par
Jetzt noch offen:\par
- PersistenceObjectManager#checkConsumers Zeug\par
- Concurrency L\'f6sung f\'fcr convenience API: versteckter Storer instanzen mit synchronized aufrufen\par
\par
\par
2020-03-16\par
\par
Bevor ichs vergess bau ich jetzt mal noch die Concurrency-Sicherheit f\'fcr die Storer ein.\par
\par
...Uuund es ist nat\'fcrlich wieder komplizierter als gedacht.\par
Die "Convenience Storing" Implementierung sind ja im PersistenceManager, nicht im StorageManager.\par
Allerdings ist im StorageManager EINE zus\'e4tzliche Methode, n\'e4mlich storeRoot. Die speichert aber zwei Instanzen, n\'e4mlich die RootReference und Root selbst. Das ist n\'f6tig, um die verschiedenen F\'e4lle von Root-Instanz-Handling abzudecken.\par
Hm, aber mei, dann muss ich daf\'fcr halt an die array-speicher-Methode weiterleiten und die gew\'fcnschte OID aus dem R\'fcckgabe-Array rausholen.\par
F\'fcr eine eher selten aufgerufene Methode sollten die zwei Array-Instanzierungen schon okay sein.\par
Hm... oder wird sie selten aufgerufen? Vielleicht gibts manche Anwendungen, die st\'e4ndig den Root storen?\par
Aber mal ehrlich: Das kann man machen, kein Problem, aber dann schleppt man halt den (insgesamt gesehen winzigen) Overhead st\'e4ndig mit. Egal.\par
Also mach ich so, bevor ich da mit irgendeiner Spezialkonstruktion ewig rumbau.\par
\par
Eins ist allerdings noch interessant:\par
Jede StorageConnection Instanz hat ihre eigene PersistenceManager Instanz.\par
D.h. schon mehrere StorageConnections haben, wird die Race Condition B\'fcchse wieder \'f6ffnen.\par
Aber eigentlich ist das okay: Wer explizit weitere Connections erstellt, muss schon eine gewisse fortgeschrittene Vorstellung von Parallit\'e4t usw. haben.\par
Also das passt so. Mutexe in PersistenceManager rein und die storeRoot Methode auf Array storing umbauen.\par
\par
Ahhh... so einfach ist es wieder mal nicht.\par
Die Array store Methode storet jeden Eintrag als Graph root (sonst br\'e4uchte man sie ja gleich nicht) und die d\'fcrfen nicht null sein.\par
Der root kann aber sehr wohl null sein.\par
Mann mann ...\par
Also Fallunterscheidung bauen...\par
\par
Und ich hab noch eine Stelle gefunden, wo explizit auf 0 gepr\'fcft wird, anstatt die Swizzling ID-Methoden zu verwenden. Also TODO hinmachen. Muss ich morgen systematisch alle suchen und beheben.\par
}
 